{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "efficient_Classification.ipynb의 사본",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1GslGbTH2qLkOXDBG9d-13IWs1HC1YNgL",
      "authorship_tag": "ABX9TyOntAvh5wleLcSROoYbmG4Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gkckdals3/Image-Argumentation/blob/main/eff_res_xception\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzKTwK2Sc8rY",
        "outputId": "85acd3f2-ef76-4a2a-c414-f12bc9087c47"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHmDDVROj2L1",
        "outputId": "5a1c4e95-7766-4d47-a7eb-233f8f6b0494"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Mar 11 02:14:24 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    48W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.metrics import Recall, Precision\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.keras.applications import *\n",
        "import os \n",
        "\n",
        "\n",
        "class callback(Callback):\n",
        "\n",
        "    def __init__(self, r, decay, save, monitor = 'val_loss'):\n",
        "        \n",
        "        self.round = r\n",
        "        self.decay = decay\n",
        "        self.best_monitor = 9999\n",
        "        self.out = save\n",
        "        self.monitor = monitor\n",
        "        self.cur_R = 1\n",
        "        self.best_epochs = 0\n",
        "        self.best_logs = ''\n",
        "    def on_train_begin(self, logs = None):\n",
        "        self.init_lr = K.get_value(self.model.optimizer.lr)\n",
        "        with open(os.path.join(self.out,'history.txt'),'a') as hist:\n",
        "            hist.write('-'*20+'\\n')\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        print('Epoch {0}: lr: {1}'.format(epoch+1, float(K.get_value(self.model.optimizer.lr))))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        R = (epoch)//self.round + 1\n",
        "        log_list = [str(i) for i in [epoch]+list(logs.items())]\n",
        "        if R > self.cur_R:\n",
        "            self.cur_R = R\n",
        "            new_lr = K.get_value(self.model.optimizer.lr) * self.decay\n",
        "            K.set_value(self.model.optimizer.lr, new_lr)\n",
        "            print('\\nlr is fixed to {0}'.format(new_lr))\n",
        "\n",
        "        monitor = logs.get(self.monitor)\n",
        "        if self.best_monitor >= monitor:\n",
        "            print('\\nbest model weights are saved at {0}'.format(self.out))\n",
        "            self.model.save_weights(os.path.join(self.out,'weights.h5'))\n",
        "            self.best_monitor = monitor\n",
        "            self.best_weights = self.model.get_weights()\n",
        "            self.best_epochs = epoch\n",
        "            self.best_logs = log_list\n",
        "        with open(os.path.join(self.out,'history.txt'),'a') as hist:\n",
        "            hist.write('\\t'.join(log_list)+'\\n')\n",
        "\n",
        "    def on_train_end(self, logs = None):\n",
        "        print('weights are setted to best weights (epochs {0})'.format(self.best_epochs + 1))\n",
        "        self.model.set_weights(self.best_weights)\n",
        "        self.best_monitor = 9999\n",
        "        self.cur_R = 1\n",
        "        self.best_epochs = 0\n",
        "        K.set_value(self.model.optimizer.lr, self.init_lr)\n",
        "        with open(os.path.join(self.out,'history.txt'),'a') as hist:\n",
        "            hist.write('\\n')\n",
        "            hist.write('\\t'.join(self.best_logs)+'\\n')\n",
        "            hist.write('-'*20+'\\n')\n",
        "\n",
        "def custom_f1(y_true, y_pred):    \n",
        "\n",
        "    def recall_m(y_true, y_pred):\n",
        "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        \n",
        "        recall = TP / (Positives+K.epsilon())    \n",
        "        return recall \n",
        "    \n",
        "    \n",
        "    def precision_m(y_true, y_pred):\n",
        "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    \n",
        "        precision = TP / (Pred_Positives+K.epsilon())\n",
        "        return precision \n",
        "    \n",
        "    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
        "    \n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "def keras_efficient(input_size=(224,224),w=None):\n",
        "    inputs = Input(input_size+(3,))\n",
        "    backbone = tensorflow.keras.applications.EfficientNetB7(weights=w, input_shape= input_size+(3,), classes=1000)\n",
        "    backbone_head = Model(inputs= backbone.inputs, outputs = backbone.layers[-2].output)\n",
        "    features = backbone_head(inputs)\n",
        "    outputs = Dense(1, activation = 'sigmoid', kernel_initializer = 'he_normal')(features)\n",
        "\n",
        "    return Model(inputs = inputs, outputs = outputs)\n",
        "\n",
        "\n",
        "def keras_efficientv2(input_size=(224,224),w=None):\n",
        "    inputs = Input(input_size+(3,))\n",
        "    backbone = tensorflow.keras.applications.EfficientNetV2B3(weights=w, input_shape= input_size+(3,), classes=1000)\n",
        "    backbone_head = Model(inputs= backbone.inputs, outputs = backbone.layers[-2].output)\n",
        "    features = backbone_head(inputs)\n",
        "    outputs = Dense(1, activation = 'sigmoid', kernel_initializer = 'he_normal')(features)\n",
        "\n",
        "    return Model(inputs = inputs, outputs = outputs)\n",
        "\n",
        "def keras_resnet(input_size=(224,224),w=None):\n",
        "    inputs = Input(input_size+(3,))\n",
        "    backbone = tensorflow.keras.applications.ResNet50V2(weights=w, input_shape= input_size+(3,), classes=1000)\n",
        "    backbone_head = Model(inputs= backbone.inputs, outputs = backbone.layers[-2].output)\n",
        "    features = backbone_head(inputs)\n",
        "    outputs = Dense(1, activation = 'sigmoid', kernel_initializer = 'he_normal')(features)\n",
        "\n",
        "    return Model(inputs = inputs, outputs = outputs)\n",
        "\n",
        "def keras_xception(input_size=(224,224),w=None):\n",
        "    inputs = Input(input_size+(3,))\n",
        "    backbone = tensorflow.keras.applications.Xception(weights=w, input_shape= input_size+(3,), classes=1000)\n",
        "    backbone_head = Model(inputs= backbone.inputs, outputs = backbone.layers[-2].output)\n",
        "    features = backbone_head(inputs)\n",
        "    outputs = Dense(1, activation = 'sigmoid', kernel_initializer = 'he_normal')(features)\n",
        "\n",
        "    return Model(inputs = inputs, outputs = outputs)"
      ],
      "metadata": {
        "id": "Xg-aSCJNVmlh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random\n",
        "import tensorflow as tf\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "import math\n",
        "\n",
        "#데이터 로드 모듈\n",
        "class data_load():\n",
        "    \n",
        "    def __init__(self,data, input_shape = (128,128)):\n",
        "        \n",
        "        train_data = pd.read_csv(os.path.join(data,'train_output.csv'))\n",
        "        self.train_y = train_data.iloc[:,1].to_numpy().astype(np.float32) \n",
        "        train_img_files = train_data.iloc[:,0].to_numpy()\n",
        "\n",
        "        idx = list(range(self.train_y.shape[0]))\n",
        "        #random.Random(1).shuffle(idx)\n",
        "        random.shuffle(idx)\n",
        "\n",
        "        self.train_y = self.train_y[idx]\n",
        "        train_img_files = train_img_files[idx]\n",
        "        train_img = []\n",
        "        print('train img load...')\n",
        "        for img_file in tqdm.tqdm(train_img_files):\n",
        "            img = Image.open(os.path.join(data,'train',img_file+'.png')).resize(input_shape) \n",
        "            train_img.append(np.array(img) / 255.)\n",
        "        self.train_X = np.array(train_img).astype(np.float32)\n",
        "        \n",
        "        test_data = pd.read_csv(os.path.join(data,'test_output_sample.csv'))\n",
        "        self.test_img_files = test_data.iloc[:,0].to_numpy()\n",
        "        test_img = []\n",
        "        print('test img load...')\n",
        "        for img_file in tqdm.tqdm(self.test_img_files):\n",
        "            img = Image.open(os.path.join(data,'test',img_file+'.png')).resize(input_shape) \n",
        "            test_img.append(np.array(img) / 255.)\n",
        "        self.test_X = np.array(test_img)\n",
        "\n",
        "#모델 학습 함수\n",
        "def training(data, model, epochs = 100, batch_size = 4,fold = 10, save='results',r=30, decay=0.1,lr = 1e-4):\n",
        "    \n",
        "    #데이터 나누는 지점 확인\n",
        "    sep = data.train_X.shape[0]//fold\n",
        "    \n",
        "    #콜백 및, 최적화 \n",
        "    ckp = callback(r=r, decay=decay,save = save,monitor = 'val_loss')\n",
        "    logger = CSVLogger(os.path.join(save,\"history.txt\"), append=True, separator='\\t')\n",
        "    adam = optimizers.Adam(lr=lr)\n",
        "    model.compile(loss = 'binary_crossentropy', metrics = [custom_f1], optimizer = adam)  \n",
        "    datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "    \n",
        "    #초기 웨이트 저장\n",
        "    model.save_weights(os.path.join(save,'init.h5'))\n",
        "\n",
        "    for i in range(fold):\n",
        "        print('fold {} [{},{}]'.format(i+1,sep*i,sep*(i+1)))\n",
        "        \n",
        "        with open(os.path.join(save,'history.txt'),'a') as hist:\n",
        "            hist.write('Fold {}'.format(i+1)+'\\n')\n",
        "\n",
        "        #최초 모델 로드\n",
        "        model.load_weights(os.path.join(save,'init.h5'))\n",
        "        \n",
        "        #데이터 분할\n",
        "        vali_X = data.train_X[sep*i:sep*(i+1)]\n",
        "        vali_y = data.train_y[sep*i:sep*(i+1)]\n",
        "        train_X = np.concatenate([\n",
        "            data.train_X[:sep*i],\n",
        "            data.train_X[sep*(i+1):]],axis=0)\n",
        "        train_y = np.concatenate([\n",
        "            data.train_y[:sep*i],\n",
        "            data.train_y[sep*(i+1):]],axis=0)\n",
        "        \n",
        "        #학습\n",
        "        model.fit(\n",
        "            datagen.flow(train_X,train_y,batch_size=batch_size), \n",
        "            validation_data = (vali_X,vali_y),\n",
        "            epochs = epochs, steps_per_epoch=math.ceil(len(train_X)/batch_size), callbacks= [ckp])\n",
        "        \n",
        "        #최적의 웨이트 저장\n",
        "        os.rename(os.path.join(save,'weights.h5'),\n",
        "                os.path.join(save,'weights_F{0}.h5'.format(i+1))) \n",
        "        with open(os.path.join(save,'history.txt'),'a') as hist:\n",
        "            hist.write('\\n'*4)\n",
        "            \n",
        "def testing(data, model, fold = 10,thr = 0.5,save='results'):\n",
        "    for i in range(fold):   \n",
        "        print('Fold {}/{}'.format(i+1,fold))\n",
        "        model.load_weights(os.path.join(save,'weights_F{}.h5'.format(i+1)))\n",
        "        if i == 0:\n",
        "            pred = model.predict(data.test_X,verbose=1) \n",
        "        else:\n",
        "            pred += model.predict(data.test_X,verbose=1)       \n",
        "    else:\n",
        "        pred /= fold\n",
        "    pred_ = np.where(pred >= thr, 1,0)    \n",
        "    results = pd.DataFrame({'Sample ID': data.test_img_files,'Control:0/Case:1': pred_.reshape(-1)})\n",
        "    results.to_csv(os.path.join(save,'test_output.csv'),index=False)"
      ],
      "metadata": {
        "id": "NvDIpM6QWaT5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "ysMHAhbkVX_G",
        "outputId": "6f2711cb-c362-4984-d10a-6b7ee4baa7eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "100%|██████████| 128/128 [01:12<00:00,  1.77it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x128 at 0x7F845EB44D50>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/SyntekaBio/train/PNG/train_output.csv')\n",
        "imgs = data.iloc[:,0].to_numpy()\n",
        "y = data.iloc[:,1].to_numpy()\n",
        "X = []\n",
        "for i in imgs:\n",
        "    img = Image.open('/content/drive/MyDrive/SyntekaBio/train/PNG/'+i+'.png').resize((128,128))\n",
        "    X.append(np.array(img)//255.)\n",
        "X = np.array(X)\n",
        "\n",
        "import statsmodels.api as sm\n",
        "import math\n",
        "import tqdm\n",
        "weights = np.zeros((128,128))\n",
        "\n",
        "for i in tqdm.tqdm(range(128)):\n",
        "\n",
        "    for j in range(128):\n",
        "        snps = np.sum(X[:,i,j,:],axis=1)\n",
        "        if len(set(snps)) == 1: \n",
        "            p = 1\n",
        "        else:\n",
        "            model = sm.OLS(y,snps)\n",
        "            fii = model.fit()\n",
        "            p = fii.summary2().tables[1]['P>|t|']\n",
        "        weights[i,j] = -math.log10(float(p))\n",
        "\n",
        "weights /= np.max(weights)\n",
        "weights *= 255\n",
        "weights = weights.astype(np.uint8)\n",
        "Image.fromarray(weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow\n",
        "import tensorflow.keras.applications\n",
        "\n",
        "###CONFIG#####\n",
        "train = False\n",
        "im_size = (512,512)\n",
        "save = '/content/drive/MyDrive/SyntekaBio/weights'\n",
        "path = '/content/drive/MyDrive/SyntekaBio/train/PNG'\n",
        "epochs = 100\n",
        "batch_size = 4\n",
        "fold = 10\n",
        "lr = 1e-4\n",
        "###############\n",
        "\n",
        "data = data_load(path,input_shape = im_size) \n",
        "model = keras_efficient(im_size) \n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "#trainning step\n",
        "print('######################')\n",
        "print('##                  ##')\n",
        "print('##   Train Models   ##')\n",
        "print('##                  ##')\n",
        "print('######################')\n",
        "    \n",
        "training(data, model, \n",
        "        epochs = epochs,\n",
        "        batch_size = batch_size,\n",
        "        fold = fold, \n",
        "        save=save,\n",
        "        r=50, \n",
        "        decay=0.1,\n",
        "        lr = lr)\n",
        "\n",
        "\n",
        "#trainning step\n",
        "#print('######################')\n",
        "#print('##                  ##')\n",
        "#print('##    Test STEP     ##')\n",
        "#print('##                  ##')\n",
        "#print('######################')\n",
        "#testing(data, model, thr = 0.5, save=save)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uHOJGo4vWvLz",
        "outputId": "e1afddcb-4c32-4bbe-bf47-e1cf329e4b00"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train img load...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 501/501 [00:20<00:00, 24.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test img load...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 126/126 [00:05<00:00, 24.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 512, 512, 3)]     0         \n",
            "                                                                 \n",
            " model (Functional)          (None, 2560)              64097687  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 2561      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 64,100,248\n",
            "Trainable params: 63,789,521\n",
            "Non-trainable params: 310,727\n",
            "_________________________________________________________________\n",
            "######################\n",
            "##                  ##\n",
            "##   Train Models   ##\n",
            "##                  ##\n",
            "######################\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 1 [0,50]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.6953 - custom_f1: 0.7135"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-722f21ccbe0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         lr = lr)\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-48f3037a311c>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(data, model, epochs, batch_size, fold, save, r, decay, lr)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvali_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvali_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             epochs = epochs, steps_per_epoch=math.ceil(len(train_X)/batch_size), callbacks= [ckp])\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m#최적의 웨이트 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_1/model/block2a_expand_bn/FusedBatchNormV3' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n      handler_func(fileobj, events)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-6-722f21ccbe0e>\", line 36, in <module>\n      lr = lr)\n    File \"<ipython-input-4-48f3037a311c>\", line 81, in training\n      epochs = epochs, steps_per_epoch=math.ceil(len(train_X)/batch_size), callbacks= [ckp])\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1431, in fit\n      _use_cached_eval_dataset=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1716, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1525, in test_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1514, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1507, in run_step\n      outputs = model.test_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1471, in test_step\n      y_pred = self(x, training=False)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 452, in call\n      inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 452, in call\n      inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/layers/normalization/batch_normalization.py\", line 767, in call\n      outputs = self._fused_batch_norm(inputs, training=training)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/layers/normalization/batch_normalization.py\", line 624, in _fused_batch_norm\n      training, train_op, _fused_batch_norm_inference)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/control_flow_util.py\", line 106, in smart_cond\n      pred, true_fn=true_fn, false_fn=false_fn, name=name)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/layers/normalization/batch_normalization.py\", line 613, in _fused_batch_norm_inference\n      data_format=self._data_format)\nNode: 'model_1/model/block2a_expand_bn/FusedBatchNormV3'\nOOM when allocating tensor with shape[32,192,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/model/block2a_expand_bn/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_test_function_73989]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/SyntekaBio/train/PNG/train_output.csv')\n",
        "imgs = data.iloc[:,0].to_numpy()\n",
        "y = data.iloc[:,1].to_numpy()\n",
        "X = []\n",
        "for i in imgs:\n",
        "    img = Image.open('/content/drive/MyDrive/SyntekaBio/train/PNG/'+i+'.png').resize((128,128))\n",
        "    X.append(np.array(img)//255.)\n",
        "X = np.array(X)\n",
        "\n",
        "import statsmodels.api as sm\n",
        "import math\n",
        "import tqdm\n",
        "weights = np.zeros((128,128))\n",
        "\n",
        "for i in tqdm.tqdm(range(128)):\n",
        "\n",
        "    for j in range(128):\n",
        "        snps = np.sum(X[:,i,j,:],axis=1)\n",
        "        if len(set(snps)) == 1: \n",
        "            p = 1\n",
        "        else:\n",
        "            model = sm.OLS(y,snps)\n",
        "            fii = model.fit()\n",
        "            p = fii.summary2().tables[1]['P>|t|']\n",
        "        weights[i,j] = -math.log10(float(p))\n",
        "\n",
        "weights /= np.max(weights)\n",
        "weights *= 255\n",
        "weights = weights.astype(np.uint8)\n",
        "Image.fromarray(weights)"
      ],
      "metadata": {
        "id": "aOVBOt65cGCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow\n",
        "import tensorflow.keras.applications\n",
        "\n",
        "###CONFIG#####\n",
        "train = False\n",
        "im_size = (512,512)\n",
        "save = '/content/drive/MyDrive/SyntekaBio/weights'\n",
        "path = '/content/drive/MyDrive/SyntekaBio/train/PNG'\n",
        "epochs = 100\n",
        "batch_size = 4\n",
        "fold = 10\n",
        "lr = 1e-4\n",
        "###############\n",
        "\n",
        "data = data_load(path,input_shape = im_size) \n",
        "model = keras_efficientv2(im_size) \n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "#trainning step\n",
        "print('######################')\n",
        "print('##                  ##')\n",
        "print('##   Train Models   ##')\n",
        "print('##                  ##')\n",
        "print('######################')\n",
        "    \n",
        "training(data, model, \n",
        "        epochs = epochs,\n",
        "        batch_size = batch_size,\n",
        "        fold = fold, \n",
        "        save=save,\n",
        "        r=50, \n",
        "        decay=0.1,\n",
        "        lr = lr)\n",
        "\n",
        "\n",
        "#trainning step\n",
        "print('######################')\n",
        "print('##                  ##')\n",
        "print('##    Test STEP     ##')\n",
        "print('##                  ##')\n",
        "print('######################')\n",
        "testing(data, model, thr = 0.5, save=save)"
      ],
      "metadata": {
        "id": "3FNFp3u5WyA9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8def979f-c628-4f09-cf68-92cd4b4131db"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train img load...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 501/501 [00:20<00:00, 24.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test img load...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 126/126 [00:05<00:00, 24.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 512, 512, 3)]     0         \n",
            "                                                                 \n",
            " model_2 (Functional)        (None, 1536)              12930622  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 1537      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,932,159\n",
            "Trainable params: 12,822,943\n",
            "Non-trainable params: 109,216\n",
            "_________________________________________________________________\n",
            "######################\n",
            "##                  ##\n",
            "##   Train Models   ##\n",
            "##                  ##\n",
            "######################\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 1 [0,50]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.6309 - custom_f1: 0.7755\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 30s 140ms/step - loss: 0.6309 - custom_f1: 0.7755 - val_loss: 8.1807 - val_custom_f1: 0.0000e+00\n",
            "Epoch 2: lr: 9.999999747378752e-05\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.5692 - custom_f1: 0.7953\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 105ms/step - loss: 0.5692 - custom_f1: 0.7953 - val_loss: 7.6517 - val_custom_f1: 0.0000e+00\n",
            "Epoch 3: lr: 9.999999747378752e-05\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.5419 - custom_f1: 0.8051 - val_loss: 19.8717 - val_custom_f1: 0.0000e+00\n",
            "Epoch 4: lr: 9.999999747378752e-05\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.4980 - custom_f1: 0.8016\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 13s 112ms/step - loss: 0.4980 - custom_f1: 0.8016 - val_loss: 6.5520 - val_custom_f1: 0.0000e+00\n",
            "Epoch 5: lr: 9.999999747378752e-05\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.4366 - custom_f1: 0.8345\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.4366 - custom_f1: 0.8345 - val_loss: 0.5639 - val_custom_f1: 0.7944\n",
            "Epoch 6: lr: 9.999999747378752e-05\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.4018 - custom_f1: 0.8508 - val_loss: 6.9871 - val_custom_f1: 0.7262\n",
            "Epoch 7: lr: 9.999999747378752e-05\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.3237 - custom_f1: 0.8933 - val_loss: 20.8786 - val_custom_f1: 0.0000e+00\n",
            "Epoch 8: lr: 9.999999747378752e-05\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.3120 - custom_f1: 0.8869 - val_loss: 36.5508 - val_custom_f1: 0.7262\n",
            "Epoch 9: lr: 9.999999747378752e-05\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.3883 - custom_f1: 0.8627 - val_loss: 3.0149 - val_custom_f1: 0.0000e+00\n",
            "Epoch 10: lr: 9.999999747378752e-05\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.3225 - custom_f1: 0.8761 - val_loss: 1.9554 - val_custom_f1: 0.0000e+00\n",
            "Epoch 11: lr: 9.999999747378752e-05\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.3063 - custom_f1: 0.8955\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.3063 - custom_f1: 0.8955 - val_loss: 0.5200 - val_custom_f1: 0.7544\n",
            "Epoch 12: lr: 9.999999747378752e-05\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.2960 - custom_f1: 0.8826 - val_loss: 1.2814 - val_custom_f1: 0.8264\n",
            "Epoch 13: lr: 9.999999747378752e-05\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.2190 - custom_f1: 0.9310 - val_loss: 2.5842 - val_custom_f1: 0.7470\n",
            "Epoch 14: lr: 9.999999747378752e-05\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.2369 - custom_f1: 0.9142 - val_loss: 5.5821 - val_custom_f1: 0.7398\n",
            "Epoch 15: lr: 9.999999747378752e-05\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1648 - custom_f1: 0.9498 - val_loss: 0.6353 - val_custom_f1: 0.8499\n",
            "Epoch 16: lr: 9.999999747378752e-05\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.1860 - custom_f1: 0.9426 - val_loss: 21.0816 - val_custom_f1: 0.7262\n",
            "Epoch 17: lr: 9.999999747378752e-05\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1817 - custom_f1: 0.9348 - val_loss: 17.9107 - val_custom_f1: 0.0000e+00\n",
            "Epoch 18: lr: 9.999999747378752e-05\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.1441 - custom_f1: 0.9724 - val_loss: 84.1770 - val_custom_f1: 0.7262\n",
            "Epoch 19: lr: 9.999999747378752e-05\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1335 - custom_f1: 0.9546 - val_loss: 5.8352 - val_custom_f1: 0.0000e+00\n",
            "Epoch 20: lr: 9.999999747378752e-05\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.2154 - custom_f1: 0.9255 - val_loss: 1.9141 - val_custom_f1: 0.2333\n",
            "Epoch 21: lr: 9.999999747378752e-05\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.1759 - custom_f1: 0.9563 - val_loss: 25.4957 - val_custom_f1: 0.7262\n",
            "Epoch 22: lr: 9.999999747378752e-05\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0979 - custom_f1: 0.9747\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 13s 111ms/step - loss: 0.0979 - custom_f1: 0.9747 - val_loss: 0.4311 - val_custom_f1: 0.8730\n",
            "Epoch 23: lr: 9.999999747378752e-05\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0555 - custom_f1: 0.9851 - val_loss: 0.4682 - val_custom_f1: 0.7970\n",
            "Epoch 24: lr: 9.999999747378752e-05\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1882 - custom_f1: 0.9483 - val_loss: 1.2275 - val_custom_f1: 0.3443\n",
            "Epoch 25: lr: 9.999999747378752e-05\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.1239 - custom_f1: 0.9723 - val_loss: 1.9621 - val_custom_f1: 0.0556\n",
            "Epoch 26: lr: 9.999999747378752e-05\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0900 - custom_f1: 0.9754 - val_loss: 11.3743 - val_custom_f1: 0.7398\n",
            "Epoch 27: lr: 9.999999747378752e-05\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1331 - custom_f1: 0.9650\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.1331 - custom_f1: 0.9650 - val_loss: 0.3210 - val_custom_f1: 0.8742\n",
            "Epoch 28: lr: 9.999999747378752e-05\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0381 - custom_f1: 0.9940 - val_loss: 0.3452 - val_custom_f1: 0.8912\n",
            "Epoch 29: lr: 9.999999747378752e-05\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0828 - custom_f1: 0.9794 - val_loss: 0.9488 - val_custom_f1: 0.8094\n",
            "Epoch 30: lr: 9.999999747378752e-05\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0881 - custom_f1: 0.9810 - val_loss: 0.5442 - val_custom_f1: 0.8377\n",
            "Epoch 31: lr: 9.999999747378752e-05\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0783 - custom_f1: 0.9805 - val_loss: 0.5756 - val_custom_f1: 0.6792\n",
            "Epoch 32: lr: 9.999999747378752e-05\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0582 - custom_f1: 0.9826 - val_loss: 3.5597 - val_custom_f1: 0.7770\n",
            "Epoch 33: lr: 9.999999747378752e-05\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0908 - custom_f1: 0.9810 - val_loss: 1.0451 - val_custom_f1: 0.5583\n",
            "Epoch 34: lr: 9.999999747378752e-05\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0740 - custom_f1: 0.9835 - val_loss: 0.6185 - val_custom_f1: 0.8546\n",
            "Epoch 35: lr: 9.999999747378752e-05\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0441 - custom_f1: 0.9935 - val_loss: 0.7399 - val_custom_f1: 0.5925\n",
            "Epoch 36: lr: 9.999999747378752e-05\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0780 - custom_f1: 0.9823 - val_loss: 0.4809 - val_custom_f1: 0.8348\n",
            "Epoch 37: lr: 9.999999747378752e-05\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0425 - custom_f1: 0.9912 - val_loss: 0.5026 - val_custom_f1: 0.8453\n",
            "Epoch 38: lr: 9.999999747378752e-05\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0834 - custom_f1: 0.9775 - val_loss: 1.5459 - val_custom_f1: 0.2738\n",
            "Epoch 39: lr: 9.999999747378752e-05\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1188 - custom_f1: 0.9650 - val_loss: 49.1670 - val_custom_f1: 0.7262\n",
            "Epoch 40: lr: 9.999999747378752e-05\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0872 - custom_f1: 0.9761 - val_loss: 8.6477 - val_custom_f1: 0.0000e+00\n",
            "Epoch 41: lr: 9.999999747378752e-05\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.2306 - custom_f1: 0.9206 - val_loss: 47.8337 - val_custom_f1: 0.7262\n",
            "Epoch 42: lr: 9.999999747378752e-05\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1272 - custom_f1: 0.9558\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.1272 - custom_f1: 0.9558 - val_loss: 0.3124 - val_custom_f1: 0.8942\n",
            "Epoch 43: lr: 9.999999747378752e-05\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1569 - custom_f1: 0.9559 - val_loss: 0.4639 - val_custom_f1: 0.8377\n",
            "Epoch 44: lr: 9.999999747378752e-05\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0716 - custom_f1: 0.9847 - val_loss: 0.3478 - val_custom_f1: 0.8908\n",
            "Epoch 45: lr: 9.999999747378752e-05\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0176 - custom_f1: 1.0000 - val_loss: 0.5146 - val_custom_f1: 0.8231\n",
            "Epoch 46: lr: 9.999999747378752e-05\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0776 - custom_f1: 0.9823 - val_loss: 0.6055 - val_custom_f1: 0.8231\n",
            "Epoch 47: lr: 9.999999747378752e-05\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0816 - custom_f1: 0.9781 - val_loss: 1.0419 - val_custom_f1: 0.8377\n",
            "Epoch 48: lr: 9.999999747378752e-05\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0448 - custom_f1: 0.9887 - val_loss: 14.2790 - val_custom_f1: 0.7262\n",
            "Epoch 49: lr: 9.999999747378752e-05\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1013 - custom_f1: 0.9809 - val_loss: 0.3449 - val_custom_f1: 0.8762\n",
            "Epoch 50: lr: 9.999999747378752e-05\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1388 - custom_f1: 0.9574 - val_loss: 1.0525 - val_custom_f1: 0.7546\n",
            "Epoch 51: lr: 9.999999747378752e-05\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1914 - custom_f1: 0.9428\n",
            "lr is fixed to 9.999999747378752e-06\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1914 - custom_f1: 0.9428 - val_loss: 1.3970 - val_custom_f1: 0.8028\n",
            "Epoch 52: lr: 9.999999747378752e-06\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1130 - custom_f1: 0.9776 - val_loss: 0.4260 - val_custom_f1: 0.8400\n",
            "Epoch 53: lr: 9.999999747378752e-06\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0750 - custom_f1: 0.9864 - val_loss: 0.5146 - val_custom_f1: 0.8400\n",
            "Epoch 54: lr: 9.999999747378752e-06\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1404 - custom_f1: 0.9646 - val_loss: 0.4567 - val_custom_f1: 0.8400\n",
            "Epoch 55: lr: 9.999999747378752e-06\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0534 - custom_f1: 0.9912 - val_loss: 0.3450 - val_custom_f1: 0.8972\n",
            "Epoch 56: lr: 9.999999747378752e-06\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0750 - custom_f1: 0.9823 - val_loss: 0.4532 - val_custom_f1: 0.8503\n",
            "Epoch 57: lr: 9.999999747378752e-06\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0209 - custom_f1: 1.0000 - val_loss: 0.3679 - val_custom_f1: 0.8993\n",
            "Epoch 58: lr: 9.999999747378752e-06\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0457 - custom_f1: 0.9899 - val_loss: 0.4070 - val_custom_f1: 0.8794\n",
            "Epoch 59: lr: 9.999999747378752e-06\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0183 - custom_f1: 1.0000 - val_loss: 0.3534 - val_custom_f1: 0.8972\n",
            "Epoch 60: lr: 9.999999747378752e-06\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0110 - custom_f1: 1.0000 - val_loss: 0.3789 - val_custom_f1: 0.8993\n",
            "Epoch 61: lr: 9.999999747378752e-06\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0698 - custom_f1: 0.9823 - val_loss: 0.3617 - val_custom_f1: 0.8993\n",
            "Epoch 62: lr: 9.999999747378752e-06\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0397 - custom_f1: 0.9912 - val_loss: 0.3451 - val_custom_f1: 0.9211\n",
            "Epoch 63: lr: 9.999999747378752e-06\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0116 - custom_f1: 1.0000 - val_loss: 0.3667 - val_custom_f1: 0.8993\n",
            "Epoch 64: lr: 9.999999747378752e-06\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0132 - custom_f1: 1.0000 - val_loss: 0.3551 - val_custom_f1: 0.8993\n",
            "Epoch 65: lr: 9.999999747378752e-06\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0660 - custom_f1: 0.9823 - val_loss: 0.3734 - val_custom_f1: 0.8993\n",
            "Epoch 66: lr: 9.999999747378752e-06\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0125 - custom_f1: 1.0000 - val_loss: 0.4072 - val_custom_f1: 0.8794\n",
            "Epoch 67: lr: 9.999999747378752e-06\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0117 - custom_f1: 1.0000 - val_loss: 0.3610 - val_custom_f1: 0.8972\n",
            "Epoch 68: lr: 9.999999747378752e-06\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0074 - custom_f1: 1.0000 - val_loss: 0.3994 - val_custom_f1: 0.8993\n",
            "Epoch 69: lr: 9.999999747378752e-06\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0371 - custom_f1: 0.9912 - val_loss: 0.3810 - val_custom_f1: 0.8993\n",
            "Epoch 70: lr: 9.999999747378752e-06\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0707 - custom_f1: 0.9823 - val_loss: 0.3927 - val_custom_f1: 0.8993\n",
            "Epoch 71: lr: 9.999999747378752e-06\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0640 - custom_f1: 0.9823 - val_loss: 0.3978 - val_custom_f1: 0.8993\n",
            "Epoch 72: lr: 9.999999747378752e-06\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0381 - custom_f1: 0.9912 - val_loss: 0.3711 - val_custom_f1: 0.9211\n",
            "Epoch 73: lr: 9.999999747378752e-06\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0385 - custom_f1: 0.9912 - val_loss: 0.4308 - val_custom_f1: 0.8993\n",
            "Epoch 74: lr: 9.999999747378752e-06\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0381 - custom_f1: 0.9912 - val_loss: 0.4652 - val_custom_f1: 0.8885\n",
            "Epoch 75: lr: 9.999999747378752e-06\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0406 - custom_f1: 0.9912 - val_loss: 0.3698 - val_custom_f1: 0.9211\n",
            "Epoch 76: lr: 9.999999747378752e-06\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0092 - custom_f1: 1.0000 - val_loss: 0.3643 - val_custom_f1: 0.9048\n",
            "Epoch 77: lr: 9.999999747378752e-06\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0379 - custom_f1: 0.9912 - val_loss: 0.3721 - val_custom_f1: 0.9211\n",
            "Epoch 78: lr: 9.999999747378752e-06\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0089 - custom_f1: 1.0000 - val_loss: 0.3549 - val_custom_f1: 0.8786\n",
            "Epoch 79: lr: 9.999999747378752e-06\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0700 - custom_f1: 0.9823 - val_loss: 0.5680 - val_custom_f1: 0.8400\n",
            "Epoch 80: lr: 9.999999747378752e-06\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0716 - custom_f1: 0.9805 - val_loss: 0.4082 - val_custom_f1: 0.9227\n",
            "Epoch 81: lr: 9.999999747378752e-06\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0387 - custom_f1: 0.9912 - val_loss: 0.4413 - val_custom_f1: 0.8885\n",
            "Epoch 82: lr: 9.999999747378752e-06\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0667 - custom_f1: 0.9823 - val_loss: 0.4423 - val_custom_f1: 0.8885\n",
            "Epoch 83: lr: 9.999999747378752e-06\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0342 - custom_f1: 0.9912 - val_loss: 0.4816 - val_custom_f1: 0.8993\n",
            "Epoch 84: lr: 9.999999747378752e-06\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0911 - custom_f1: 0.9735 - val_loss: 0.3963 - val_custom_f1: 0.9286\n",
            "Epoch 85: lr: 9.999999747378752e-06\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0112 - custom_f1: 1.0000 - val_loss: 0.4145 - val_custom_f1: 0.9107\n",
            "Epoch 86: lr: 9.999999747378752e-06\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0358 - custom_f1: 0.9912 - val_loss: 0.3812 - val_custom_f1: 0.9048\n",
            "Epoch 87: lr: 9.999999747378752e-06\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0105 - custom_f1: 1.0000 - val_loss: 0.4092 - val_custom_f1: 0.9107\n",
            "Epoch 88: lr: 9.999999747378752e-06\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0377 - custom_f1: 0.9912 - val_loss: 0.3811 - val_custom_f1: 0.9286\n",
            "Epoch 89: lr: 9.999999747378752e-06\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0636 - custom_f1: 0.9823 - val_loss: 0.4143 - val_custom_f1: 0.9107\n",
            "Epoch 90: lr: 9.999999747378752e-06\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0097 - custom_f1: 1.0000 - val_loss: 0.4025 - val_custom_f1: 0.8831\n",
            "Epoch 91: lr: 9.999999747378752e-06\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0348 - custom_f1: 0.9912 - val_loss: 0.4009 - val_custom_f1: 0.9048\n",
            "Epoch 92: lr: 9.999999747378752e-06\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0377 - custom_f1: 0.9912 - val_loss: 0.4071 - val_custom_f1: 0.8786\n",
            "Epoch 93: lr: 9.999999747378752e-06\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0591 - custom_f1: 0.9823 - val_loss: 0.4475 - val_custom_f1: 0.9068\n",
            "Epoch 94: lr: 9.999999747378752e-06\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0091 - custom_f1: 1.0000 - val_loss: 0.4414 - val_custom_f1: 0.8786\n",
            "Epoch 95: lr: 9.999999747378752e-06\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0667 - custom_f1: 0.9823 - val_loss: 0.5000 - val_custom_f1: 0.8712\n",
            "Epoch 96: lr: 9.999999747378752e-06\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.1108 - custom_f1: 0.9646 - val_loss: 0.5385 - val_custom_f1: 0.8885\n",
            "Epoch 97: lr: 9.999999747378752e-06\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0391 - custom_f1: 0.9912 - val_loss: 0.4425 - val_custom_f1: 0.8712\n",
            "Epoch 98: lr: 9.999999747378752e-06\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0131 - custom_f1: 1.0000 - val_loss: 0.4598 - val_custom_f1: 0.8870\n",
            "Epoch 99: lr: 9.999999747378752e-06\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0087 - custom_f1: 1.0000 - val_loss: 0.4517 - val_custom_f1: 0.8756\n",
            "Epoch 100: lr: 9.999999747378752e-06\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0635 - custom_f1: 0.9823 - val_loss: 0.5022 - val_custom_f1: 0.8949\n",
            "weights are setted to best weights (epochs 42)\n",
            "fold 2 [50,100]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.6357 - custom_f1: 0.7748\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 106ms/step - loss: 0.6357 - custom_f1: 0.7748 - val_loss: 0.7061 - val_custom_f1: 0.1714\n",
            "Epoch 2: lr: 9.999999747378752e-05\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.5958 - custom_f1: 0.7894 - val_loss: 6.5098 - val_custom_f1: 0.0000e+00\n",
            "Epoch 3: lr: 9.999999747378752e-05\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.5262 - custom_f1: 0.8139 - val_loss: 4.4203 - val_custom_f1: 0.0000e+00\n",
            "Epoch 4: lr: 9.999999747378752e-05\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.4814 - custom_f1: 0.8262 - val_loss: 2.4311 - val_custom_f1: 0.0000e+00\n",
            "Epoch 5: lr: 9.999999747378752e-05\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.4186 - custom_f1: 0.8408 - val_loss: 0.8446 - val_custom_f1: 0.2417\n",
            "Epoch 6: lr: 9.999999747378752e-05\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.3290 - custom_f1: 0.8835 - val_loss: 50.1133 - val_custom_f1: 0.7259\n",
            "Epoch 7: lr: 9.999999747378752e-05\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.2813 - custom_f1: 0.9151 - val_loss: 37.1416 - val_custom_f1: 0.0000e+00\n",
            "Epoch 8: lr: 9.999999747378752e-05\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.2403 - custom_f1: 0.9114\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 13s 111ms/step - loss: 0.2403 - custom_f1: 0.9114 - val_loss: 0.4488 - val_custom_f1: 0.8444\n",
            "Epoch 9: lr: 9.999999747378752e-05\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.2387 - custom_f1: 0.9238\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 13s 111ms/step - loss: 0.2387 - custom_f1: 0.9238 - val_loss: 0.3181 - val_custom_f1: 0.8586\n",
            "Epoch 10: lr: 9.999999747378752e-05\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.1164 - custom_f1: 0.9687 - val_loss: 0.5498 - val_custom_f1: 0.8011\n",
            "Epoch 11: lr: 9.999999747378752e-05\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1073 - custom_f1: 0.9604 - val_loss: 4.4898 - val_custom_f1: 0.7382\n",
            "Epoch 12: lr: 9.999999747378752e-05\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1241 - custom_f1: 0.9607 - val_loss: 59.6877 - val_custom_f1: 0.7259\n",
            "Epoch 13: lr: 9.999999747378752e-05\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1241 - custom_f1: 0.9671 - val_loss: 2.1081 - val_custom_f1: 0.0000e+00\n",
            "Epoch 14: lr: 9.999999747378752e-05\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1745 - custom_f1: 0.9485 - val_loss: 0.9960 - val_custom_f1: 0.7593\n",
            "Epoch 15: lr: 9.999999747378752e-05\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1101 - custom_f1: 0.9673 - val_loss: 111.2801 - val_custom_f1: 0.7259\n",
            "Epoch 16: lr: 9.999999747378752e-05\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0871 - custom_f1: 0.9723 - val_loss: 3.2934 - val_custom_f1: 0.0000e+00\n",
            "Epoch 17: lr: 9.999999747378752e-05\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0761 - custom_f1: 0.9797 - val_loss: 46.1519 - val_custom_f1: 0.7259\n",
            "Epoch 18: lr: 9.999999747378752e-05\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0728 - custom_f1: 0.9869 - val_loss: 2.3943 - val_custom_f1: 0.7459\n",
            "Epoch 19: lr: 9.999999747378752e-05\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1090 - custom_f1: 0.9795 - val_loss: 0.5074 - val_custom_f1: 0.7630\n",
            "Epoch 20: lr: 9.999999747378752e-05\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0236 - custom_f1: 0.9970 - val_loss: 0.7971 - val_custom_f1: 0.8233\n",
            "Epoch 21: lr: 9.999999747378752e-05\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0931 - custom_f1: 0.9764 - val_loss: 5.2043 - val_custom_f1: 0.0000e+00\n",
            "Epoch 22: lr: 9.999999747378752e-05\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0574 - custom_f1: 0.9857 - val_loss: 96.1758 - val_custom_f1: 0.7259\n",
            "Epoch 23: lr: 9.999999747378752e-05\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1037 - custom_f1: 0.9770 - val_loss: 0.8594 - val_custom_f1: 0.6876\n",
            "Epoch 24: lr: 9.999999747378752e-05\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0507 - custom_f1: 0.9912 - val_loss: 1.4304 - val_custom_f1: 0.4796\n",
            "Epoch 25: lr: 9.999999747378752e-05\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0716 - custom_f1: 0.9805 - val_loss: 4.6728 - val_custom_f1: 0.0000e+00\n",
            "Epoch 26: lr: 9.999999747378752e-05\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0650 - custom_f1: 0.9823\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.0650 - custom_f1: 0.9823 - val_loss: 0.2963 - val_custom_f1: 0.9373\n",
            "Epoch 27: lr: 9.999999747378752e-05\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0928 - custom_f1: 0.9722 - val_loss: 0.3418 - val_custom_f1: 0.9251\n",
            "Epoch 28: lr: 9.999999747378752e-05\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0566 - custom_f1: 0.9869 - val_loss: 0.9684 - val_custom_f1: 0.6146\n",
            "Epoch 29: lr: 9.999999747378752e-05\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1004 - custom_f1: 0.9751 - val_loss: 5.7919 - val_custom_f1: 0.7351\n",
            "Epoch 30: lr: 9.999999747378752e-05\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1791 - custom_f1: 0.9408 - val_loss: 136.7672 - val_custom_f1: 0.7259\n",
            "Epoch 31: lr: 9.999999747378752e-05\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0816 - custom_f1: 0.9787 - val_loss: 1.7623 - val_custom_f1: 0.7459\n",
            "Epoch 32: lr: 9.999999747378752e-05\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0675 - custom_f1: 0.9769 - val_loss: 0.7049 - val_custom_f1: 0.7976\n",
            "Epoch 33: lr: 9.999999747378752e-05\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0790 - custom_f1: 0.9810 - val_loss: 0.8832 - val_custom_f1: 0.7000\n",
            "Epoch 34: lr: 9.999999747378752e-05\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0675 - custom_f1: 0.9823 - val_loss: 3.6021 - val_custom_f1: 0.2265\n",
            "Epoch 35: lr: 9.999999747378752e-05\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0918 - custom_f1: 0.9735 - val_loss: 0.3315 - val_custom_f1: 0.8730\n",
            "Epoch 36: lr: 9.999999747378752e-05\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1148 - custom_f1: 0.9646 - val_loss: 0.4810 - val_custom_f1: 0.8299\n",
            "Epoch 37: lr: 9.999999747378752e-05\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1340 - custom_f1: 0.9701 - val_loss: 0.4766 - val_custom_f1: 0.8490\n",
            "Epoch 38: lr: 9.999999747378752e-05\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1255 - custom_f1: 0.9666 - val_loss: 1.4495 - val_custom_f1: 0.1911\n",
            "Epoch 39: lr: 9.999999747378752e-05\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0603 - custom_f1: 0.9897 - val_loss: 0.3992 - val_custom_f1: 0.8655\n",
            "Epoch 40: lr: 9.999999747378752e-05\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1202 - custom_f1: 0.9678 - val_loss: 0.4217 - val_custom_f1: 0.8675\n",
            "Epoch 41: lr: 9.999999747378752e-05\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1033 - custom_f1: 0.9678 - val_loss: 1.9427 - val_custom_f1: 0.7459\n",
            "Epoch 42: lr: 9.999999747378752e-05\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0603 - custom_f1: 0.9876 - val_loss: 2.9941 - val_custom_f1: 0.7459\n",
            "Epoch 43: lr: 9.999999747378752e-05\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0127 - custom_f1: 1.0000 - val_loss: 0.5868 - val_custom_f1: 0.8059\n",
            "Epoch 44: lr: 9.999999747378752e-05\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0432 - custom_f1: 0.9912 - val_loss: 0.3768 - val_custom_f1: 0.8611\n",
            "Epoch 45: lr: 9.999999747378752e-05\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1110 - custom_f1: 0.9717\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.1110 - custom_f1: 0.9717 - val_loss: 0.2749 - val_custom_f1: 0.8863\n",
            "Epoch 46: lr: 9.999999747378752e-05\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0545 - custom_f1: 0.9864 - val_loss: 0.6724 - val_custom_f1: 0.8221\n",
            "Epoch 47: lr: 9.999999747378752e-05\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0457 - custom_f1: 0.9894 - val_loss: 8.6898 - val_custom_f1: 0.0000e+00\n",
            "Epoch 48: lr: 9.999999747378752e-05\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0866 - custom_f1: 0.9735 - val_loss: 0.3985 - val_custom_f1: 0.8730\n",
            "Epoch 49: lr: 9.999999747378752e-05\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0347 - custom_f1: 0.9912 - val_loss: 0.5504 - val_custom_f1: 0.8852\n",
            "Epoch 50: lr: 9.999999747378752e-05\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0568 - custom_f1: 0.9823 - val_loss: 4.0032 - val_custom_f1: 0.7459\n",
            "Epoch 51: lr: 9.999999747378752e-05\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0595 - custom_f1: 0.9823\n",
            "lr is fixed to 9.999999747378752e-06\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0595 - custom_f1: 0.9823 - val_loss: 0.6439 - val_custom_f1: 0.8441\n",
            "Epoch 52: lr: 9.999999747378752e-06\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0769 - custom_f1: 0.9735 - val_loss: 0.3705 - val_custom_f1: 0.9125\n",
            "Epoch 53: lr: 9.999999747378752e-06\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0501 - custom_f1: 0.9823 - val_loss: 0.3707 - val_custom_f1: 0.8990\n",
            "Epoch 54: lr: 9.999999747378752e-06\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0136 - custom_f1: 1.0000 - val_loss: 0.3705 - val_custom_f1: 0.9010\n",
            "Epoch 55: lr: 9.999999747378752e-06\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0081 - custom_f1: 1.0000 - val_loss: 0.3495 - val_custom_f1: 0.9010\n",
            "Epoch 56: lr: 9.999999747378752e-06\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0090 - custom_f1: 1.0000 - val_loss: 0.3445 - val_custom_f1: 0.9010\n",
            "Epoch 57: lr: 9.999999747378752e-06\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - 11s 101ms/step - loss: 0.0461 - custom_f1: 0.9823 - val_loss: 0.3395 - val_custom_f1: 0.9010\n",
            "Epoch 58: lr: 9.999999747378752e-06\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0625 - custom_f1: 0.9735 - val_loss: 0.3509 - val_custom_f1: 0.8891\n",
            "Epoch 59: lr: 9.999999747378752e-06\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0111 - custom_f1: 1.0000 - val_loss: 0.3144 - val_custom_f1: 0.9111\n",
            "Epoch 60: lr: 9.999999747378752e-06\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0078 - custom_f1: 1.0000 - val_loss: 0.3266 - val_custom_f1: 0.9111\n",
            "Epoch 61: lr: 9.999999747378752e-06\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0073 - custom_f1: 1.0000 - val_loss: 0.3225 - val_custom_f1: 0.9111\n",
            "Epoch 62: lr: 9.999999747378752e-06\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0481 - custom_f1: 0.9823 - val_loss: 0.3493 - val_custom_f1: 0.9111\n",
            "Epoch 63: lr: 9.999999747378752e-06\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0459 - custom_f1: 0.9823 - val_loss: 0.3748 - val_custom_f1: 0.8891\n",
            "Epoch 64: lr: 9.999999747378752e-06\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0729 - custom_f1: 0.9646 - val_loss: 0.3091 - val_custom_f1: 0.9111\n",
            "Epoch 65: lr: 9.999999747378752e-06\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0477 - custom_f1: 0.9735 - val_loss: 0.2948 - val_custom_f1: 0.8877\n",
            "Epoch 66: lr: 9.999999747378752e-06\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0468 - custom_f1: 0.9735 - val_loss: 0.3272 - val_custom_f1: 0.8990\n",
            "Epoch 67: lr: 9.999999747378752e-06\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0402 - custom_f1: 0.9823 - val_loss: 0.3343 - val_custom_f1: 0.8990\n",
            "Epoch 68: lr: 9.999999747378752e-06\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0222 - custom_f1: 0.9912 - val_loss: 0.3406 - val_custom_f1: 0.8776\n",
            "Epoch 69: lr: 9.999999747378752e-06\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0075 - custom_f1: 1.0000 - val_loss: 0.3386 - val_custom_f1: 0.8891\n",
            "Epoch 70: lr: 9.999999747378752e-06\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0382 - custom_f1: 0.9823 - val_loss: 0.4926 - val_custom_f1: 0.8524\n",
            "Epoch 71: lr: 9.999999747378752e-06\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0186 - custom_f1: 0.9912 - val_loss: 0.3220 - val_custom_f1: 0.9111\n",
            "Epoch 72: lr: 9.999999747378752e-06\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0296 - custom_f1: 0.9823 - val_loss: 0.3312 - val_custom_f1: 0.8877\n",
            "Epoch 73: lr: 9.999999747378752e-06\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0319 - custom_f1: 0.9823 - val_loss: 0.3980 - val_custom_f1: 0.8852\n",
            "Epoch 74: lr: 9.999999747378752e-06\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0145 - custom_f1: 0.9912 - val_loss: 0.3843 - val_custom_f1: 0.8700\n",
            "Epoch 75: lr: 9.999999747378752e-06\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0478 - custom_f1: 0.9735 - val_loss: 0.3549 - val_custom_f1: 0.8863\n",
            "Epoch 76: lr: 9.999999747378752e-06\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0332 - custom_f1: 0.9735 - val_loss: 0.3289 - val_custom_f1: 0.8993\n",
            "Epoch 77: lr: 9.999999747378752e-06\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0061 - custom_f1: 1.0000 - val_loss: 0.4028 - val_custom_f1: 0.8700\n",
            "Epoch 78: lr: 9.999999747378752e-06\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0330 - custom_f1: 0.9823 - val_loss: 0.3245 - val_custom_f1: 0.8993\n",
            "Epoch 79: lr: 9.999999747378752e-06\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0211 - custom_f1: 0.9912 - val_loss: 0.3226 - val_custom_f1: 0.8993\n",
            "Epoch 80: lr: 9.999999747378752e-06\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0206 - custom_f1: 0.9912 - val_loss: 0.3917 - val_custom_f1: 0.8700\n",
            "Epoch 81: lr: 9.999999747378752e-06\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0235 - custom_f1: 0.9823 - val_loss: 0.3436 - val_custom_f1: 0.8993\n",
            "Epoch 82: lr: 9.999999747378752e-06\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0311 - custom_f1: 0.9646 - val_loss: 0.2952 - val_custom_f1: 0.9111\n",
            "Epoch 83: lr: 9.999999747378752e-06\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0109 - custom_f1: 0.9912 - val_loss: 0.3765 - val_custom_f1: 0.8794\n",
            "Epoch 84: lr: 9.999999747378752e-06\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0082 - custom_f1: 0.9912 - val_loss: 0.3574 - val_custom_f1: 0.8993\n",
            "Epoch 85: lr: 9.999999747378752e-06\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0142 - custom_f1: 0.9823 - val_loss: 0.3328 - val_custom_f1: 0.8877\n",
            "Epoch 86: lr: 9.999999747378752e-06\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0306 - custom_f1: 0.9735 - val_loss: 0.3815 - val_custom_f1: 0.8891\n",
            "Epoch 87: lr: 9.999999747378752e-06\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0191 - custom_f1: 0.9823 - val_loss: 0.8604 - val_custom_f1: 0.8069\n",
            "Epoch 88: lr: 9.999999747378752e-06\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0103 - custom_f1: 0.9912 - val_loss: 0.4054 - val_custom_f1: 0.8700\n",
            "Epoch 89: lr: 9.999999747378752e-06\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0093 - custom_f1: 0.9912 - val_loss: 0.3859 - val_custom_f1: 0.8700\n",
            "Epoch 90: lr: 9.999999747378752e-06\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0086 - custom_f1: 0.9912 - val_loss: 0.3792 - val_custom_f1: 0.8794\n",
            "Epoch 91: lr: 9.999999747378752e-06\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0205 - custom_f1: 0.9823 - val_loss: 0.3584 - val_custom_f1: 0.8877\n",
            "Epoch 92: lr: 9.999999747378752e-06\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0136 - custom_f1: 0.9735 - val_loss: 0.3695 - val_custom_f1: 0.8877\n",
            "Epoch 93: lr: 9.999999747378752e-06\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0156 - custom_f1: 0.9735 - val_loss: 0.3364 - val_custom_f1: 0.8877\n",
            "Epoch 94: lr: 9.999999747378752e-06\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0133 - custom_f1: 0.9735 - val_loss: 0.3613 - val_custom_f1: 0.8877\n",
            "Epoch 95: lr: 9.999999747378752e-06\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0097 - custom_f1: 0.9912 - val_loss: 0.3634 - val_custom_f1: 0.9111\n",
            "Epoch 96: lr: 9.999999747378752e-06\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0104 - custom_f1: 0.9823 - val_loss: 0.3952 - val_custom_f1: 0.8811\n",
            "Epoch 97: lr: 9.999999747378752e-06\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0067 - custom_f1: 0.9912 - val_loss: 0.3594 - val_custom_f1: 0.8993\n",
            "Epoch 98: lr: 9.999999747378752e-06\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0136 - custom_f1: 0.9823 - val_loss: 0.8722 - val_custom_f1: 0.8470\n",
            "Epoch 99: lr: 9.999999747378752e-06\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0068 - custom_f1: 0.9912 - val_loss: 0.3229 - val_custom_f1: 0.9227\n",
            "Epoch 100: lr: 9.999999747378752e-06\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0085 - custom_f1: 0.9823 - val_loss: 0.3392 - val_custom_f1: 0.9111\n",
            "weights are setted to best weights (epochs 45)\n",
            "fold 3 [100,150]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.6344 - custom_f1: 0.7662\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 106ms/step - loss: 0.6344 - custom_f1: 0.7662 - val_loss: 4.0522 - val_custom_f1: 0.7962\n",
            "Epoch 2: lr: 9.999999747378752e-05\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.6158 - custom_f1: 0.7625 - val_loss: 7.0291 - val_custom_f1: 0.0000e+00\n",
            "Epoch 3: lr: 9.999999747378752e-05\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.5691 - custom_f1: 0.7803 - val_loss: 49.9448 - val_custom_f1: 0.0000e+00\n",
            "Epoch 4: lr: 9.999999747378752e-05\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.4962 - custom_f1: 0.8373 - val_loss: 8.9661 - val_custom_f1: 0.0000e+00\n",
            "Epoch 5: lr: 9.999999747378752e-05\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.4390 - custom_f1: 0.8555\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 13s 111ms/step - loss: 0.4390 - custom_f1: 0.8555 - val_loss: 3.7214 - val_custom_f1: 0.0000e+00\n",
            "Epoch 6: lr: 9.999999747378752e-05\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.3551 - custom_f1: 0.8894\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 13s 111ms/step - loss: 0.3551 - custom_f1: 0.8894 - val_loss: 3.6520 - val_custom_f1: 0.6436\n",
            "Epoch 7: lr: 9.999999747378752e-05\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.2870 - custom_f1: 0.8932 - val_loss: 23.3725 - val_custom_f1: 0.7962\n",
            "Epoch 8: lr: 9.999999747378752e-05\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.2635 - custom_f1: 0.9077 - val_loss: 8.2853 - val_custom_f1: 0.7962\n",
            "Epoch 9: lr: 9.999999747378752e-05\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.2408 - custom_f1: 0.9158\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 109ms/step - loss: 0.2408 - custom_f1: 0.9158 - val_loss: 3.0128 - val_custom_f1: 0.0000e+00\n",
            "Epoch 10: lr: 9.999999747378752e-05\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1695 - custom_f1: 0.9577 - val_loss: 23.2485 - val_custom_f1: 0.7962\n",
            "Epoch 11: lr: 9.999999747378752e-05\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.2494 - custom_f1: 0.9168\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 111ms/step - loss: 0.2494 - custom_f1: 0.9168 - val_loss: 2.3036 - val_custom_f1: 0.0000e+00\n",
            "Epoch 12: lr: 9.999999747378752e-05\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.1928 - custom_f1: 0.9371 - val_loss: 4.4939 - val_custom_f1: 0.0000e+00\n",
            "Epoch 13: lr: 9.999999747378752e-05\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1342 - custom_f1: 0.9666 - val_loss: 36.7800 - val_custom_f1: 0.7962\n",
            "Epoch 14: lr: 9.999999747378752e-05\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1094 - custom_f1: 0.9768\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 109ms/step - loss: 0.1094 - custom_f1: 0.9768 - val_loss: 0.3244 - val_custom_f1: 0.8819\n",
            "Epoch 15: lr: 9.999999747378752e-05\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0658 - custom_f1: 0.9894 - val_loss: 30.8704 - val_custom_f1: 0.7962\n",
            "Epoch 16: lr: 9.999999747378752e-05\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0964 - custom_f1: 0.9805 - val_loss: 10.4969 - val_custom_f1: 0.0000e+00\n",
            "Epoch 17: lr: 9.999999747378752e-05\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0820 - custom_f1: 0.9804 - val_loss: 5.4735 - val_custom_f1: 0.0000e+00\n",
            "Epoch 18: lr: 9.999999747378752e-05\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1932 - custom_f1: 0.9453 - val_loss: 1.6552 - val_custom_f1: 0.2870\n",
            "Epoch 19: lr: 9.999999747378752e-05\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0961 - custom_f1: 0.9695 - val_loss: 5.1070 - val_custom_f1: 0.0000e+00\n",
            "Epoch 20: lr: 9.999999747378752e-05\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1131 - custom_f1: 0.9722 - val_loss: 33.1952 - val_custom_f1: 0.7962\n",
            "Epoch 21: lr: 9.999999747378752e-05\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0612 - custom_f1: 0.9881 - val_loss: 6.2104 - val_custom_f1: 0.0000e+00\n",
            "Epoch 22: lr: 9.999999747378752e-05\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0852 - custom_f1: 0.9793\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.0852 - custom_f1: 0.9793 - val_loss: 0.1536 - val_custom_f1: 0.9419\n",
            "Epoch 23: lr: 9.999999747378752e-05\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0852 - custom_f1: 0.9788 - val_loss: 5.6562 - val_custom_f1: 0.0000e+00\n",
            "Epoch 24: lr: 9.999999747378752e-05\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0723 - custom_f1: 0.9810 - val_loss: 23.2456 - val_custom_f1: 0.7962\n",
            "Epoch 25: lr: 9.999999747378752e-05\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0264 - custom_f1: 0.9982 - val_loss: 38.1624 - val_custom_f1: 0.7962\n",
            "Epoch 26: lr: 9.999999747378752e-05\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0459 - custom_f1: 0.9906 - val_loss: 23.8075 - val_custom_f1: 0.7962\n",
            "Epoch 27: lr: 9.999999747378752e-05\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1307 - custom_f1: 0.9696 - val_loss: 28.5218 - val_custom_f1: 0.7962\n",
            "Epoch 28: lr: 9.999999747378752e-05\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0708 - custom_f1: 0.9799 - val_loss: 9.4612 - val_custom_f1: 0.0000e+00\n",
            "Epoch 29: lr: 9.999999747378752e-05\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0717 - custom_f1: 0.9738 - val_loss: 20.8746 - val_custom_f1: 0.7962\n",
            "Epoch 30: lr: 9.999999747378752e-05\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1480 - custom_f1: 0.9658 - val_loss: 0.2564 - val_custom_f1: 0.9390\n",
            "Epoch 31: lr: 9.999999747378752e-05\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1247 - custom_f1: 0.9671 - val_loss: 0.9628 - val_custom_f1: 0.8256\n",
            "Epoch 32: lr: 9.999999747378752e-05\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0479 - custom_f1: 0.9881 - val_loss: 19.5643 - val_custom_f1: 0.0000e+00\n",
            "Epoch 33: lr: 9.999999747378752e-05\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0804 - custom_f1: 0.9823 - val_loss: 40.8125 - val_custom_f1: 0.7962\n",
            "Epoch 34: lr: 9.999999747378752e-05\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0733 - custom_f1: 0.9794 - val_loss: 1.4011 - val_custom_f1: 0.8038\n",
            "Epoch 35: lr: 9.999999747378752e-05\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1389 - custom_f1: 0.9571 - val_loss: 6.8754 - val_custom_f1: 0.0000e+00\n",
            "Epoch 36: lr: 9.999999747378752e-05\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1002 - custom_f1: 0.9778 - val_loss: 0.2661 - val_custom_f1: 0.9324\n",
            "Epoch 37: lr: 9.999999747378752e-05\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0657 - custom_f1: 0.9822 - val_loss: 5.7040 - val_custom_f1: 0.7962\n",
            "Epoch 38: lr: 9.999999747378752e-05\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0972 - custom_f1: 0.9762 - val_loss: 0.6863 - val_custom_f1: 0.8733\n",
            "Epoch 39: lr: 9.999999747378752e-05\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0171 - custom_f1: 0.9971 - val_loss: 4.0116 - val_custom_f1: 0.1224\n",
            "Epoch 40: lr: 9.999999747378752e-05\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0378 - custom_f1: 0.9912 - val_loss: 2.3527 - val_custom_f1: 0.3370\n",
            "Epoch 41: lr: 9.999999747378752e-05\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0063 - custom_f1: 1.0000\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.0063 - custom_f1: 1.0000 - val_loss: 0.1353 - val_custom_f1: 0.9615\n",
            "Epoch 42: lr: 9.999999747378752e-05\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0032 - custom_f1: 1.0000\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 13s 111ms/step - loss: 0.0032 - custom_f1: 1.0000 - val_loss: 0.1248 - val_custom_f1: 0.9573\n",
            "Epoch 43: lr: 9.999999747378752e-05\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1185 - custom_f1: 0.9692 - val_loss: 6.8983 - val_custom_f1: 0.0000e+00\n",
            "Epoch 44: lr: 9.999999747378752e-05\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0308 - custom_f1: 0.9958 - val_loss: 8.6414 - val_custom_f1: 0.8118\n",
            "Epoch 45: lr: 9.999999747378752e-05\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0295 - custom_f1: 0.9922 - val_loss: 8.7147 - val_custom_f1: 0.0000e+00\n",
            "Epoch 46: lr: 9.999999747378752e-05\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0713 - custom_f1: 0.9804 - val_loss: 22.4759 - val_custom_f1: 0.7962\n",
            "Epoch 47: lr: 9.999999747378752e-05\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0417 - custom_f1: 0.9912 - val_loss: 2.8140 - val_custom_f1: 0.2298\n",
            "Epoch 48: lr: 9.999999747378752e-05\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0369 - custom_f1: 0.9912 - val_loss: 6.2675 - val_custom_f1: 0.0000e+00\n",
            "Epoch 49: lr: 9.999999747378752e-05\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0098 - custom_f1: 1.0000 - val_loss: 0.1320 - val_custom_f1: 0.9773\n",
            "Epoch 50: lr: 9.999999747378752e-05\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0370 - custom_f1: 0.9899 - val_loss: 0.4065 - val_custom_f1: 0.8452\n",
            "Epoch 51: lr: 9.999999747378752e-05\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0571 - custom_f1: 0.9863\n",
            "lr is fixed to 9.999999747378752e-06\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0571 - custom_f1: 0.9863 - val_loss: 21.6415 - val_custom_f1: 0.0000e+00\n",
            "Epoch 52: lr: 9.999999747378752e-06\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0601 - custom_f1: 0.9934 - val_loss: 0.1743 - val_custom_f1: 0.9573\n",
            "Epoch 53: lr: 9.999999747378752e-06\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0586 - custom_f1: 0.9829 - val_loss: 0.7329 - val_custom_f1: 0.8562\n",
            "Epoch 54: lr: 9.999999747378752e-06\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0635 - custom_f1: 0.9823 - val_loss: 0.2042 - val_custom_f1: 0.9573\n",
            "Epoch 55: lr: 9.999999747378752e-06\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0892 - custom_f1: 0.9705 - val_loss: 0.1485 - val_custom_f1: 0.9573\n",
            "Epoch 56: lr: 9.999999747378752e-06\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0392 - custom_f1: 0.9894\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 109ms/step - loss: 0.0392 - custom_f1: 0.9894 - val_loss: 0.1240 - val_custom_f1: 0.9573\n",
            "Epoch 57: lr: 9.999999747378752e-06\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0351 - custom_f1: 0.9894\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.0351 - custom_f1: 0.9894 - val_loss: 0.1026 - val_custom_f1: 0.9684\n",
            "Epoch 58: lr: 9.999999747378752e-06\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0058 - custom_f1: 1.0000\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 13s 111ms/step - loss: 0.0058 - custom_f1: 1.0000 - val_loss: 0.0878 - val_custom_f1: 0.9684\n",
            "Epoch 59: lr: 9.999999747378752e-06\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0543 - custom_f1: 0.9823 - val_loss: 0.0939 - val_custom_f1: 0.9684\n",
            "Epoch 60: lr: 9.999999747378752e-06\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0507 - custom_f1: 0.9823 - val_loss: 0.1077 - val_custom_f1: 0.9573\n",
            "Epoch 61: lr: 9.999999747378752e-06\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0436 - custom_f1: 0.9823\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 109ms/step - loss: 0.0436 - custom_f1: 0.9823 - val_loss: 0.0772 - val_custom_f1: 0.9884\n",
            "Epoch 62: lr: 9.999999747378752e-06\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0068 - custom_f1: 1.0000\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 105ms/step - loss: 0.0068 - custom_f1: 1.0000 - val_loss: 0.0743 - val_custom_f1: 0.9884\n",
            "Epoch 63: lr: 9.999999747378752e-06\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0066 - custom_f1: 1.0000\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 105ms/step - loss: 0.0066 - custom_f1: 1.0000 - val_loss: 0.0642 - val_custom_f1: 0.9884\n",
            "Epoch 64: lr: 9.999999747378752e-06\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0282 - custom_f1: 0.9912 - val_loss: 0.0776 - val_custom_f1: 0.9684\n",
            "Epoch 65: lr: 9.999999747378752e-06\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0499 - custom_f1: 0.9805 - val_loss: 0.0687 - val_custom_f1: 0.9884\n",
            "Epoch 66: lr: 9.999999747378752e-06\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0066 - custom_f1: 1.0000 - val_loss: 0.2653 - val_custom_f1: 0.9268\n",
            "Epoch 67: lr: 9.999999747378752e-06\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0395 - custom_f1: 0.9823\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.0395 - custom_f1: 0.9823 - val_loss: 0.0417 - val_custom_f1: 0.9884\n",
            "Epoch 68: lr: 9.999999747378752e-06\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0391 - custom_f1: 0.9823 - val_loss: 0.0594 - val_custom_f1: 0.9884\n",
            "Epoch 69: lr: 9.999999747378752e-06\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0207 - custom_f1: 0.9912\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 13s 111ms/step - loss: 0.0207 - custom_f1: 0.9912 - val_loss: 0.0362 - val_custom_f1: 1.0000\n",
            "Epoch 70: lr: 9.999999747378752e-06\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0192 - custom_f1: 0.9912 - val_loss: 0.0406 - val_custom_f1: 0.9884\n",
            "Epoch 71: lr: 9.999999747378752e-06\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0216 - custom_f1: 0.9912 - val_loss: 0.0958 - val_custom_f1: 0.9684\n",
            "Epoch 72: lr: 9.999999747378752e-06\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0056 - custom_f1: 1.0000 - val_loss: 0.0441 - val_custom_f1: 0.9884\n",
            "Epoch 73: lr: 9.999999747378752e-06\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0424 - custom_f1: 0.9735 - val_loss: 0.0756 - val_custom_f1: 0.9884\n",
            "Epoch 74: lr: 9.999999747378752e-06\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0446 - custom_f1: 0.9646 - val_loss: 0.0468 - val_custom_f1: 1.0000\n",
            "Epoch 75: lr: 9.999999747378752e-06\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0157 - custom_f1: 0.9912 - val_loss: 0.0480 - val_custom_f1: 0.9884\n",
            "Epoch 76: lr: 9.999999747378752e-06\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0291 - custom_f1: 0.9823 - val_loss: 0.0524 - val_custom_f1: 1.0000\n",
            "Epoch 77: lr: 9.999999747378752e-06\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0115 - custom_f1: 0.9912 - val_loss: 0.0496 - val_custom_f1: 0.9884\n",
            "Epoch 78: lr: 9.999999747378752e-06\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0216 - custom_f1: 0.9912 - val_loss: 0.0459 - val_custom_f1: 1.0000\n",
            "Epoch 79: lr: 9.999999747378752e-06\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0044 - custom_f1: 1.0000 - val_loss: 0.0489 - val_custom_f1: 0.9884\n",
            "Epoch 80: lr: 9.999999747378752e-06\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0422 - custom_f1: 0.9558 - val_loss: 0.0496 - val_custom_f1: 1.0000\n",
            "Epoch 81: lr: 9.999999747378752e-06\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0095 - custom_f1: 0.9912 - val_loss: 0.0641 - val_custom_f1: 0.9773\n",
            "Epoch 82: lr: 9.999999747378752e-06\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0093 - custom_f1: 0.9912 - val_loss: 0.0678 - val_custom_f1: 0.9773\n",
            "Epoch 83: lr: 9.999999747378752e-06\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0158 - custom_f1: 0.9823 - val_loss: 0.0418 - val_custom_f1: 1.0000\n",
            "Epoch 84: lr: 9.999999747378752e-06\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0129 - custom_f1: 0.9735 - val_loss: 0.0391 - val_custom_f1: 0.9884\n",
            "Epoch 85: lr: 9.999999747378752e-06\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0035 - custom_f1: 1.0000 - val_loss: 0.0476 - val_custom_f1: 0.9884\n",
            "Epoch 86: lr: 9.999999747378752e-06\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0062 - custom_f1: 0.9912 - val_loss: 0.0543 - val_custom_f1: 0.9884\n",
            "Epoch 87: lr: 9.999999747378752e-06\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0095 - custom_f1: 0.9823 - val_loss: 0.5281 - val_custom_f1: 0.8733\n",
            "Epoch 88: lr: 9.999999747378752e-06\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0293 - custom_f1: 0.9735 - val_loss: 0.0784 - val_custom_f1: 0.9878\n",
            "Epoch 89: lr: 9.999999747378752e-06\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0033 - custom_f1: 1.0000 - val_loss: 0.0434 - val_custom_f1: 0.9884\n",
            "Epoch 90: lr: 9.999999747378752e-06\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0097 - custom_f1: 0.9735\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 109ms/step - loss: 0.0097 - custom_f1: 0.9735 - val_loss: 0.0260 - val_custom_f1: 1.0000\n",
            "Epoch 91: lr: 9.999999747378752e-06\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0051 - custom_f1: 0.9912 - val_loss: 0.0285 - val_custom_f1: 1.0000\n",
            "Epoch 92: lr: 9.999999747378752e-06\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0096 - custom_f1: 0.9735 - val_loss: 0.0548 - val_custom_f1: 0.9884\n",
            "Epoch 93: lr: 9.999999747378752e-06\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0025 - custom_f1: 1.0000 - val_loss: 0.0301 - val_custom_f1: 1.0000\n",
            "Epoch 94: lr: 9.999999747378752e-06\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0066 - custom_f1: 0.9823 - val_loss: 0.0329 - val_custom_f1: 1.0000\n",
            "Epoch 95: lr: 9.999999747378752e-06\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0082 - custom_f1: 0.9646 - val_loss: 0.0366 - val_custom_f1: 0.9884\n",
            "Epoch 96: lr: 9.999999747378752e-06\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0062 - custom_f1: 0.9912 - val_loss: 1.0311 - val_custom_f1: 0.8256\n",
            "Epoch 97: lr: 9.999999747378752e-06\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0089 - custom_f1: 0.9735 - val_loss: 0.0366 - val_custom_f1: 1.0000\n",
            "Epoch 98: lr: 9.999999747378752e-06\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0056 - custom_f1: 0.9823 - val_loss: 0.0419 - val_custom_f1: 1.0000\n",
            "Epoch 99: lr: 9.999999747378752e-06\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0078 - custom_f1: 0.9912 - val_loss: 0.0555 - val_custom_f1: 1.0000\n",
            "Epoch 100: lr: 9.999999747378752e-06\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0045 - custom_f1: 0.9823 - val_loss: 0.0334 - val_custom_f1: 1.0000\n",
            "weights are setted to best weights (epochs 90)\n",
            "fold 4 [150,200]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.6414 - custom_f1: 0.7609\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 106ms/step - loss: 0.6414 - custom_f1: 0.7609 - val_loss: 26.7602 - val_custom_f1: 0.0000e+00\n",
            "Epoch 2: lr: 9.999999747378752e-05\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.5870 - custom_f1: 0.7812\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.5870 - custom_f1: 0.7812 - val_loss: 1.1311 - val_custom_f1: 0.0000e+00\n",
            "Epoch 3: lr: 9.999999747378752e-05\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.5180 - custom_f1: 0.8158 - val_loss: 18.3497 - val_custom_f1: 0.0000e+00\n",
            "Epoch 4: lr: 9.999999747378752e-05\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.4894 - custom_f1: 0.8193 - val_loss: 6.1905 - val_custom_f1: 0.8780\n",
            "Epoch 5: lr: 9.999999747378752e-05\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.4016 - custom_f1: 0.8765\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.4016 - custom_f1: 0.8765 - val_loss: 0.6253 - val_custom_f1: 0.8780\n",
            "Epoch 6: lr: 9.999999747378752e-05\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.2929 - custom_f1: 0.8954 - val_loss: 5.4424 - val_custom_f1: 0.0000e+00\n",
            "Epoch 7: lr: 9.999999747378752e-05\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.3201 - custom_f1: 0.8886 - val_loss: 3.4029 - val_custom_f1: 0.0000e+00\n",
            "Epoch 8: lr: 9.999999747378752e-05\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.2105 - custom_f1: 0.9319 - val_loss: 9.6526 - val_custom_f1: 0.8780\n",
            "Epoch 9: lr: 9.999999747378752e-05\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1264 - custom_f1: 0.9558 - val_loss: 1.7756 - val_custom_f1: 0.0000e+00\n",
            "Epoch 10: lr: 9.999999747378752e-05\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1972 - custom_f1: 0.9371 - val_loss: 67.6783 - val_custom_f1: 0.8780\n",
            "Epoch 11: lr: 9.999999747378752e-05\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1620 - custom_f1: 0.9585\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 109ms/step - loss: 0.1620 - custom_f1: 0.9585 - val_loss: 0.5061 - val_custom_f1: 0.8100\n",
            "Epoch 12: lr: 9.999999747378752e-05\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1838 - custom_f1: 0.9370 - val_loss: 45.2074 - val_custom_f1: 0.8780\n",
            "Epoch 13: lr: 9.999999747378752e-05\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1707 - custom_f1: 0.9531\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.1707 - custom_f1: 0.9531 - val_loss: 0.2154 - val_custom_f1: 0.9333\n",
            "Epoch 14: lr: 9.999999747378752e-05\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0948 - custom_f1: 0.9739 - val_loss: 5.5015 - val_custom_f1: 0.0000e+00\n",
            "Epoch 15: lr: 9.999999747378752e-05\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0871 - custom_f1: 0.9810 - val_loss: 1.0912 - val_custom_f1: 0.6270\n",
            "Epoch 16: lr: 9.999999747378752e-05\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0935 - custom_f1: 0.9735 - val_loss: 11.2253 - val_custom_f1: 0.0000e+00\n",
            "Epoch 17: lr: 9.999999747378752e-05\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0397 - custom_f1: 0.9912 - val_loss: 7.2685 - val_custom_f1: 0.8937\n",
            "Epoch 18: lr: 9.999999747378752e-05\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0676 - custom_f1: 0.9794\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 13s 111ms/step - loss: 0.0676 - custom_f1: 0.9794 - val_loss: 0.1208 - val_custom_f1: 0.9728\n",
            "Epoch 19: lr: 9.999999747378752e-05\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0446 - custom_f1: 0.9912 - val_loss: 0.5049 - val_custom_f1: 0.8645\n",
            "Epoch 20: lr: 9.999999747378752e-05\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0386 - custom_f1: 0.9912 - val_loss: 0.1834 - val_custom_f1: 0.9631\n",
            "Epoch 21: lr: 9.999999747378752e-05\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0076 - custom_f1: 1.0000 - val_loss: 0.2220 - val_custom_f1: 0.9387\n",
            "Epoch 22: lr: 9.999999747378752e-05\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0382 - custom_f1: 0.9912 - val_loss: 0.1682 - val_custom_f1: 0.9631\n",
            "Epoch 23: lr: 9.999999747378752e-05\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0392 - custom_f1: 0.9912 - val_loss: 0.1458 - val_custom_f1: 0.9611\n",
            "Epoch 24: lr: 9.999999747378752e-05\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0667 - custom_f1: 0.9823 - val_loss: 3.8552 - val_custom_f1: 0.0000e+00\n",
            "Epoch 25: lr: 9.999999747378752e-05\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0570 - custom_f1: 0.9823 - val_loss: 0.4096 - val_custom_f1: 0.9106\n",
            "Epoch 26: lr: 9.999999747378752e-05\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0091 - custom_f1: 1.0000\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 109ms/step - loss: 0.0091 - custom_f1: 1.0000 - val_loss: 0.0788 - val_custom_f1: 0.9728\n",
            "Epoch 27: lr: 9.999999747378752e-05\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0057 - custom_f1: 1.0000 - val_loss: 0.1532 - val_custom_f1: 0.9488\n",
            "Epoch 28: lr: 9.999999747378752e-05\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1541 - custom_f1: 0.9469 - val_loss: 1.1663 - val_custom_f1: 0.6781\n",
            "Epoch 29: lr: 9.999999747378752e-05\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0605 - custom_f1: 0.9823 - val_loss: 0.5189 - val_custom_f1: 0.9196\n",
            "Epoch 30: lr: 9.999999747378752e-05\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0575 - custom_f1: 0.9823 - val_loss: 8.4740 - val_custom_f1: 0.0000e+00\n",
            "Epoch 31: lr: 9.999999747378752e-05\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0423 - custom_f1: 0.9912 - val_loss: 1.0731 - val_custom_f1: 0.9106\n",
            "Epoch 32: lr: 9.999999747378752e-05\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0632 - custom_f1: 0.9823 - val_loss: 3.3344 - val_custom_f1: 0.9020\n",
            "Epoch 33: lr: 9.999999747378752e-05\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0610 - custom_f1: 0.9823 - val_loss: 1.9018 - val_custom_f1: 0.9020\n",
            "Epoch 34: lr: 9.999999747378752e-05\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.2801 - custom_f1: 0.9183 - val_loss: 7.1274 - val_custom_f1: 0.0000e+00\n",
            "Epoch 35: lr: 9.999999747378752e-05\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.3648 - custom_f1: 0.8571 - val_loss: 17.1550 - val_custom_f1: 0.8780\n",
            "Epoch 36: lr: 9.999999747378752e-05\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.2259 - custom_f1: 0.9344 - val_loss: 0.2020 - val_custom_f1: 0.9432\n",
            "Epoch 37: lr: 9.999999747378752e-05\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0846 - custom_f1: 0.9816 - val_loss: 5.6828 - val_custom_f1: 0.0000e+00\n",
            "Epoch 38: lr: 9.999999747378752e-05\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1588 - custom_f1: 0.9517 - val_loss: 7.3327 - val_custom_f1: 0.0000e+00\n",
            "Epoch 39: lr: 9.999999747378752e-05\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0564 - custom_f1: 0.9914 - val_loss: 28.7356 - val_custom_f1: 0.8780\n",
            "Epoch 40: lr: 9.999999747378752e-05\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1074 - custom_f1: 0.9767 - val_loss: 0.4799 - val_custom_f1: 0.8205\n",
            "Epoch 41: lr: 9.999999747378752e-05\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0846 - custom_f1: 0.9798 - val_loss: 0.1684 - val_custom_f1: 0.9621\n",
            "Epoch 42: lr: 9.999999747378752e-05\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1385 - custom_f1: 0.9671 - val_loss: 4.3306 - val_custom_f1: 0.0435\n",
            "Epoch 43: lr: 9.999999747378752e-05\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0892 - custom_f1: 0.9767 - val_loss: 4.8116 - val_custom_f1: 0.0000e+00\n",
            "Epoch 44: lr: 9.999999747378752e-05\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0804 - custom_f1: 0.9822 - val_loss: 0.2893 - val_custom_f1: 0.9248\n",
            "Epoch 45: lr: 9.999999747378752e-05\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1252 - custom_f1: 0.9751 - val_loss: 57.6605 - val_custom_f1: 0.8780\n",
            "Epoch 46: lr: 9.999999747378752e-05\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1062 - custom_f1: 0.9751 - val_loss: 1.2259 - val_custom_f1: 0.5333\n",
            "Epoch 47: lr: 9.999999747378752e-05\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1442 - custom_f1: 0.9622 - val_loss: 7.4631 - val_custom_f1: 0.8857\n",
            "Epoch 48: lr: 9.999999747378752e-05\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0505 - custom_f1: 0.9912 - val_loss: 0.2565 - val_custom_f1: 0.9550\n",
            "Epoch 49: lr: 9.999999747378752e-05\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0688 - custom_f1: 0.9823 - val_loss: 0.2350 - val_custom_f1: 0.9550\n",
            "Epoch 50: lr: 9.999999747378752e-05\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.1334 - custom_f1: 0.9469 - val_loss: 0.1759 - val_custom_f1: 0.9583\n",
            "Epoch 51: lr: 9.999999747378752e-05\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0733 - custom_f1: 0.9805\n",
            "lr is fixed to 9.999999747378752e-06\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0733 - custom_f1: 0.9805 - val_loss: 0.3229 - val_custom_f1: 0.9248\n",
            "Epoch 52: lr: 9.999999747378752e-06\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0822 - custom_f1: 0.9646 - val_loss: 0.1190 - val_custom_f1: 0.9667\n",
            "Epoch 53: lr: 9.999999747378752e-06\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0450 - custom_f1: 0.9823 - val_loss: 0.0841 - val_custom_f1: 0.9667\n",
            "Epoch 54: lr: 9.999999747378752e-06\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0260 - custom_f1: 0.9947 - val_loss: 0.0895 - val_custom_f1: 0.9728\n",
            "Epoch 55: lr: 9.999999747378752e-06\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0810 - custom_f1: 0.9646 - val_loss: 0.1483 - val_custom_f1: 0.9667\n",
            "Epoch 56: lr: 9.999999747378752e-06\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0395 - custom_f1: 0.9823 - val_loss: 0.0929 - val_custom_f1: 0.9839\n",
            "Epoch 57: lr: 9.999999747378752e-06\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0481 - custom_f1: 0.9823 - val_loss: 0.1251 - val_custom_f1: 0.9667\n",
            "Epoch 58: lr: 9.999999747378752e-06\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0523 - custom_f1: 0.9735 - val_loss: 0.0848 - val_custom_f1: 0.9728\n",
            "Epoch 59: lr: 9.999999747378752e-06\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0406 - custom_f1: 0.9823 - val_loss: 0.0854 - val_custom_f1: 0.9728\n",
            "Epoch 60: lr: 9.999999747378752e-06\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0556 - custom_f1: 0.9735 - val_loss: 0.1426 - val_custom_f1: 0.9667\n",
            "Epoch 61: lr: 9.999999747378752e-06\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0152 - custom_f1: 1.0000 - val_loss: 0.0888 - val_custom_f1: 0.9728\n",
            "Epoch 62: lr: 9.999999747378752e-06\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0490 - custom_f1: 0.9646 - val_loss: 0.0823 - val_custom_f1: 0.9728\n",
            "Epoch 63: lr: 9.999999747378752e-06\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0382 - custom_f1: 0.9735 - val_loss: 0.0904 - val_custom_f1: 0.9839\n",
            "Epoch 64: lr: 9.999999747378752e-06\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0198 - custom_f1: 0.9912 - val_loss: 0.0926 - val_custom_f1: 0.9839\n",
            "Epoch 65: lr: 9.999999747378752e-06\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0403 - custom_f1: 0.9735 - val_loss: 0.0989 - val_custom_f1: 0.9667\n",
            "Epoch 66: lr: 9.999999747378752e-06\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0260 - custom_f1: 0.9823 - val_loss: 0.0899 - val_custom_f1: 0.9728\n",
            "Epoch 67: lr: 9.999999747378752e-06\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0279 - custom_f1: 0.9823 - val_loss: 0.0943 - val_custom_f1: 0.9667\n",
            "Epoch 68: lr: 9.999999747378752e-06\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0252 - custom_f1: 0.9823 - val_loss: 0.0957 - val_custom_f1: 0.9681\n",
            "Epoch 69: lr: 9.999999747378752e-06\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0385 - custom_f1: 0.9646 - val_loss: 0.1268 - val_custom_f1: 0.9667\n",
            "Epoch 70: lr: 9.999999747378752e-06\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0074 - custom_f1: 1.0000 - val_loss: 0.0865 - val_custom_f1: 0.9621\n",
            "Epoch 71: lr: 9.999999747378752e-06\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0066 - custom_f1: 1.0000 - val_loss: 0.0859 - val_custom_f1: 0.9783\n",
            "Epoch 72: lr: 9.999999747378752e-06\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0163 - custom_f1: 0.9912 - val_loss: 0.0935 - val_custom_f1: 0.9667\n",
            "Epoch 73: lr: 9.999999747378752e-06\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0197 - custom_f1: 0.9823 - val_loss: 0.0995 - val_custom_f1: 0.9667\n",
            "Epoch 74: lr: 9.999999747378752e-06\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0212 - custom_f1: 0.9823 - val_loss: 0.0849 - val_custom_f1: 0.9621\n",
            "Epoch 75: lr: 9.999999747378752e-06\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0114 - custom_f1: 0.9912 - val_loss: 0.1087 - val_custom_f1: 0.9667\n",
            "Epoch 76: lr: 9.999999747378752e-06\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0163 - custom_f1: 0.9823 - val_loss: 0.0897 - val_custom_f1: 0.9621\n",
            "Epoch 77: lr: 9.999999747378752e-06\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0168 - custom_f1: 0.9823 - val_loss: 0.0817 - val_custom_f1: 0.9839\n",
            "Epoch 78: lr: 9.999999747378752e-06\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0060 - custom_f1: 1.0000 - val_loss: 0.0865 - val_custom_f1: 0.9783\n",
            "Epoch 79: lr: 9.999999747378752e-06\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0373 - custom_f1: 0.9735 - val_loss: 0.1075 - val_custom_f1: 0.9667\n",
            "Epoch 80: lr: 9.999999747378752e-06\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0271 - custom_f1: 0.9558 - val_loss: 0.0894 - val_custom_f1: 0.9839\n",
            "Epoch 81: lr: 9.999999747378752e-06\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0117 - custom_f1: 0.9912\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 109ms/step - loss: 0.0117 - custom_f1: 0.9912 - val_loss: 0.0774 - val_custom_f1: 0.9681\n",
            "Epoch 82: lr: 9.999999747378752e-06\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0250 - custom_f1: 0.9823 - val_loss: 0.0888 - val_custom_f1: 0.9681\n",
            "Epoch 83: lr: 9.999999747378752e-06\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0122 - custom_f1: 0.9823 - val_loss: 0.0854 - val_custom_f1: 0.9783\n",
            "Epoch 84: lr: 9.999999747378752e-06\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0076 - custom_f1: 0.9912 - val_loss: 0.0797 - val_custom_f1: 0.9783\n",
            "Epoch 85: lr: 9.999999747378752e-06\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0122 - custom_f1: 0.9823 - val_loss: 0.0866 - val_custom_f1: 0.9667\n",
            "Epoch 86: lr: 9.999999747378752e-06\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0060 - custom_f1: 0.9912 - val_loss: 0.0783 - val_custom_f1: 0.9621\n",
            "Epoch 87: lr: 9.999999747378752e-06\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0036 - custom_f1: 1.0000 - val_loss: 0.0952 - val_custom_f1: 0.9681\n",
            "Epoch 88: lr: 9.999999747378752e-06\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0024 - custom_f1: 1.0000\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 109ms/step - loss: 0.0024 - custom_f1: 1.0000 - val_loss: 0.0767 - val_custom_f1: 0.9621\n",
            "Epoch 89: lr: 9.999999747378752e-06\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0136 - custom_f1: 0.9735 - val_loss: 0.1101 - val_custom_f1: 0.9681\n",
            "Epoch 90: lr: 9.999999747378752e-06\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0097 - custom_f1: 0.9823 - val_loss: 0.0786 - val_custom_f1: 0.9728\n",
            "Epoch 91: lr: 9.999999747378752e-06\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0121 - custom_f1: 0.9735 - val_loss: 0.0780 - val_custom_f1: 0.9667\n",
            "Epoch 92: lr: 9.999999747378752e-06\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0027 - custom_f1: 1.0000\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 13s 111ms/step - loss: 0.0027 - custom_f1: 1.0000 - val_loss: 0.0747 - val_custom_f1: 0.9621\n",
            "Epoch 93: lr: 9.999999747378752e-06\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0030 - custom_f1: 1.0000 - val_loss: 0.0749 - val_custom_f1: 0.9621\n",
            "Epoch 94: lr: 9.999999747378752e-06\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0089 - custom_f1: 0.9823 - val_loss: 0.1251 - val_custom_f1: 0.9667\n",
            "Epoch 95: lr: 9.999999747378752e-06\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0130 - custom_f1: 0.9646\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 13s 111ms/step - loss: 0.0130 - custom_f1: 0.9646 - val_loss: 0.0712 - val_custom_f1: 0.9839\n",
            "Epoch 96: lr: 9.999999747378752e-06\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0068 - custom_f1: 0.9823 - val_loss: 0.0981 - val_custom_f1: 0.9681\n",
            "Epoch 97: lr: 9.999999747378752e-06\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0062 - custom_f1: 0.9823 - val_loss: 0.0781 - val_custom_f1: 0.9839\n",
            "Epoch 98: lr: 9.999999747378752e-06\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0098 - custom_f1: 0.9735 - val_loss: 0.0789 - val_custom_f1: 0.9783\n",
            "Epoch 99: lr: 9.999999747378752e-06\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0040 - custom_f1: 0.9912 - val_loss: 0.0816 - val_custom_f1: 0.9728\n",
            "Epoch 100: lr: 9.999999747378752e-06\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0035 - custom_f1: 0.9912 - val_loss: 0.0733 - val_custom_f1: 0.9839\n",
            "weights are setted to best weights (epochs 95)\n",
            "fold 5 [200,250]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.6499 - custom_f1: 0.7625\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 106ms/step - loss: 0.6499 - custom_f1: 0.7625 - val_loss: 372.6860 - val_custom_f1: 0.0000e+00\n",
            "Epoch 2: lr: 9.999999747378752e-05\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.6056 - custom_f1: 0.7731\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 109ms/step - loss: 0.6056 - custom_f1: 0.7731 - val_loss: 3.3797 - val_custom_f1: 0.8386\n",
            "Epoch 3: lr: 9.999999747378752e-05\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.5363 - custom_f1: 0.7896 - val_loss: 219.2326 - val_custom_f1: 0.0000e+00\n",
            "Epoch 4: lr: 9.999999747378752e-05\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.4609 - custom_f1: 0.8327 - val_loss: 13.9074 - val_custom_f1: 0.8386\n",
            "Epoch 5: lr: 9.999999747378752e-05\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.4372 - custom_f1: 0.8338 - val_loss: 912.1156 - val_custom_f1: 0.0000e+00\n",
            "Epoch 6: lr: 9.999999747378752e-05\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.3532 - custom_f1: 0.8720 - val_loss: 3936.9443 - val_custom_f1: 0.0000e+00\n",
            "Epoch 7: lr: 9.999999747378752e-05\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.3494 - custom_f1: 0.8865 - val_loss: 23.9351 - val_custom_f1: 0.8386\n",
            "Epoch 8: lr: 9.999999747378752e-05\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.2638 - custom_f1: 0.9072\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 109ms/step - loss: 0.2638 - custom_f1: 0.9072 - val_loss: 0.9029 - val_custom_f1: 0.8831\n",
            "Epoch 9: lr: 9.999999747378752e-05\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1802 - custom_f1: 0.9462 - val_loss: 1.7867 - val_custom_f1: 0.1154\n",
            "Epoch 10: lr: 9.999999747378752e-05\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.2295 - custom_f1: 0.9321 - val_loss: 11.1597 - val_custom_f1: 0.0000e+00\n",
            "Epoch 11: lr: 9.999999747378752e-05\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1387 - custom_f1: 0.9592 - val_loss: 85.4399 - val_custom_f1: 0.8386\n",
            "Epoch 12: lr: 9.999999747378752e-05\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1654 - custom_f1: 0.9570\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.1654 - custom_f1: 0.9570 - val_loss: 0.3262 - val_custom_f1: 0.8973\n",
            "Epoch 13: lr: 9.999999747378752e-05\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.1192 - custom_f1: 0.9735 - val_loss: 0.4831 - val_custom_f1: 0.8831\n",
            "Epoch 14: lr: 9.999999747378752e-05\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1340 - custom_f1: 0.9637 - val_loss: 0.7923 - val_custom_f1: 0.6933\n",
            "Epoch 15: lr: 9.999999747378752e-05\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0630 - custom_f1: 0.9869 - val_loss: 1.0913 - val_custom_f1: 0.5758\n",
            "Epoch 16: lr: 9.999999747378752e-05\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0323 - custom_f1: 0.9958 - val_loss: 5.2428 - val_custom_f1: 0.0000e+00\n",
            "Epoch 17: lr: 9.999999747378752e-05\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0705 - custom_f1: 0.9858 - val_loss: 64.6531 - val_custom_f1: 0.8386\n",
            "Epoch 18: lr: 9.999999747378752e-05\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1620 - custom_f1: 0.9566 - val_loss: 19.6998 - val_custom_f1: 0.0000e+00\n",
            "Epoch 19: lr: 9.999999747378752e-05\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0570 - custom_f1: 0.9867 - val_loss: 12.5135 - val_custom_f1: 0.0000e+00\n",
            "Epoch 20: lr: 9.999999747378752e-05\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1680 - custom_f1: 0.9559 - val_loss: 42.1616 - val_custom_f1: 0.8386\n",
            "Epoch 21: lr: 9.999999747378752e-05\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1088 - custom_f1: 0.9624 - val_loss: 2.9506 - val_custom_f1: 0.2500\n",
            "Epoch 22: lr: 9.999999747378752e-05\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1184 - custom_f1: 0.9642 - val_loss: 60.1922 - val_custom_f1: 0.8386\n",
            "Epoch 23: lr: 9.999999747378752e-05\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0482 - custom_f1: 0.9912 - val_loss: 0.8038 - val_custom_f1: 0.8333\n",
            "Epoch 24: lr: 9.999999747378752e-05\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0706 - custom_f1: 0.9823 - val_loss: 0.4589 - val_custom_f1: 0.8814\n",
            "Epoch 25: lr: 9.999999747378752e-05\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1397 - custom_f1: 0.9558 - val_loss: 1.1249 - val_custom_f1: 0.7967\n",
            "Epoch 26: lr: 9.999999747378752e-05\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0455 - custom_f1: 0.9912 - val_loss: 17.7883 - val_custom_f1: 0.8386\n",
            "Epoch 27: lr: 9.999999747378752e-05\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0402 - custom_f1: 0.9912 - val_loss: 0.3933 - val_custom_f1: 0.9149\n",
            "Epoch 28: lr: 9.999999747378752e-05\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0858 - custom_f1: 0.9735 - val_loss: 82.7947 - val_custom_f1: 0.8386\n",
            "Epoch 29: lr: 9.999999747378752e-05\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0155 - custom_f1: 1.0000 - val_loss: 0.6151 - val_custom_f1: 0.8666\n",
            "Epoch 30: lr: 9.999999747378752e-05\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0441 - custom_f1: 0.9899 - val_loss: 9.5676 - val_custom_f1: 0.0000e+00\n",
            "Epoch 31: lr: 9.999999747378752e-05\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1914 - custom_f1: 0.9484 - val_loss: 5.2688 - val_custom_f1: 0.8386\n",
            "Epoch 32: lr: 9.999999747378752e-05\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1774 - custom_f1: 0.9470\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.1774 - custom_f1: 0.9470 - val_loss: 0.3106 - val_custom_f1: 0.9060\n",
            "Epoch 33: lr: 9.999999747378752e-05\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1277 - custom_f1: 0.9651 - val_loss: 1.1584 - val_custom_f1: 0.6577\n",
            "Epoch 34: lr: 9.999999747378752e-05\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1099 - custom_f1: 0.9690 - val_loss: 21.0713 - val_custom_f1: 0.8386\n",
            "Epoch 35: lr: 9.999999747378752e-05\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1344 - custom_f1: 0.9612 - val_loss: 0.4379 - val_custom_f1: 0.9060\n",
            "Epoch 36: lr: 9.999999747378752e-05\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1052 - custom_f1: 0.9708 - val_loss: 0.4320 - val_custom_f1: 0.9149\n",
            "Epoch 37: lr: 9.999999747378752e-05\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0295 - custom_f1: 0.9935 - val_loss: 0.4839 - val_custom_f1: 0.8973\n",
            "Epoch 38: lr: 9.999999747378752e-05\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0949 - custom_f1: 0.9775\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 109ms/step - loss: 0.0949 - custom_f1: 0.9775 - val_loss: 0.2887 - val_custom_f1: 0.9383\n",
            "Epoch 39: lr: 9.999999747378752e-05\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0685 - custom_f1: 0.9899\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 105ms/step - loss: 0.0685 - custom_f1: 0.9899 - val_loss: 0.2478 - val_custom_f1: 0.9600\n",
            "Epoch 40: lr: 9.999999747378752e-05\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0710 - custom_f1: 0.9805 - val_loss: 0.3066 - val_custom_f1: 0.9000\n",
            "Epoch 41: lr: 9.999999747378752e-05\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0523 - custom_f1: 0.9881 - val_loss: 1.8014 - val_custom_f1: 0.6184\n",
            "Epoch 42: lr: 9.999999747378752e-05\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0586 - custom_f1: 0.9876\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.0586 - custom_f1: 0.9876 - val_loss: 0.2393 - val_custom_f1: 0.9506\n",
            "Epoch 43: lr: 9.999999747378752e-05\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0537 - custom_f1: 0.9869 - val_loss: 2.7280 - val_custom_f1: 0.8683\n",
            "Epoch 44: lr: 9.999999747378752e-05\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0857 - custom_f1: 0.9708 - val_loss: 12.7675 - val_custom_f1: 0.0000e+00\n",
            "Epoch 45: lr: 9.999999747378752e-05\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1180 - custom_f1: 0.9757 - val_loss: 1.1043 - val_custom_f1: 0.7750\n",
            "Epoch 46: lr: 9.999999747378752e-05\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0539 - custom_f1: 0.9864 - val_loss: 15.0619 - val_custom_f1: 0.8386\n",
            "Epoch 47: lr: 9.999999747378752e-05\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0411 - custom_f1: 0.9912 - val_loss: 0.5652 - val_custom_f1: 0.8990\n",
            "Epoch 48: lr: 9.999999747378752e-05\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0493 - custom_f1: 0.9869 - val_loss: 0.3071 - val_custom_f1: 0.9060\n",
            "Epoch 49: lr: 9.999999747378752e-05\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0088 - custom_f1: 1.0000 - val_loss: 0.3385 - val_custom_f1: 0.9583\n",
            "Epoch 50: lr: 9.999999747378752e-05\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1148 - custom_f1: 0.9646 - val_loss: 0.7786 - val_custom_f1: 0.8604\n",
            "Epoch 51: lr: 9.999999747378752e-05\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0164 - custom_f1: 1.0000\n",
            "lr is fixed to 9.999999747378752e-06\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0164 - custom_f1: 1.0000 - val_loss: 0.3022 - val_custom_f1: 0.9383\n",
            "Epoch 52: lr: 9.999999747378752e-06\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0348 - custom_f1: 0.9912 - val_loss: 0.4054 - val_custom_f1: 0.9583\n",
            "Epoch 53: lr: 9.999999747378752e-06\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0602 - custom_f1: 0.9823 - val_loss: 0.3141 - val_custom_f1: 0.9383\n",
            "Epoch 54: lr: 9.999999747378752e-06\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0849 - custom_f1: 0.9735 - val_loss: 0.3073 - val_custom_f1: 0.9383\n",
            "Epoch 55: lr: 9.999999747378752e-06\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0310 - custom_f1: 0.9912 - val_loss: 0.4445 - val_custom_f1: 0.9574\n",
            "Epoch 56: lr: 9.999999747378752e-06\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0321 - custom_f1: 0.9912 - val_loss: 0.3703 - val_custom_f1: 0.9583\n",
            "Epoch 57: lr: 9.999999747378752e-06\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0574 - custom_f1: 0.9823 - val_loss: 0.3159 - val_custom_f1: 0.9383\n",
            "Epoch 58: lr: 9.999999747378752e-06\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0092 - custom_f1: 1.0000 - val_loss: 0.3791 - val_custom_f1: 0.9681\n",
            "Epoch 59: lr: 9.999999747378752e-06\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0542 - custom_f1: 0.9823 - val_loss: 0.3863 - val_custom_f1: 0.9681\n",
            "Epoch 60: lr: 9.999999747378752e-06\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0542 - custom_f1: 0.9823 - val_loss: 0.3899 - val_custom_f1: 0.9681\n",
            "Epoch 61: lr: 9.999999747378752e-06\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0332 - custom_f1: 0.9912 - val_loss: 0.3549 - val_custom_f1: 0.9583\n",
            "Epoch 62: lr: 9.999999747378752e-06\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0080 - custom_f1: 1.0000 - val_loss: 0.3269 - val_custom_f1: 0.9383\n",
            "Epoch 63: lr: 9.999999747378752e-06\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0288 - custom_f1: 0.9912 - val_loss: 0.3396 - val_custom_f1: 0.9383\n",
            "Epoch 64: lr: 9.999999747378752e-06\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0073 - custom_f1: 1.0000 - val_loss: 0.3543 - val_custom_f1: 0.9383\n",
            "Epoch 65: lr: 9.999999747378752e-06\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0290 - custom_f1: 0.9912 - val_loss: 0.3675 - val_custom_f1: 0.9383\n",
            "Epoch 66: lr: 9.999999747378752e-06\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0320 - custom_f1: 0.9912 - val_loss: 0.3690 - val_custom_f1: 0.9383\n",
            "Epoch 67: lr: 9.999999747378752e-06\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0076 - custom_f1: 1.0000 - val_loss: 0.3873 - val_custom_f1: 0.9383\n",
            "Epoch 68: lr: 9.999999747378752e-06\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1002 - custom_f1: 0.9646 - val_loss: 0.4663 - val_custom_f1: 0.9443\n",
            "Epoch 69: lr: 9.999999747378752e-06\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0862 - custom_f1: 0.9646 - val_loss: 0.3499 - val_custom_f1: 0.9681\n",
            "Epoch 70: lr: 9.999999747378752e-06\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0096 - custom_f1: 1.0000 - val_loss: 0.3131 - val_custom_f1: 0.9383\n",
            "Epoch 71: lr: 9.999999747378752e-06\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0528 - custom_f1: 0.9823 - val_loss: 0.4041 - val_custom_f1: 0.9443\n",
            "Epoch 72: lr: 9.999999747378752e-06\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0097 - custom_f1: 1.0000 - val_loss: 0.3579 - val_custom_f1: 0.9383\n",
            "Epoch 73: lr: 9.999999747378752e-06\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0269 - custom_f1: 0.9912 - val_loss: 0.3203 - val_custom_f1: 0.9383\n",
            "Epoch 74: lr: 9.999999747378752e-06\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0673 - custom_f1: 0.9735 - val_loss: 0.4113 - val_custom_f1: 0.9681\n",
            "Epoch 75: lr: 9.999999747378752e-06\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0506 - custom_f1: 0.9823 - val_loss: 0.5099 - val_custom_f1: 0.9226\n",
            "Epoch 76: lr: 9.999999747378752e-06\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0547 - custom_f1: 0.9735 - val_loss: 0.2976 - val_custom_f1: 0.9506\n",
            "Epoch 77: lr: 9.999999747378752e-06\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0398 - custom_f1: 0.9823 - val_loss: 0.3121 - val_custom_f1: 0.9383\n",
            "Epoch 78: lr: 9.999999747378752e-06\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0427 - custom_f1: 0.9823 - val_loss: 0.3922 - val_custom_f1: 0.9443\n",
            "Epoch 79: lr: 9.999999747378752e-06\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0523 - custom_f1: 0.9735 - val_loss: 0.3162 - val_custom_f1: 0.9289\n",
            "Epoch 80: lr: 9.999999747378752e-06\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0437 - custom_f1: 0.9823 - val_loss: 0.3560 - val_custom_f1: 0.9345\n",
            "Epoch 81: lr: 9.999999747378752e-06\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0078 - custom_f1: 1.0000 - val_loss: 0.3564 - val_custom_f1: 0.9321\n",
            "Epoch 82: lr: 9.999999747378752e-06\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0204 - custom_f1: 0.9912 - val_loss: 0.4576 - val_custom_f1: 0.9443\n",
            "Epoch 83: lr: 9.999999747378752e-06\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0437 - custom_f1: 0.9735 - val_loss: 0.9995 - val_custom_f1: 0.8472\n",
            "Epoch 84: lr: 9.999999747378752e-06\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0206 - custom_f1: 0.9912 - val_loss: 0.4777 - val_custom_f1: 0.9226\n",
            "Epoch 85: lr: 9.999999747378752e-06\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0064 - custom_f1: 1.0000 - val_loss: 0.3737 - val_custom_f1: 0.9200\n",
            "Epoch 86: lr: 9.999999747378752e-06\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0359 - custom_f1: 0.9823 - val_loss: 0.5015 - val_custom_f1: 0.9148\n",
            "Epoch 87: lr: 9.999999747378752e-06\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0306 - custom_f1: 0.9735 - val_loss: 0.9781 - val_custom_f1: 0.8472\n",
            "Epoch 88: lr: 9.999999747378752e-06\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0128 - custom_f1: 0.9912 - val_loss: 0.3034 - val_custom_f1: 0.9200\n",
            "Epoch 89: lr: 9.999999747378752e-06\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0310 - custom_f1: 0.9912 - val_loss: 0.3569 - val_custom_f1: 0.9148\n",
            "Epoch 90: lr: 9.999999747378752e-06\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0192 - custom_f1: 0.9823 - val_loss: 0.3365 - val_custom_f1: 0.9148\n",
            "Epoch 91: lr: 9.999999747378752e-06\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0189 - custom_f1: 0.9823 - val_loss: 0.4043 - val_custom_f1: 0.9246\n",
            "Epoch 92: lr: 9.999999747378752e-06\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0142 - custom_f1: 0.9823 - val_loss: 0.3322 - val_custom_f1: 0.9321\n",
            "Epoch 93: lr: 9.999999747378752e-06\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0260 - custom_f1: 0.9735 - val_loss: 0.3464 - val_custom_f1: 0.9443\n",
            "Epoch 94: lr: 9.999999747378752e-06\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0066 - custom_f1: 1.0000 - val_loss: 0.3664 - val_custom_f1: 0.9200\n",
            "Epoch 95: lr: 9.999999747378752e-06\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0102 - custom_f1: 0.9912 - val_loss: 0.4083 - val_custom_f1: 0.9148\n",
            "Epoch 96: lr: 9.999999747378752e-06\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0185 - custom_f1: 0.9735 - val_loss: 0.3384 - val_custom_f1: 0.9321\n",
            "Epoch 97: lr: 9.999999747378752e-06\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0163 - custom_f1: 0.9735 - val_loss: 0.3132 - val_custom_f1: 0.9148\n",
            "Epoch 98: lr: 9.999999747378752e-06\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0042 - custom_f1: 1.0000 - val_loss: 0.3811 - val_custom_f1: 0.9148\n",
            "Epoch 99: lr: 9.999999747378752e-06\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0032 - custom_f1: 1.0000 - val_loss: 0.3664 - val_custom_f1: 0.9054\n",
            "Epoch 100: lr: 9.999999747378752e-06\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0117 - custom_f1: 0.9912 - val_loss: 0.3910 - val_custom_f1: 0.9106\n",
            "weights are setted to best weights (epochs 42)\n",
            "fold 6 [250,300]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.6493 - custom_f1: 0.7507\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 105ms/step - loss: 0.6493 - custom_f1: 0.7507 - val_loss: 0.7987 - val_custom_f1: 0.0000e+00\n",
            "Epoch 2: lr: 9.999999747378752e-05\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.6077 - custom_f1: 0.7659 - val_loss: 7.4846 - val_custom_f1: 0.0000e+00\n",
            "Epoch 3: lr: 9.999999747378752e-05\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.5639 - custom_f1: 0.7742 - val_loss: 5.6872 - val_custom_f1: 0.8580\n",
            "Epoch 4: lr: 9.999999747378752e-05\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.4730 - custom_f1: 0.8447 - val_loss: 22.8703 - val_custom_f1: 0.0000e+00\n",
            "Epoch 5: lr: 9.999999747378752e-05\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.3973 - custom_f1: 0.8668 - val_loss: 7.9896 - val_custom_f1: 0.8580\n",
            "Epoch 6: lr: 9.999999747378752e-05\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.3179 - custom_f1: 0.8970 - val_loss: 4.4953 - val_custom_f1: 0.0000e+00\n",
            "Epoch 7: lr: 9.999999747378752e-05\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.3064 - custom_f1: 0.8807 - val_loss: 3.3146 - val_custom_f1: 0.0000e+00\n",
            "Epoch 8: lr: 9.999999747378752e-05\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.2459 - custom_f1: 0.9190 - val_loss: 5.8886 - val_custom_f1: 0.0000e+00\n",
            "Epoch 9: lr: 9.999999747378752e-05\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1588 - custom_f1: 0.9517 - val_loss: 13.4075 - val_custom_f1: 0.8580\n",
            "Epoch 10: lr: 9.999999747378752e-05\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1806 - custom_f1: 0.9464 - val_loss: 2.4418 - val_custom_f1: 0.8580\n",
            "Epoch 11: lr: 9.999999747378752e-05\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1091 - custom_f1: 0.9710 - val_loss: 1.9285 - val_custom_f1: 0.8798\n",
            "Epoch 12: lr: 9.999999747378752e-05\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1442 - custom_f1: 0.9546 - val_loss: 6.7594 - val_custom_f1: 0.0000e+00\n",
            "Epoch 13: lr: 9.999999747378752e-05\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1422 - custom_f1: 0.9697 - val_loss: 2.6186 - val_custom_f1: 0.0385\n",
            "Epoch 14: lr: 9.999999747378752e-05\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1412 - custom_f1: 0.9663 - val_loss: 12.3223 - val_custom_f1: 0.0000e+00\n",
            "Epoch 15: lr: 9.999999747378752e-05\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0756 - custom_f1: 0.9861 - val_loss: 4.4210 - val_custom_f1: 0.0000e+00\n",
            "Epoch 16: lr: 9.999999747378752e-05\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1418 - custom_f1: 0.9604\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 109ms/step - loss: 0.1418 - custom_f1: 0.9604 - val_loss: 0.2342 - val_custom_f1: 0.9200\n",
            "Epoch 17: lr: 9.999999747378752e-05\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0273 - custom_f1: 0.9987\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 13s 111ms/step - loss: 0.0273 - custom_f1: 0.9987 - val_loss: 0.1980 - val_custom_f1: 0.9423\n",
            "Epoch 18: lr: 9.999999747378752e-05\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1051 - custom_f1: 0.9697 - val_loss: 2.5731 - val_custom_f1: 0.1099\n",
            "Epoch 19: lr: 9.999999747378752e-05\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0210 - custom_f1: 0.9971 - val_loss: 1.5215 - val_custom_f1: 0.8798\n",
            "Epoch 20: lr: 9.999999747378752e-05\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0779 - custom_f1: 0.9805 - val_loss: 27.1572 - val_custom_f1: 0.8580\n",
            "Epoch 21: lr: 9.999999747378752e-05\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0632 - custom_f1: 0.9827 - val_loss: 17.2915 - val_custom_f1: 0.8580\n",
            "Epoch 22: lr: 9.999999747378752e-05\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0761 - custom_f1: 0.9804 - val_loss: 20.5790 - val_custom_f1: 0.8580\n",
            "Epoch 23: lr: 9.999999747378752e-05\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.2780 - custom_f1: 0.9220 - val_loss: 4.4791 - val_custom_f1: 0.0000e+00\n",
            "Epoch 24: lr: 9.999999747378752e-05\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1566 - custom_f1: 0.9429 - val_loss: 3.3269 - val_custom_f1: 0.8580\n",
            "Epoch 25: lr: 9.999999747378752e-05\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1529 - custom_f1: 0.9567 - val_loss: 0.2288 - val_custom_f1: 0.9506\n",
            "Epoch 26: lr: 9.999999747378752e-05\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0235 - custom_f1: 0.9945 - val_loss: 0.3419 - val_custom_f1: 0.9112\n",
            "Epoch 27: lr: 9.999999747378752e-05\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0428 - custom_f1: 0.9912 - val_loss: 0.2116 - val_custom_f1: 0.9506\n",
            "Epoch 28: lr: 9.999999747378752e-05\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0614 - custom_f1: 0.9823 - val_loss: 0.2089 - val_custom_f1: 0.9528\n",
            "Epoch 29: lr: 9.999999747378752e-05\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0407 - custom_f1: 0.9912 - val_loss: 0.3677 - val_custom_f1: 0.9112\n",
            "Epoch 30: lr: 9.999999747378752e-05\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0074 - custom_f1: 1.0000\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.0074 - custom_f1: 1.0000 - val_loss: 0.1912 - val_custom_f1: 0.9506\n",
            "Epoch 31: lr: 9.999999747378752e-05\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0374 - custom_f1: 0.9912 - val_loss: 0.1933 - val_custom_f1: 0.9506\n",
            "Epoch 32: lr: 9.999999747378752e-05\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0639 - custom_f1: 0.9823 - val_loss: 0.2482 - val_custom_f1: 0.9532\n",
            "Epoch 33: lr: 9.999999747378752e-05\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1013 - custom_f1: 0.9687 - val_loss: 0.2859 - val_custom_f1: 0.9175\n",
            "Epoch 34: lr: 9.999999747378752e-05\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.2445 - custom_f1: 0.9206 - val_loss: 31.7643 - val_custom_f1: 0.8580\n",
            "Epoch 35: lr: 9.999999747378752e-05\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1806 - custom_f1: 0.9479 - val_loss: 0.7917 - val_custom_f1: 0.5131\n",
            "Epoch 36: lr: 9.999999747378752e-05\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0804 - custom_f1: 0.9786\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.0804 - custom_f1: 0.9786 - val_loss: 0.1784 - val_custom_f1: 0.9694\n",
            "Epoch 37: lr: 9.999999747378752e-05\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0948 - custom_f1: 0.9734 - val_loss: 6.6898 - val_custom_f1: 0.8580\n",
            "Epoch 38: lr: 9.999999747378752e-05\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0558 - custom_f1: 0.9863 - val_loss: 0.4644 - val_custom_f1: 0.9365\n",
            "Epoch 39: lr: 9.999999747378752e-05\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0518 - custom_f1: 0.9899 - val_loss: 0.2782 - val_custom_f1: 0.9258\n",
            "Epoch 40: lr: 9.999999747378752e-05\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0510 - custom_f1: 0.9894\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 13s 113ms/step - loss: 0.0510 - custom_f1: 0.9894 - val_loss: 0.1614 - val_custom_f1: 0.9494\n",
            "Epoch 41: lr: 9.999999747378752e-05\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0159 - custom_f1: 0.9987 - val_loss: 0.2750 - val_custom_f1: 0.9272\n",
            "Epoch 42: lr: 9.999999747378752e-05\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0866 - custom_f1: 0.9798 - val_loss: 1.6385 - val_custom_f1: 0.4288\n",
            "Epoch 43: lr: 9.999999747378752e-05\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0601 - custom_f1: 0.9852 - val_loss: 3.7129 - val_custom_f1: 0.0385\n",
            "Epoch 44: lr: 9.999999747378752e-05\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1020 - custom_f1: 0.9717 - val_loss: 0.4272 - val_custom_f1: 0.8963\n",
            "Epoch 45: lr: 9.999999747378752e-05\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0627 - custom_f1: 0.9823 - val_loss: 0.2582 - val_custom_f1: 0.9161\n",
            "Epoch 46: lr: 9.999999747378752e-05\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0608 - custom_f1: 0.9823 - val_loss: 0.2306 - val_custom_f1: 0.9105\n",
            "Epoch 47: lr: 9.999999747378752e-05\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0338 - custom_f1: 0.9912 - val_loss: 0.2723 - val_custom_f1: 0.9272\n",
            "Epoch 48: lr: 9.999999747378752e-05\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1078 - custom_f1: 0.9646 - val_loss: 3.8818 - val_custom_f1: 0.1455\n",
            "Epoch 49: lr: 9.999999747378752e-05\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0367 - custom_f1: 0.9912 - val_loss: 0.2112 - val_custom_f1: 0.9451\n",
            "Epoch 50: lr: 9.999999747378752e-05\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0651 - custom_f1: 0.9823 - val_loss: 1.8630 - val_custom_f1: 0.4965\n",
            "Epoch 51: lr: 9.999999747378752e-05\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0631 - custom_f1: 0.9810\n",
            "lr is fixed to 9.999999747378752e-06\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0631 - custom_f1: 0.9810 - val_loss: 1.8163 - val_custom_f1: 0.5000\n",
            "Epoch 52: lr: 9.999999747378752e-06\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0378 - custom_f1: 0.9881 - val_loss: 0.3136 - val_custom_f1: 0.9272\n",
            "Epoch 53: lr: 9.999999747378752e-06\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1155 - custom_f1: 0.9740 - val_loss: 0.3843 - val_custom_f1: 0.9112\n",
            "Epoch 54: lr: 9.999999747378752e-06\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.1060 - custom_f1: 0.9690 - val_loss: 0.2139 - val_custom_f1: 0.9451\n",
            "Epoch 55: lr: 9.999999747378752e-06\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0527 - custom_f1: 0.9823 - val_loss: 0.2732 - val_custom_f1: 0.9360\n",
            "Epoch 56: lr: 9.999999747378752e-06\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0499 - custom_f1: 0.9823 - val_loss: 0.2146 - val_custom_f1: 0.9451\n",
            "Epoch 57: lr: 9.999999747378752e-06\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0565 - custom_f1: 0.9858 - val_loss: 0.2884 - val_custom_f1: 0.9360\n",
            "Epoch 58: lr: 9.999999747378752e-06\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1085 - custom_f1: 0.9558 - val_loss: 0.2190 - val_custom_f1: 0.9451\n",
            "Epoch 59: lr: 9.999999747378752e-06\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0551 - custom_f1: 0.9858 - val_loss: 0.3434 - val_custom_f1: 0.9272\n",
            "Epoch 60: lr: 9.999999747378752e-06\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0803 - custom_f1: 0.9646 - val_loss: 0.3219 - val_custom_f1: 0.9272\n",
            "Epoch 61: lr: 9.999999747378752e-06\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0325 - custom_f1: 0.9912 - val_loss: 0.3225 - val_custom_f1: 0.9272\n",
            "Epoch 62: lr: 9.999999747378752e-06\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0458 - custom_f1: 0.9823 - val_loss: 0.2422 - val_custom_f1: 0.9360\n",
            "Epoch 63: lr: 9.999999747378752e-06\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0113 - custom_f1: 1.0000 - val_loss: 0.2872 - val_custom_f1: 0.9272\n",
            "Epoch 64: lr: 9.999999747378752e-06\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0257 - custom_f1: 0.9912 - val_loss: 0.2705 - val_custom_f1: 0.9360\n",
            "Epoch 65: lr: 9.999999747378752e-06\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0245 - custom_f1: 0.9912 - val_loss: 0.2658 - val_custom_f1: 0.9360\n",
            "Epoch 66: lr: 9.999999747378752e-06\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0308 - custom_f1: 0.9912 - val_loss: 0.3532 - val_custom_f1: 0.9360\n",
            "Epoch 67: lr: 9.999999747378752e-06\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0587 - custom_f1: 0.9722 - val_loss: 0.5254 - val_custom_f1: 0.8963\n",
            "Epoch 68: lr: 9.999999747378752e-06\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0594 - custom_f1: 0.9735 - val_loss: 0.3389 - val_custom_f1: 0.9272\n",
            "Epoch 69: lr: 9.999999747378752e-06\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0439 - custom_f1: 0.9823 - val_loss: 0.3052 - val_custom_f1: 0.9272\n",
            "Epoch 70: lr: 9.999999747378752e-06\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0265 - custom_f1: 0.9912 - val_loss: 0.1910 - val_custom_f1: 0.9545\n",
            "Epoch 71: lr: 9.999999747378752e-06\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0369 - custom_f1: 0.9823 - val_loss: 0.2400 - val_custom_f1: 0.9360\n",
            "Epoch 72: lr: 9.999999747378752e-06\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0357 - custom_f1: 0.9823 - val_loss: 0.4279 - val_custom_f1: 0.9112\n",
            "Epoch 73: lr: 9.999999747378752e-06\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0475 - custom_f1: 0.9735 - val_loss: 0.2971 - val_custom_f1: 0.9360\n",
            "Epoch 74: lr: 9.999999747378752e-06\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0237 - custom_f1: 0.9912 - val_loss: 0.2603 - val_custom_f1: 0.9360\n",
            "Epoch 75: lr: 9.999999747378752e-06\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0479 - custom_f1: 0.9735 - val_loss: 0.2519 - val_custom_f1: 0.9360\n",
            "Epoch 76: lr: 9.999999747378752e-06\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0215 - custom_f1: 0.9912 - val_loss: 0.3502 - val_custom_f1: 0.9360\n",
            "Epoch 77: lr: 9.999999747378752e-06\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0068 - custom_f1: 1.0000 - val_loss: 0.2827 - val_custom_f1: 0.9360\n",
            "Epoch 78: lr: 9.999999747378752e-06\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0371 - custom_f1: 0.9823 - val_loss: 0.2503 - val_custom_f1: 0.9360\n",
            "Epoch 79: lr: 9.999999747378752e-06\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0070 - custom_f1: 1.0000 - val_loss: 0.2847 - val_custom_f1: 0.9360\n",
            "Epoch 80: lr: 9.999999747378752e-06\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0050 - custom_f1: 1.0000 - val_loss: 0.3203 - val_custom_f1: 0.9360\n",
            "Epoch 81: lr: 9.999999747378752e-06\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0359 - custom_f1: 0.9735 - val_loss: 0.2119 - val_custom_f1: 0.9451\n",
            "Epoch 82: lr: 9.999999747378752e-06\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0338 - custom_f1: 0.9735 - val_loss: 0.2584 - val_custom_f1: 0.9451\n",
            "Epoch 83: lr: 9.999999747378752e-06\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0495 - custom_f1: 0.9558 - val_loss: 0.2205 - val_custom_f1: 0.9150\n",
            "Epoch 84: lr: 9.999999747378752e-06\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0073 - custom_f1: 1.0000 - val_loss: 0.3003 - val_custom_f1: 0.9360\n",
            "Epoch 85: lr: 9.999999747378752e-06\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0136 - custom_f1: 0.9912 - val_loss: 0.3195 - val_custom_f1: 0.9360\n",
            "Epoch 86: lr: 9.999999747378752e-06\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0170 - custom_f1: 0.9912 - val_loss: 0.2505 - val_custom_f1: 0.9451\n",
            "Epoch 87: lr: 9.999999747378752e-06\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0196 - custom_f1: 0.9823 - val_loss: 0.2197 - val_custom_f1: 0.9349\n",
            "Epoch 88: lr: 9.999999747378752e-06\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0138 - custom_f1: 0.9912 - val_loss: 0.4481 - val_custom_f1: 0.9272\n",
            "Epoch 89: lr: 9.999999747378752e-06\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0192 - custom_f1: 0.9823 - val_loss: 0.2664 - val_custom_f1: 0.9360\n",
            "Epoch 90: lr: 9.999999747378752e-06\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0148 - custom_f1: 0.9823 - val_loss: 0.2678 - val_custom_f1: 0.9360\n",
            "Epoch 91: lr: 9.999999747378752e-06\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0092 - custom_f1: 0.9912 - val_loss: 0.2635 - val_custom_f1: 0.9451\n",
            "Epoch 92: lr: 9.999999747378752e-06\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0093 - custom_f1: 0.9912 - val_loss: 0.3756 - val_custom_f1: 0.9360\n",
            "Epoch 93: lr: 9.999999747378752e-06\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0105 - custom_f1: 0.9912 - val_loss: 0.2625 - val_custom_f1: 0.9451\n",
            "Epoch 94: lr: 9.999999747378752e-06\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0127 - custom_f1: 0.9823 - val_loss: 0.2756 - val_custom_f1: 0.9360\n",
            "Epoch 95: lr: 9.999999747378752e-06\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0131 - custom_f1: 0.9823 - val_loss: 0.3207 - val_custom_f1: 0.9360\n",
            "Epoch 96: lr: 9.999999747378752e-06\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0037 - custom_f1: 1.0000 - val_loss: 0.2431 - val_custom_f1: 0.9451\n",
            "Epoch 97: lr: 9.999999747378752e-06\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0070 - custom_f1: 0.9912 - val_loss: 0.3906 - val_custom_f1: 0.8868\n",
            "Epoch 98: lr: 9.999999747378752e-06\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0127 - custom_f1: 0.9735 - val_loss: 0.3167 - val_custom_f1: 0.9360\n",
            "Epoch 99: lr: 9.999999747378752e-06\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0052 - custom_f1: 0.9912 - val_loss: 0.2947 - val_custom_f1: 0.9360\n",
            "Epoch 100: lr: 9.999999747378752e-06\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0062 - custom_f1: 0.9912 - val_loss: 0.3675 - val_custom_f1: 0.9360\n",
            "weights are setted to best weights (epochs 40)\n",
            "fold 7 [300,350]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.6358 - custom_f1: 0.7649\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 106ms/step - loss: 0.6358 - custom_f1: 0.7649 - val_loss: 9.5505 - val_custom_f1: 0.0000e+00\n",
            "Epoch 2: lr: 9.999999747378752e-05\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.5995 - custom_f1: 0.7732 - val_loss: 11.7621 - val_custom_f1: 0.0000e+00\n",
            "Epoch 3: lr: 9.999999747378752e-05\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.5354 - custom_f1: 0.7885\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.5354 - custom_f1: 0.7885 - val_loss: 1.5351 - val_custom_f1: 0.0000e+00\n",
            "Epoch 4: lr: 9.999999747378752e-05\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.5177 - custom_f1: 0.7967\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 13s 111ms/step - loss: 0.5177 - custom_f1: 0.7967 - val_loss: 1.3869 - val_custom_f1: 0.8156\n",
            "Epoch 5: lr: 9.999999747378752e-05\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.4530 - custom_f1: 0.8308 - val_loss: 2.3796 - val_custom_f1: 0.0000e+00\n",
            "Epoch 6: lr: 9.999999747378752e-05\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.3784 - custom_f1: 0.8787 - val_loss: 2.4242 - val_custom_f1: 0.8156\n",
            "Epoch 7: lr: 9.999999747378752e-05\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.3672 - custom_f1: 0.8729 - val_loss: 69.8191 - val_custom_f1: 0.8156\n",
            "Epoch 8: lr: 9.999999747378752e-05\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.2622 - custom_f1: 0.8954\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.2622 - custom_f1: 0.8954 - val_loss: 1.3636 - val_custom_f1: 0.8451\n",
            "Epoch 9: lr: 9.999999747378752e-05\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.3198 - custom_f1: 0.8821\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 13s 112ms/step - loss: 0.3198 - custom_f1: 0.8821 - val_loss: 0.3499 - val_custom_f1: 0.8763\n",
            "Epoch 10: lr: 9.999999747378752e-05\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.2270 - custom_f1: 0.9195 - val_loss: 58.4560 - val_custom_f1: 0.8156\n",
            "Epoch 11: lr: 9.999999747378752e-05\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.2967 - custom_f1: 0.9037 - val_loss: 1.7098 - val_custom_f1: 0.0000e+00\n",
            "Epoch 12: lr: 9.999999747378752e-05\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1651 - custom_f1: 0.9442 - val_loss: 5.0293 - val_custom_f1: 0.0000e+00\n",
            "Epoch 13: lr: 9.999999747378752e-05\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1344 - custom_f1: 0.9592 - val_loss: 18.9591 - val_custom_f1: 0.8156\n",
            "Epoch 14: lr: 9.999999747378752e-05\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1470 - custom_f1: 0.9581\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.1470 - custom_f1: 0.9581 - val_loss: 0.2037 - val_custom_f1: 0.9651\n",
            "Epoch 15: lr: 9.999999747378752e-05\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1134 - custom_f1: 0.9691 - val_loss: 3.5923 - val_custom_f1: 0.8451\n",
            "Epoch 16: lr: 9.999999747378752e-05\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0619 - custom_f1: 0.9852 - val_loss: 2.7135 - val_custom_f1: 0.0000e+00\n",
            "Epoch 17: lr: 9.999999747378752e-05\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0812 - custom_f1: 0.9810 - val_loss: 44.9496 - val_custom_f1: 0.8156\n",
            "Epoch 18: lr: 9.999999747378752e-05\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1429 - custom_f1: 0.9657 - val_loss: 0.3061 - val_custom_f1: 0.9208\n",
            "Epoch 19: lr: 9.999999747378752e-05\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0764 - custom_f1: 0.9822 - val_loss: 3.3479 - val_custom_f1: 0.0000e+00\n",
            "Epoch 20: lr: 9.999999747378752e-05\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1387 - custom_f1: 0.9618 - val_loss: 6.8622 - val_custom_f1: 0.8372\n",
            "Epoch 21: lr: 9.999999747378752e-05\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0577 - custom_f1: 0.9856 - val_loss: 0.6562 - val_custom_f1: 0.7528\n",
            "Epoch 22: lr: 9.999999747378752e-05\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1542 - custom_f1: 0.9589 - val_loss: 3.3380 - val_custom_f1: 0.0714\n",
            "Epoch 23: lr: 9.999999747378752e-05\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1261 - custom_f1: 0.9643 - val_loss: 28.6424 - val_custom_f1: 0.8156\n",
            "Epoch 24: lr: 9.999999747378752e-05\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0864 - custom_f1: 0.9781 - val_loss: 5.6784 - val_custom_f1: 0.0000e+00\n",
            "Epoch 25: lr: 9.999999747378752e-05\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0732 - custom_f1: 0.9805\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.0732 - custom_f1: 0.9805 - val_loss: 0.0786 - val_custom_f1: 0.9693\n",
            "Epoch 26: lr: 9.999999747378752e-05\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0435 - custom_f1: 0.9912 - val_loss: 32.3112 - val_custom_f1: 0.8156\n",
            "Epoch 27: lr: 9.999999747378752e-05\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0227 - custom_f1: 0.9987 - val_loss: 6.1751 - val_custom_f1: 0.0000e+00\n",
            "Epoch 28: lr: 9.999999747378752e-05\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0650 - custom_f1: 0.9812 - val_loss: 0.6280 - val_custom_f1: 0.8479\n",
            "Epoch 29: lr: 9.999999747378752e-05\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.2278 - custom_f1: 0.9247 - val_loss: 11.4901 - val_custom_f1: 0.0000e+00\n",
            "Epoch 30: lr: 9.999999747378752e-05\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.2086 - custom_f1: 0.9386 - val_loss: 2.0836 - val_custom_f1: 0.0714\n",
            "Epoch 31: lr: 9.999999747378752e-05\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.1598 - custom_f1: 0.9549 - val_loss: 6.8243 - val_custom_f1: 0.0000e+00\n",
            "Epoch 32: lr: 9.999999747378752e-05\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0782 - custom_f1: 0.9823 - val_loss: 0.1370 - val_custom_f1: 0.9577\n",
            "Epoch 33: lr: 9.999999747378752e-05\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0173 - custom_f1: 0.9971 - val_loss: 0.4942 - val_custom_f1: 0.8929\n",
            "Epoch 34: lr: 9.999999747378752e-05\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0447 - custom_f1: 0.9912 - val_loss: 0.1365 - val_custom_f1: 0.9762\n",
            "Epoch 35: lr: 9.999999747378752e-05\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1173 - custom_f1: 0.9717 - val_loss: 0.9380 - val_custom_f1: 0.5579\n",
            "Epoch 36: lr: 9.999999747378752e-05\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0809 - custom_f1: 0.9823 - val_loss: 0.2596 - val_custom_f1: 0.9208\n",
            "Epoch 37: lr: 9.999999747378752e-05\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0453 - custom_f1: 0.9957 - val_loss: 1.8862 - val_custom_f1: 0.2203\n",
            "Epoch 38: lr: 9.999999747378752e-05\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1273 - custom_f1: 0.9628 - val_loss: 24.4459 - val_custom_f1: 0.8156\n",
            "Epoch 39: lr: 9.999999747378752e-05\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0642 - custom_f1: 0.9899 - val_loss: 0.3014 - val_custom_f1: 0.9380\n",
            "Epoch 40: lr: 9.999999747378752e-05\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0614 - custom_f1: 0.9898 - val_loss: 0.2585 - val_custom_f1: 0.9359\n",
            "Epoch 41: lr: 9.999999747378752e-05\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0526 - custom_f1: 0.9864 - val_loss: 21.7945 - val_custom_f1: 0.8156\n",
            "Epoch 42: lr: 9.999999747378752e-05\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0797 - custom_f1: 0.9805 - val_loss: 0.8715 - val_custom_f1: 0.8451\n",
            "Epoch 43: lr: 9.999999747378752e-05\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0483 - custom_f1: 0.9903 - val_loss: 0.1778 - val_custom_f1: 0.9360\n",
            "Epoch 44: lr: 9.999999747378752e-05\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0803 - custom_f1: 0.9788 - val_loss: 0.4194 - val_custom_f1: 0.9208\n",
            "Epoch 45: lr: 9.999999747378752e-05\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1277 - custom_f1: 0.9614 - val_loss: 0.4505 - val_custom_f1: 0.8301\n",
            "Epoch 46: lr: 9.999999747378752e-05\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1402 - custom_f1: 0.9588 - val_loss: 0.5785 - val_custom_f1: 0.8271\n",
            "Epoch 47: lr: 9.999999747378752e-05\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0853 - custom_f1: 0.9734 - val_loss: 1.5379 - val_custom_f1: 0.5112\n",
            "Epoch 48: lr: 9.999999747378752e-05\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0857 - custom_f1: 0.9717 - val_loss: 0.5847 - val_custom_f1: 0.7247\n",
            "Epoch 49: lr: 9.999999747378752e-05\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0382 - custom_f1: 0.9912 - val_loss: 0.2899 - val_custom_f1: 0.9111\n",
            "Epoch 50: lr: 9.999999747378752e-05\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0381 - custom_f1: 0.9912 - val_loss: 0.2057 - val_custom_f1: 0.9380\n",
            "Epoch 51: lr: 9.999999747378752e-05\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0549 - custom_f1: 0.9823\n",
            "lr is fixed to 9.999999747378752e-06\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0549 - custom_f1: 0.9823 - val_loss: 1.4587 - val_custom_f1: 0.8451\n",
            "Epoch 52: lr: 9.999999747378752e-06\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0301 - custom_f1: 0.9912 - val_loss: 0.1348 - val_custom_f1: 0.9588\n",
            "Epoch 53: lr: 9.999999747378752e-06\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0250 - custom_f1: 0.9912 - val_loss: 0.1251 - val_custom_f1: 0.9588\n",
            "Epoch 54: lr: 9.999999747378752e-06\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0325 - custom_f1: 0.9912 - val_loss: 0.0998 - val_custom_f1: 0.9699\n",
            "Epoch 55: lr: 9.999999747378752e-06\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0641 - custom_f1: 0.9823 - val_loss: 0.1284 - val_custom_f1: 0.9588\n",
            "Epoch 56: lr: 9.999999747378752e-06\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0436 - custom_f1: 0.9912 - val_loss: 0.1671 - val_custom_f1: 0.9588\n",
            "Epoch 57: lr: 9.999999747378752e-06\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0532 - custom_f1: 0.9823 - val_loss: 0.1059 - val_custom_f1: 0.9699\n",
            "Epoch 58: lr: 9.999999747378752e-06\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0283 - custom_f1: 0.9912 - val_loss: 0.1231 - val_custom_f1: 0.9699\n",
            "Epoch 59: lr: 9.999999747378752e-06\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0459 - custom_f1: 0.9823 - val_loss: 0.1557 - val_custom_f1: 0.9615\n",
            "Epoch 60: lr: 9.999999747378752e-06\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0247 - custom_f1: 0.9912 - val_loss: 0.1639 - val_custom_f1: 0.9416\n",
            "Epoch 61: lr: 9.999999747378752e-06\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0591 - custom_f1: 0.9735 - val_loss: 0.0947 - val_custom_f1: 0.9699\n",
            "Epoch 62: lr: 9.999999747378752e-06\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0118 - custom_f1: 1.0000 - val_loss: 0.1387 - val_custom_f1: 0.9588\n",
            "Epoch 63: lr: 9.999999747378752e-06\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0294 - custom_f1: 0.9912 - val_loss: 0.1485 - val_custom_f1: 0.9416\n",
            "Epoch 64: lr: 9.999999747378752e-06\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0723 - custom_f1: 0.9646 - val_loss: 0.0942 - val_custom_f1: 0.9878\n",
            "Epoch 65: lr: 9.999999747378752e-06\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0472 - custom_f1: 0.9735 - val_loss: 0.2030 - val_custom_f1: 0.9310\n",
            "Epoch 66: lr: 9.999999747378752e-06\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0248 - custom_f1: 0.9912 - val_loss: 0.1106 - val_custom_f1: 0.9699\n",
            "Epoch 67: lr: 9.999999747378752e-06\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0272 - custom_f1: 0.9912 - val_loss: 0.1152 - val_custom_f1: 0.9699\n",
            "Epoch 68: lr: 9.999999747378752e-06\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0523 - custom_f1: 0.9735 - val_loss: 0.1193 - val_custom_f1: 0.9699\n",
            "Epoch 69: lr: 9.999999747378752e-06\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0303 - custom_f1: 0.9823 - val_loss: 0.0891 - val_custom_f1: 0.9699\n",
            "Epoch 70: lr: 9.999999747378752e-06\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0229 - custom_f1: 0.9823 - val_loss: 0.1318 - val_custom_f1: 0.9481\n",
            "Epoch 71: lr: 9.999999747378752e-06\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0476 - custom_f1: 0.9646 - val_loss: 0.1351 - val_custom_f1: 0.9416\n",
            "Epoch 72: lr: 9.999999747378752e-06\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0082 - custom_f1: 1.0000 - val_loss: 0.1059 - val_custom_f1: 0.9699\n",
            "Epoch 73: lr: 9.999999747378752e-06\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0405 - custom_f1: 0.9735 - val_loss: 0.1793 - val_custom_f1: 0.9615\n",
            "Epoch 74: lr: 9.999999747378752e-06\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0173 - custom_f1: 0.9912 - val_loss: 0.1313 - val_custom_f1: 0.9699\n",
            "Epoch 75: lr: 9.999999747378752e-06\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0417 - custom_f1: 0.9646 - val_loss: 0.0882 - val_custom_f1: 0.9878\n",
            "Epoch 76: lr: 9.999999747378752e-06\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0108 - custom_f1: 1.0000 - val_loss: 0.1534 - val_custom_f1: 0.9481\n",
            "Epoch 77: lr: 9.999999747378752e-06\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0055 - custom_f1: 1.0000 - val_loss: 0.1367 - val_custom_f1: 0.9481\n",
            "Epoch 78: lr: 9.999999747378752e-06\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0261 - custom_f1: 0.9735 - val_loss: 0.2010 - val_custom_f1: 0.9310\n",
            "Epoch 79: lr: 9.999999747378752e-06\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0309 - custom_f1: 0.9823 - val_loss: 0.1975 - val_custom_f1: 0.9310\n",
            "Epoch 80: lr: 9.999999747378752e-06\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0122 - custom_f1: 0.9912 - val_loss: 0.0904 - val_custom_f1: 0.9878\n",
            "Epoch 81: lr: 9.999999747378752e-06\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0045 - custom_f1: 1.0000 - val_loss: 0.1297 - val_custom_f1: 0.9588\n",
            "Epoch 82: lr: 9.999999747378752e-06\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0377 - custom_f1: 0.9558 - val_loss: 0.3532 - val_custom_f1: 0.9111\n",
            "Epoch 83: lr: 9.999999747378752e-06\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0292 - custom_f1: 0.9823 - val_loss: 0.6737 - val_custom_f1: 0.7727\n",
            "Epoch 84: lr: 9.999999747378752e-06\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0104 - custom_f1: 0.9912 - val_loss: 0.1566 - val_custom_f1: 0.9466\n",
            "Epoch 85: lr: 9.999999747378752e-06\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0184 - custom_f1: 0.9735 - val_loss: 0.1555 - val_custom_f1: 0.9588\n",
            "Epoch 86: lr: 9.999999747378752e-06\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0109 - custom_f1: 0.9912 - val_loss: 0.2486 - val_custom_f1: 0.9208\n",
            "Epoch 87: lr: 9.999999747378752e-06\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0078 - custom_f1: 0.9912 - val_loss: 0.1339 - val_custom_f1: 0.9588\n",
            "Epoch 88: lr: 9.999999747378752e-06\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0037 - custom_f1: 1.0000 - val_loss: 0.1215 - val_custom_f1: 0.9466\n",
            "Epoch 89: lr: 9.999999747378752e-06\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0068 - custom_f1: 0.9912 - val_loss: 0.1177 - val_custom_f1: 0.9466\n",
            "Epoch 90: lr: 9.999999747378752e-06\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0030 - custom_f1: 1.0000 - val_loss: 0.1162 - val_custom_f1: 0.9466\n",
            "Epoch 91: lr: 9.999999747378752e-06\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0171 - custom_f1: 0.9735 - val_loss: 0.1457 - val_custom_f1: 0.9294\n",
            "Epoch 92: lr: 9.999999747378752e-06\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0065 - custom_f1: 0.9912 - val_loss: 0.0935 - val_custom_f1: 0.9693\n",
            "Epoch 93: lr: 9.999999747378752e-06\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0076 - custom_f1: 0.9912 - val_loss: 0.1223 - val_custom_f1: 0.9577\n",
            "Epoch 94: lr: 9.999999747378752e-06\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0072 - custom_f1: 0.9912 - val_loss: 0.1566 - val_custom_f1: 0.9416\n",
            "Epoch 95: lr: 9.999999747378752e-06\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0024 - custom_f1: 1.0000 - val_loss: 0.1003 - val_custom_f1: 0.9577\n",
            "Epoch 96: lr: 9.999999747378752e-06\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0078 - custom_f1: 0.9823 - val_loss: 0.1386 - val_custom_f1: 0.9750\n",
            "Epoch 97: lr: 9.999999747378752e-06\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0063 - custom_f1: 0.9912 - val_loss: 0.1132 - val_custom_f1: 0.9577\n",
            "Epoch 98: lr: 9.999999747378752e-06\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0061 - custom_f1: 0.9912 - val_loss: 0.2034 - val_custom_f1: 0.9310\n",
            "Epoch 99: lr: 9.999999747378752e-06\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0072 - custom_f1: 0.9823 - val_loss: 0.1422 - val_custom_f1: 0.9360\n",
            "Epoch 100: lr: 9.999999747378752e-06\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0043 - custom_f1: 0.9912 - val_loss: 0.1598 - val_custom_f1: 0.9360\n",
            "weights are setted to best weights (epochs 25)\n",
            "fold 8 [350,400]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.6412 - custom_f1: 0.7680\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 106ms/step - loss: 0.6412 - custom_f1: 0.7680 - val_loss: 0.8313 - val_custom_f1: 0.0000e+00\n",
            "Epoch 2: lr: 9.999999747378752e-05\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.6030 - custom_f1: 0.7673 - val_loss: 20.1243 - val_custom_f1: 0.0000e+00\n",
            "Epoch 3: lr: 9.999999747378752e-05\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.5546 - custom_f1: 0.8013 - val_loss: 2.4742 - val_custom_f1: 0.7725\n",
            "Epoch 4: lr: 9.999999747378752e-05\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.4694 - custom_f1: 0.8323 - val_loss: 2.6968 - val_custom_f1: 0.7725\n",
            "Epoch 5: lr: 9.999999747378752e-05\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.4815 - custom_f1: 0.8325 - val_loss: 59.0126 - val_custom_f1: 0.0000e+00\n",
            "Epoch 6: lr: 9.999999747378752e-05\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.4316 - custom_f1: 0.8444 - val_loss: 4.9117 - val_custom_f1: 0.0000e+00\n",
            "Epoch 7: lr: 9.999999747378752e-05\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.3332 - custom_f1: 0.8835\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 109ms/step - loss: 0.3332 - custom_f1: 0.8835 - val_loss: 0.3508 - val_custom_f1: 0.8565\n",
            "Epoch 8: lr: 9.999999747378752e-05\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.3036 - custom_f1: 0.8934 - val_loss: 6.9244 - val_custom_f1: 0.7725\n",
            "Epoch 9: lr: 9.999999747378752e-05\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.2269 - custom_f1: 0.9228 - val_loss: 13.7939 - val_custom_f1: 0.7725\n",
            "Epoch 10: lr: 9.999999747378752e-05\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.2843 - custom_f1: 0.9119 - val_loss: 10.1999 - val_custom_f1: 0.0000e+00\n",
            "Epoch 11: lr: 9.999999747378752e-05\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.2284 - custom_f1: 0.9209 - val_loss: 13.1495 - val_custom_f1: 0.7725\n",
            "Epoch 12: lr: 9.999999747378752e-05\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1155 - custom_f1: 0.9683 - val_loss: 17.6851 - val_custom_f1: 0.0000e+00\n",
            "Epoch 13: lr: 9.999999747378752e-05\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1307 - custom_f1: 0.9689 - val_loss: 46.1423 - val_custom_f1: 0.7725\n",
            "Epoch 14: lr: 9.999999747378752e-05\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0611 - custom_f1: 0.9910 - val_loss: 5.7332 - val_custom_f1: 0.7725\n",
            "Epoch 15: lr: 9.999999747378752e-05\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0958 - custom_f1: 0.9823 - val_loss: 1.4455 - val_custom_f1: 0.8403\n",
            "Epoch 16: lr: 9.999999747378752e-05\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1027 - custom_f1: 0.9794 - val_loss: 0.4370 - val_custom_f1: 0.8863\n",
            "Epoch 17: lr: 9.999999747378752e-05\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0585 - custom_f1: 0.9869 - val_loss: 3.4576 - val_custom_f1: 0.0000e+00\n",
            "Epoch 18: lr: 9.999999747378752e-05\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1206 - custom_f1: 0.9735 - val_loss: 11.1548 - val_custom_f1: 0.0000e+00\n",
            "Epoch 19: lr: 9.999999747378752e-05\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1250 - custom_f1: 0.9616 - val_loss: 17.5180 - val_custom_f1: 0.7725\n",
            "Epoch 20: lr: 9.999999747378752e-05\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0964 - custom_f1: 0.9796 - val_loss: 10.4185 - val_custom_f1: 0.0000e+00\n",
            "Epoch 21: lr: 9.999999747378752e-05\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0624 - custom_f1: 0.9866 - val_loss: 49.4425 - val_custom_f1: 0.7725\n",
            "Epoch 22: lr: 9.999999747378752e-05\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0819 - custom_f1: 0.9716 - val_loss: 10.4722 - val_custom_f1: 0.0000e+00\n",
            "Epoch 23: lr: 9.999999747378752e-05\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1054 - custom_f1: 0.9774 - val_loss: 11.6980 - val_custom_f1: 0.0000e+00\n",
            "Epoch 24: lr: 9.999999747378752e-05\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1052 - custom_f1: 0.9775 - val_loss: 0.9376 - val_custom_f1: 0.8015\n",
            "Epoch 25: lr: 9.999999747378752e-05\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0356 - custom_f1: 0.9905 - val_loss: 12.5683 - val_custom_f1: 0.0000e+00\n",
            "Epoch 26: lr: 9.999999747378752e-05\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1004 - custom_f1: 0.9761 - val_loss: 2.2642 - val_custom_f1: 0.8096\n",
            "Epoch 27: lr: 9.999999747378752e-05\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1457 - custom_f1: 0.9601 - val_loss: 0.9047 - val_custom_f1: 0.8244\n",
            "Epoch 28: lr: 9.999999747378752e-05\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1248 - custom_f1: 0.9720 - val_loss: 9.7765 - val_custom_f1: 0.0000e+00\n",
            "Epoch 29: lr: 9.999999747378752e-05\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0913 - custom_f1: 0.9697 - val_loss: 0.5140 - val_custom_f1: 0.8746\n",
            "Epoch 30: lr: 9.999999747378752e-05\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0529 - custom_f1: 0.9881 - val_loss: 0.5851 - val_custom_f1: 0.8528\n",
            "Epoch 31: lr: 9.999999747378752e-05\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0790 - custom_f1: 0.9793 - val_loss: 0.4923 - val_custom_f1: 0.8667\n",
            "Epoch 32: lr: 9.999999747378752e-05\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0851 - custom_f1: 0.9767 - val_loss: 4.9333 - val_custom_f1: 0.7725\n",
            "Epoch 33: lr: 9.999999747378752e-05\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0881 - custom_f1: 0.9805 - val_loss: 7.5381 - val_custom_f1: 0.0000e+00\n",
            "Epoch 34: lr: 9.999999747378752e-05\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0450 - custom_f1: 0.9894\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 109ms/step - loss: 0.0450 - custom_f1: 0.9894 - val_loss: 0.2634 - val_custom_f1: 0.9227\n",
            "Epoch 35: lr: 9.999999747378752e-05\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0431 - custom_f1: 0.9899 - val_loss: 0.5506 - val_custom_f1: 0.8361\n",
            "Epoch 36: lr: 9.999999747378752e-05\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0447 - custom_f1: 0.9876 - val_loss: 0.9715 - val_custom_f1: 0.7667\n",
            "Epoch 37: lr: 9.999999747378752e-05\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1136 - custom_f1: 0.9654 - val_loss: 0.7832 - val_custom_f1: 0.6548\n",
            "Epoch 38: lr: 9.999999747378752e-05\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1344 - custom_f1: 0.9708 - val_loss: 2.8312 - val_custom_f1: 0.0952\n",
            "Epoch 39: lr: 9.999999747378752e-05\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1174 - custom_f1: 0.9572 - val_loss: 66.4428 - val_custom_f1: 0.7725\n",
            "Epoch 40: lr: 9.999999747378752e-05\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1187 - custom_f1: 0.9681\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.1187 - custom_f1: 0.9681 - val_loss: 0.2408 - val_custom_f1: 0.9150\n",
            "Epoch 41: lr: 9.999999747378752e-05\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1291 - custom_f1: 0.9633 - val_loss: 0.5796 - val_custom_f1: 0.8575\n",
            "Epoch 42: lr: 9.999999747378752e-05\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1053 - custom_f1: 0.9646 - val_loss: 0.4453 - val_custom_f1: 0.9034\n",
            "Epoch 43: lr: 9.999999747378752e-05\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0553 - custom_f1: 0.9846 - val_loss: 0.3938 - val_custom_f1: 0.8990\n",
            "Epoch 44: lr: 9.999999747378752e-05\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0139 - custom_f1: 1.0000 - val_loss: 0.3252 - val_custom_f1: 0.8755\n",
            "Epoch 45: lr: 9.999999747378752e-05\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0872 - custom_f1: 0.9735 - val_loss: 0.3938 - val_custom_f1: 0.8731\n",
            "Epoch 46: lr: 9.999999747378752e-05\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0499 - custom_f1: 0.9899 - val_loss: 0.2568 - val_custom_f1: 0.9150\n",
            "Epoch 47: lr: 9.999999747378752e-05\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0429 - custom_f1: 0.9864 - val_loss: 28.3755 - val_custom_f1: 0.0000e+00\n",
            "Epoch 48: lr: 9.999999747378752e-05\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0364 - custom_f1: 0.9912 - val_loss: 1.0552 - val_custom_f1: 0.8575\n",
            "Epoch 49: lr: 9.999999747378752e-05\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0211 - custom_f1: 0.9945 - val_loss: 52.1916 - val_custom_f1: 0.7725\n",
            "Epoch 50: lr: 9.999999747378752e-05\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0337 - custom_f1: 0.9901\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.0337 - custom_f1: 0.9901 - val_loss: 0.2167 - val_custom_f1: 0.9320\n",
            "Epoch 51: lr: 9.999999747378752e-05\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0710 - custom_f1: 0.9817\n",
            "lr is fixed to 9.999999747378752e-06\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0710 - custom_f1: 0.9817 - val_loss: 125.0341 - val_custom_f1: 0.7725\n",
            "Epoch 52: lr: 9.999999747378752e-06\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0894 - custom_f1: 0.9779 - val_loss: 0.2759 - val_custom_f1: 0.8819\n",
            "Epoch 53: lr: 9.999999747378752e-06\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0893 - custom_f1: 0.9799 - val_loss: 0.3858 - val_custom_f1: 0.8763\n",
            "Epoch 54: lr: 9.999999747378752e-06\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0712 - custom_f1: 0.9761 - val_loss: 0.4717 - val_custom_f1: 0.8667\n",
            "Epoch 55: lr: 9.999999747378752e-06\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0159 - custom_f1: 0.9958 - val_loss: 0.4025 - val_custom_f1: 0.8571\n",
            "Epoch 56: lr: 9.999999747378752e-06\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0328 - custom_f1: 0.9912\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.0328 - custom_f1: 0.9912 - val_loss: 0.2142 - val_custom_f1: 0.9398\n",
            "Epoch 57: lr: 9.999999747378752e-06\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0319 - custom_f1: 0.9912 - val_loss: 0.2218 - val_custom_f1: 0.9107\n",
            "Epoch 58: lr: 9.999999747378752e-06\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0705 - custom_f1: 0.9805 - val_loss: 0.2734 - val_custom_f1: 0.8755\n",
            "Epoch 59: lr: 9.999999747378752e-06\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0303 - custom_f1: 0.9912 - val_loss: 0.2169 - val_custom_f1: 0.9333\n",
            "Epoch 60: lr: 9.999999747378752e-06\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0072 - custom_f1: 1.0000\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.0072 - custom_f1: 1.0000 - val_loss: 0.2127 - val_custom_f1: 0.9519\n",
            "Epoch 61: lr: 9.999999747378752e-06\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0284 - custom_f1: 0.9912 - val_loss: 0.2536 - val_custom_f1: 0.8924\n",
            "Epoch 62: lr: 9.999999747378752e-06\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0274 - custom_f1: 0.9912\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.0274 - custom_f1: 0.9912 - val_loss: 0.1971 - val_custom_f1: 0.9417\n",
            "Epoch 63: lr: 9.999999747378752e-06\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0281 - custom_f1: 0.9912 - val_loss: 0.2096 - val_custom_f1: 0.9417\n",
            "Epoch 64: lr: 9.999999747378752e-06\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1077 - custom_f1: 0.9540 - val_loss: 0.2459 - val_custom_f1: 0.9283\n",
            "Epoch 65: lr: 9.999999747378752e-06\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0251 - custom_f1: 0.9912 - val_loss: 0.2573 - val_custom_f1: 0.9034\n",
            "Epoch 66: lr: 9.999999747378752e-06\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0213 - custom_f1: 0.9912 - val_loss: 0.2540 - val_custom_f1: 0.9034\n",
            "Epoch 67: lr: 9.999999747378752e-06\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0227 - custom_f1: 0.9912 - val_loss: 0.2422 - val_custom_f1: 0.9217\n",
            "Epoch 68: lr: 9.999999747378752e-06\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0216 - custom_f1: 0.9912 - val_loss: 0.2671 - val_custom_f1: 0.9034\n",
            "Epoch 69: lr: 9.999999747378752e-06\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0414 - custom_f1: 0.9823 - val_loss: 0.2770 - val_custom_f1: 0.9377\n",
            "Epoch 70: lr: 9.999999747378752e-06\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0393 - custom_f1: 0.9823 - val_loss: 0.2878 - val_custom_f1: 0.8924\n",
            "Epoch 71: lr: 9.999999747378752e-06\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0199 - custom_f1: 0.9912 - val_loss: 0.2591 - val_custom_f1: 0.9034\n",
            "Epoch 72: lr: 9.999999747378752e-06\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0650 - custom_f1: 0.9646 - val_loss: 0.3670 - val_custom_f1: 0.8759\n",
            "Epoch 73: lr: 9.999999747378752e-06\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 12s 102ms/step - loss: 0.0198 - custom_f1: 0.9912 - val_loss: 0.2491 - val_custom_f1: 0.9015\n",
            "Epoch 74: lr: 9.999999747378752e-06\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0070 - custom_f1: 1.0000 - val_loss: 0.2556 - val_custom_f1: 0.9034\n",
            "Epoch 75: lr: 9.999999747378752e-06\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0293 - custom_f1: 0.9823 - val_loss: 0.2590 - val_custom_f1: 0.8900\n",
            "Epoch 76: lr: 9.999999747378752e-06\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0284 - custom_f1: 0.9823 - val_loss: 0.2993 - val_custom_f1: 0.9034\n",
            "Epoch 77: lr: 9.999999747378752e-06\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0191 - custom_f1: 0.9912 - val_loss: 0.2679 - val_custom_f1: 0.9034\n",
            "Epoch 78: lr: 9.999999747378752e-06\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0043 - custom_f1: 1.0000 - val_loss: 0.3449 - val_custom_f1: 0.8755\n",
            "Epoch 79: lr: 9.999999747378752e-06\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0176 - custom_f1: 0.9912 - val_loss: 0.2760 - val_custom_f1: 0.9034\n",
            "Epoch 80: lr: 9.999999747378752e-06\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0163 - custom_f1: 0.9912 - val_loss: 0.2729 - val_custom_f1: 0.9034\n",
            "Epoch 81: lr: 9.999999747378752e-06\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0574 - custom_f1: 0.9646 - val_loss: 0.2659 - val_custom_f1: 0.8900\n",
            "Epoch 82: lr: 9.999999747378752e-06\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0061 - custom_f1: 1.0000 - val_loss: 0.2696 - val_custom_f1: 0.8755\n",
            "Epoch 83: lr: 9.999999747378752e-06\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0279 - custom_f1: 0.9735 - val_loss: 0.2646 - val_custom_f1: 0.9034\n",
            "Epoch 84: lr: 9.999999747378752e-06\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0124 - custom_f1: 0.9912 - val_loss: 0.4651 - val_custom_f1: 0.8549\n",
            "Epoch 85: lr: 9.999999747378752e-06\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0182 - custom_f1: 0.9912 - val_loss: 0.2510 - val_custom_f1: 0.8900\n",
            "Epoch 86: lr: 9.999999747378752e-06\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0137 - custom_f1: 0.9912 - val_loss: 0.2705 - val_custom_f1: 0.9034\n",
            "Epoch 87: lr: 9.999999747378752e-06\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0114 - custom_f1: 0.9912 - val_loss: 0.2695 - val_custom_f1: 0.9034\n",
            "Epoch 88: lr: 9.999999747378752e-06\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0048 - custom_f1: 1.0000 - val_loss: 0.2791 - val_custom_f1: 0.9034\n",
            "Epoch 89: lr: 9.999999747378752e-06\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0042 - custom_f1: 1.0000 - val_loss: 0.2751 - val_custom_f1: 0.9034\n",
            "Epoch 90: lr: 9.999999747378752e-06\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0187 - custom_f1: 0.9823 - val_loss: 0.3047 - val_custom_f1: 0.8761\n",
            "Epoch 91: lr: 9.999999747378752e-06\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0115 - custom_f1: 0.9912 - val_loss: 0.2875 - val_custom_f1: 0.8924\n",
            "Epoch 92: lr: 9.999999747378752e-06\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0181 - custom_f1: 0.9823 - val_loss: 0.2832 - val_custom_f1: 0.8900\n",
            "Epoch 93: lr: 9.999999747378752e-06\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0040 - custom_f1: 1.0000 - val_loss: 0.2954 - val_custom_f1: 0.8924\n",
            "Epoch 94: lr: 9.999999747378752e-06\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0097 - custom_f1: 0.9912 - val_loss: 0.3374 - val_custom_f1: 0.8924\n",
            "Epoch 95: lr: 9.999999747378752e-06\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0092 - custom_f1: 0.9912 - val_loss: 0.3115 - val_custom_f1: 0.8924\n",
            "Epoch 96: lr: 9.999999747378752e-06\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0078 - custom_f1: 0.9912 - val_loss: 0.2976 - val_custom_f1: 0.9034\n",
            "Epoch 97: lr: 9.999999747378752e-06\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0030 - custom_f1: 1.0000 - val_loss: 0.2518 - val_custom_f1: 0.9150\n",
            "Epoch 98: lr: 9.999999747378752e-06\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0026 - custom_f1: 1.0000 - val_loss: 0.2565 - val_custom_f1: 0.9150\n",
            "Epoch 99: lr: 9.999999747378752e-06\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0156 - custom_f1: 0.9823 - val_loss: 0.2831 - val_custom_f1: 0.9034\n",
            "Epoch 100: lr: 9.999999747378752e-06\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0279 - custom_f1: 0.9469 - val_loss: 0.3336 - val_custom_f1: 0.8662\n",
            "weights are setted to best weights (epochs 62)\n",
            "fold 9 [400,450]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.6401 - custom_f1: 0.7630\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 105ms/step - loss: 0.6401 - custom_f1: 0.7630 - val_loss: 73.3080 - val_custom_f1: 0.2455\n",
            "Epoch 2: lr: 9.999999747378752e-05\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.5714 - custom_f1: 0.7849 - val_loss: 286.7513 - val_custom_f1: 0.7519\n",
            "Epoch 3: lr: 9.999999747378752e-05\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.5611 - custom_f1: 0.7930\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 109ms/step - loss: 0.5611 - custom_f1: 0.7930 - val_loss: 7.1302 - val_custom_f1: 0.7519\n",
            "Epoch 4: lr: 9.999999747378752e-05\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.4848 - custom_f1: 0.8083\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 105ms/step - loss: 0.4848 - custom_f1: 0.8083 - val_loss: 0.8140 - val_custom_f1: 0.7519\n",
            "Epoch 5: lr: 9.999999747378752e-05\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.4809 - custom_f1: 0.8235 - val_loss: 5.5095 - val_custom_f1: 0.0000e+00\n",
            "Epoch 6: lr: 9.999999747378752e-05\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.4424 - custom_f1: 0.8324 - val_loss: 4.8360 - val_custom_f1: 0.0000e+00\n",
            "Epoch 7: lr: 9.999999747378752e-05\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.3653 - custom_f1: 0.8739 - val_loss: 1.5162 - val_custom_f1: 0.7593\n",
            "Epoch 8: lr: 9.999999747378752e-05\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.3315 - custom_f1: 0.8772 - val_loss: 33.0672 - val_custom_f1: 0.7519\n",
            "Epoch 9: lr: 9.999999747378752e-05\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.2177 - custom_f1: 0.9240 - val_loss: 8.4388 - val_custom_f1: 0.0000e+00\n",
            "Epoch 10: lr: 9.999999747378752e-05\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.2463 - custom_f1: 0.9062 - val_loss: 24.9727 - val_custom_f1: 0.7519\n",
            "Epoch 11: lr: 9.999999747378752e-05\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1821 - custom_f1: 0.9257 - val_loss: 4.3819 - val_custom_f1: 0.0000e+00\n",
            "Epoch 12: lr: 9.999999747378752e-05\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.2189 - custom_f1: 0.9358\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 109ms/step - loss: 0.2189 - custom_f1: 0.9358 - val_loss: 0.7671 - val_custom_f1: 0.4231\n",
            "Epoch 13: lr: 9.999999747378752e-05\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0802 - custom_f1: 0.9849 - val_loss: 2.4041 - val_custom_f1: 0.0000e+00\n",
            "Epoch 14: lr: 9.999999747378752e-05\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0904 - custom_f1: 0.9857 - val_loss: 0.9620 - val_custom_f1: 0.3141\n",
            "Epoch 15: lr: 9.999999747378752e-05\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0936 - custom_f1: 0.9751\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.0936 - custom_f1: 0.9751 - val_loss: 0.3054 - val_custom_f1: 0.8963\n",
            "Epoch 16: lr: 9.999999747378752e-05\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0946 - custom_f1: 0.9805 - val_loss: 7.4616 - val_custom_f1: 0.0000e+00\n",
            "Epoch 17: lr: 9.999999747378752e-05\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0906 - custom_f1: 0.9761 - val_loss: 0.4422 - val_custom_f1: 0.7647\n",
            "Epoch 18: lr: 9.999999747378752e-05\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1882 - custom_f1: 0.9444 - val_loss: 1.3692 - val_custom_f1: 0.1667\n",
            "Epoch 19: lr: 9.999999747378752e-05\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1209 - custom_f1: 0.9675 - val_loss: 8.2313 - val_custom_f1: 0.0000e+00\n",
            "Epoch 20: lr: 9.999999747378752e-05\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0781 - custom_f1: 0.9857 - val_loss: 1.1372 - val_custom_f1: 0.7971\n",
            "Epoch 21: lr: 9.999999747378752e-05\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0695 - custom_f1: 0.9881 - val_loss: 2.2095 - val_custom_f1: 0.8117\n",
            "Epoch 22: lr: 9.999999747378752e-05\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0464 - custom_f1: 0.9912 - val_loss: 3.0266 - val_custom_f1: 0.8205\n",
            "Epoch 23: lr: 9.999999747378752e-05\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0164 - custom_f1: 0.9982 - val_loss: 47.0178 - val_custom_f1: 0.7519\n",
            "Epoch 24: lr: 9.999999747378752e-05\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0915 - custom_f1: 0.9781 - val_loss: 22.9608 - val_custom_f1: 0.7519\n",
            "Epoch 25: lr: 9.999999747378752e-05\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0326 - custom_f1: 0.9940 - val_loss: 0.4875 - val_custom_f1: 0.7619\n",
            "Epoch 26: lr: 9.999999747378752e-05\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0890 - custom_f1: 0.9810 - val_loss: 0.3241 - val_custom_f1: 0.8434\n",
            "Epoch 27: lr: 9.999999747378752e-05\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0521 - custom_f1: 0.9894 - val_loss: 6.9561 - val_custom_f1: 0.0000e+00\n",
            "Epoch 28: lr: 9.999999747378752e-05\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.1111 - custom_f1: 0.9690 - val_loss: 8.6461 - val_custom_f1: 0.7519\n",
            "Epoch 29: lr: 9.999999747378752e-05\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0833 - custom_f1: 0.9751 - val_loss: 10.4520 - val_custom_f1: 0.7519\n",
            "Epoch 30: lr: 9.999999747378752e-05\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0733 - custom_f1: 0.9858 - val_loss: 7.2467 - val_custom_f1: 0.0000e+00\n",
            "Epoch 31: lr: 9.999999747378752e-05\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1185 - custom_f1: 0.9649 - val_loss: 4.6382 - val_custom_f1: 0.0000e+00\n",
            "Epoch 32: lr: 9.999999747378752e-05\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0913 - custom_f1: 0.9776 - val_loss: 6.0192 - val_custom_f1: 0.0000e+00\n",
            "Epoch 33: lr: 9.999999747378752e-05\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1911 - custom_f1: 0.9431 - val_loss: 1.5437 - val_custom_f1: 0.1739\n",
            "Epoch 34: lr: 9.999999747378752e-05\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0412 - custom_f1: 0.9952 - val_loss: 2.7241 - val_custom_f1: 0.1364\n",
            "Epoch 35: lr: 9.999999747378752e-05\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0440 - custom_f1: 0.9912 - val_loss: 0.8525 - val_custom_f1: 0.8493\n",
            "Epoch 36: lr: 9.999999747378752e-05\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0393 - custom_f1: 0.9912\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 13s 111ms/step - loss: 0.0393 - custom_f1: 0.9912 - val_loss: 0.3039 - val_custom_f1: 0.9036\n",
            "Epoch 37: lr: 9.999999747378752e-05\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0416 - custom_f1: 0.9912 - val_loss: 2.0626 - val_custom_f1: 0.2083\n",
            "Epoch 38: lr: 9.999999747378752e-05\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0405 - custom_f1: 0.9912 - val_loss: 2.0287 - val_custom_f1: 0.8205\n",
            "Epoch 39: lr: 9.999999747378752e-05\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0637 - custom_f1: 0.9823 - val_loss: 1.1456 - val_custom_f1: 0.8392\n",
            "Epoch 40: lr: 9.999999747378752e-05\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0628 - custom_f1: 0.9823 - val_loss: 14.1578 - val_custom_f1: 0.7519\n",
            "Epoch 41: lr: 9.999999747378752e-05\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0495 - custom_f1: 0.9899 - val_loss: 1.8109 - val_custom_f1: 0.8151\n",
            "Epoch 42: lr: 9.999999747378752e-05\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0931 - custom_f1: 0.9864 - val_loss: 6.9624 - val_custom_f1: 0.0000e+00\n",
            "Epoch 43: lr: 9.999999747378752e-05\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1974 - custom_f1: 0.9391 - val_loss: 17.7049 - val_custom_f1: 0.7519\n",
            "Epoch 44: lr: 9.999999747378752e-05\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0752 - custom_f1: 0.9835 - val_loss: 0.6382 - val_custom_f1: 0.6618\n",
            "Epoch 45: lr: 9.999999747378752e-05\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0684 - custom_f1: 0.9817 - val_loss: 4.9280 - val_custom_f1: 0.7519\n",
            "Epoch 46: lr: 9.999999747378752e-05\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0456 - custom_f1: 0.9912 - val_loss: 1.1797 - val_custom_f1: 0.6417\n",
            "Epoch 47: lr: 9.999999747378752e-05\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0515 - custom_f1: 0.9886 - val_loss: 9.3695 - val_custom_f1: 0.0000e+00\n",
            "Epoch 48: lr: 9.999999747378752e-05\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0685 - custom_f1: 0.9821 - val_loss: 4.3670 - val_custom_f1: 0.0000e+00\n",
            "Epoch 49: lr: 9.999999747378752e-05\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0888 - custom_f1: 0.9745 - val_loss: 45.5941 - val_custom_f1: 0.7519\n",
            "Epoch 50: lr: 9.999999747378752e-05\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1703 - custom_f1: 0.9522 - val_loss: 8.6142 - val_custom_f1: 0.0000e+00\n",
            "Epoch 51: lr: 9.999999747378752e-05\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0749 - custom_f1: 0.9851\n",
            "lr is fixed to 9.999999747378752e-06\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0749 - custom_f1: 0.9851 - val_loss: 3.7074 - val_custom_f1: 0.0952\n",
            "Epoch 52: lr: 9.999999747378752e-06\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0735 - custom_f1: 0.9810 - val_loss: 0.9759 - val_custom_f1: 0.7977\n",
            "Epoch 53: lr: 9.999999747378752e-06\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0488 - custom_f1: 0.9912 - val_loss: 0.5759 - val_custom_f1: 0.8068\n",
            "Epoch 54: lr: 9.999999747378752e-06\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0167 - custom_f1: 1.0000 - val_loss: 0.6078 - val_custom_f1: 0.8068\n",
            "Epoch 55: lr: 9.999999747378752e-06\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0667 - custom_f1: 0.9823 - val_loss: 0.4489 - val_custom_f1: 0.8413\n",
            "Epoch 56: lr: 9.999999747378752e-06\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0687 - custom_f1: 0.9823 - val_loss: 0.4507 - val_custom_f1: 0.8481\n",
            "Epoch 57: lr: 9.999999747378752e-06\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0380 - custom_f1: 0.9912 - val_loss: 0.5073 - val_custom_f1: 0.8169\n",
            "Epoch 58: lr: 9.999999747378752e-06\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0109 - custom_f1: 1.0000 - val_loss: 0.4462 - val_custom_f1: 0.8481\n",
            "Epoch 59: lr: 9.999999747378752e-06\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0626 - custom_f1: 0.9823 - val_loss: 0.4414 - val_custom_f1: 0.8615\n",
            "Epoch 60: lr: 9.999999747378752e-06\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0649 - custom_f1: 0.9823 - val_loss: 0.5930 - val_custom_f1: 0.8068\n",
            "Epoch 61: lr: 9.999999747378752e-06\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0350 - custom_f1: 0.9912 - val_loss: 0.5151 - val_custom_f1: 0.8169\n",
            "Epoch 62: lr: 9.999999747378752e-06\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0576 - custom_f1: 0.9823 - val_loss: 0.4178 - val_custom_f1: 0.8591\n",
            "Epoch 63: lr: 9.999999747378752e-06\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0346 - custom_f1: 0.9912 - val_loss: 0.4364 - val_custom_f1: 0.8437\n",
            "Epoch 64: lr: 9.999999747378752e-06\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0357 - custom_f1: 0.9912 - val_loss: 0.4100 - val_custom_f1: 0.8706\n",
            "Epoch 65: lr: 9.999999747378752e-06\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0085 - custom_f1: 1.0000 - val_loss: 0.5096 - val_custom_f1: 0.8169\n",
            "Epoch 66: lr: 9.999999747378752e-06\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0099 - custom_f1: 1.0000 - val_loss: 0.4352 - val_custom_f1: 0.8437\n",
            "Epoch 67: lr: 9.999999747378752e-06\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0341 - custom_f1: 0.9912 - val_loss: 0.4245 - val_custom_f1: 0.8437\n",
            "Epoch 68: lr: 9.999999747378752e-06\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0083 - custom_f1: 1.0000 - val_loss: 0.4342 - val_custom_f1: 0.8437\n",
            "Epoch 69: lr: 9.999999747378752e-06\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0084 - custom_f1: 1.0000 - val_loss: 0.4817 - val_custom_f1: 0.8169\n",
            "Epoch 70: lr: 9.999999747378752e-06\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0855 - custom_f1: 0.9735 - val_loss: 0.3889 - val_custom_f1: 0.8528\n",
            "Epoch 71: lr: 9.999999747378752e-06\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0090 - custom_f1: 1.0000 - val_loss: 0.4062 - val_custom_f1: 0.8413\n",
            "Epoch 72: lr: 9.999999747378752e-06\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0339 - custom_f1: 0.9912 - val_loss: 0.4059 - val_custom_f1: 0.8901\n",
            "Epoch 73: lr: 9.999999747378752e-06\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0080 - custom_f1: 1.0000 - val_loss: 0.4121 - val_custom_f1: 0.8547\n",
            "Epoch 74: lr: 9.999999747378752e-06\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0080 - custom_f1: 1.0000 - val_loss: 0.3951 - val_custom_f1: 0.8413\n",
            "Epoch 75: lr: 9.999999747378752e-06\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0590 - custom_f1: 0.9823 - val_loss: 0.3943 - val_custom_f1: 0.8528\n",
            "Epoch 76: lr: 9.999999747378752e-06\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0594 - custom_f1: 0.9823 - val_loss: 0.4840 - val_custom_f1: 0.8274\n",
            "Epoch 77: lr: 9.999999747378752e-06\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0552 - custom_f1: 0.9823 - val_loss: 0.3603 - val_custom_f1: 0.8901\n",
            "Epoch 78: lr: 9.999999747378752e-06\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0311 - custom_f1: 0.9912 - val_loss: 0.3849 - val_custom_f1: 0.8437\n",
            "Epoch 79: lr: 9.999999747378752e-06\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0343 - custom_f1: 0.9912 - val_loss: 0.3636 - val_custom_f1: 0.8901\n",
            "Epoch 80: lr: 9.999999747378752e-06\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0079 - custom_f1: 1.0000 - val_loss: 0.3994 - val_custom_f1: 0.8437\n",
            "Epoch 81: lr: 9.999999747378752e-06\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0304 - custom_f1: 0.9912 - val_loss: 0.3543 - val_custom_f1: 0.8725\n",
            "Epoch 82: lr: 9.999999747378752e-06\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0299 - custom_f1: 0.9912 - val_loss: 0.5068 - val_custom_f1: 0.8444\n",
            "Epoch 83: lr: 9.999999747378752e-06\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0307 - custom_f1: 0.9912 - val_loss: 0.4166 - val_custom_f1: 0.8437\n",
            "Epoch 84: lr: 9.999999747378752e-06\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0794 - custom_f1: 0.9735 - val_loss: 0.7866 - val_custom_f1: 0.8205\n",
            "Epoch 85: lr: 9.999999747378752e-06\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0108 - custom_f1: 1.0000 - val_loss: 0.3108 - val_custom_f1: 0.8725\n",
            "Epoch 86: lr: 9.999999747378752e-06\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0302 - custom_f1: 0.9912 - val_loss: 1.1202 - val_custom_f1: 0.8117\n",
            "Epoch 87: lr: 9.999999747378752e-06\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0296 - custom_f1: 0.9912 - val_loss: 0.3414 - val_custom_f1: 0.8437\n",
            "Epoch 88: lr: 9.999999747378752e-06\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0073 - custom_f1: 1.0000 - val_loss: 0.4129 - val_custom_f1: 0.8437\n",
            "Epoch 89: lr: 9.999999747378752e-06\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0498 - custom_f1: 0.9823 - val_loss: 0.3176 - val_custom_f1: 0.8725\n",
            "Epoch 90: lr: 9.999999747378752e-06\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0658 - custom_f1: 0.9735 - val_loss: 0.4117 - val_custom_f1: 0.8690\n",
            "Epoch 91: lr: 9.999999747378752e-06\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0273 - custom_f1: 0.9912 - val_loss: 0.4145 - val_custom_f1: 0.8690\n",
            "Epoch 92: lr: 9.999999747378752e-06\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0071 - custom_f1: 1.0000 - val_loss: 0.3410 - val_custom_f1: 0.8437\n",
            "Epoch 93: lr: 9.999999747378752e-06\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0220 - custom_f1: 0.9912 - val_loss: 0.3431 - val_custom_f1: 0.8828\n",
            "Epoch 94: lr: 9.999999747378752e-06\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0371 - custom_f1: 0.9823 - val_loss: 0.3522 - val_custom_f1: 0.8524\n",
            "Epoch 95: lr: 9.999999747378752e-06\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0073 - custom_f1: 1.0000 - val_loss: 0.4227 - val_custom_f1: 0.8524\n",
            "Epoch 96: lr: 9.999999747378752e-06\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0411 - custom_f1: 0.9823 - val_loss: 0.4452 - val_custom_f1: 0.8370\n",
            "Epoch 97: lr: 9.999999747378752e-06\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0201 - custom_f1: 0.9912 - val_loss: 0.3717 - val_custom_f1: 0.8524\n",
            "Epoch 98: lr: 9.999999747378752e-06\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0410 - custom_f1: 0.9823 - val_loss: 0.3263 - val_custom_f1: 0.8848\n",
            "Epoch 99: lr: 9.999999747378752e-06\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0332 - custom_f1: 0.9823 - val_loss: 0.4839 - val_custom_f1: 0.8649\n",
            "Epoch 100: lr: 9.999999747378752e-06\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0208 - custom_f1: 0.9912 - val_loss: 0.3388 - val_custom_f1: 0.8738\n",
            "weights are setted to best weights (epochs 36)\n",
            "fold 10 [450,500]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.6402 - custom_f1: 0.7738\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 106ms/step - loss: 0.6402 - custom_f1: 0.7738 - val_loss: 3.6447 - val_custom_f1: 0.0000e+00\n",
            "Epoch 2: lr: 9.999999747378752e-05\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.5866 - custom_f1: 0.7875\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 13s 111ms/step - loss: 0.5866 - custom_f1: 0.7875 - val_loss: 0.7555 - val_custom_f1: 0.0000e+00\n",
            "Epoch 3: lr: 9.999999747378752e-05\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.5586 - custom_f1: 0.7909 - val_loss: 0.7922 - val_custom_f1: 0.0455\n",
            "Epoch 4: lr: 9.999999747378752e-05\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.4642 - custom_f1: 0.8324\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.4642 - custom_f1: 0.8324 - val_loss: 0.6283 - val_custom_f1: 0.7682\n",
            "Epoch 5: lr: 9.999999747378752e-05\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.3778 - custom_f1: 0.8480 - val_loss: 7.5858 - val_custom_f1: 0.7534\n",
            "Epoch 6: lr: 9.999999747378752e-05\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.3014 - custom_f1: 0.9022 - val_loss: 1.2803 - val_custom_f1: 0.0455\n",
            "Epoch 7: lr: 9.999999747378752e-05\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.2367 - custom_f1: 0.9252 - val_loss: 41.8222 - val_custom_f1: 0.7534\n",
            "Epoch 8: lr: 9.999999747378752e-05\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.2639 - custom_f1: 0.9146\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 111ms/step - loss: 0.2639 - custom_f1: 0.9146 - val_loss: 0.3280 - val_custom_f1: 0.8481\n",
            "Epoch 9: lr: 9.999999747378752e-05\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.2567 - custom_f1: 0.9246 - val_loss: 47.3118 - val_custom_f1: 0.7534\n",
            "Epoch 10: lr: 9.999999747378752e-05\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1412 - custom_f1: 0.9546 - val_loss: 3.1335 - val_custom_f1: 0.7742\n",
            "Epoch 11: lr: 9.999999747378752e-05\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1402 - custom_f1: 0.9544 - val_loss: 47.2084 - val_custom_f1: 0.7534\n",
            "Epoch 12: lr: 9.999999747378752e-05\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1183 - custom_f1: 0.9674 - val_loss: 1.1016 - val_custom_f1: 0.4167\n",
            "Epoch 13: lr: 9.999999747378752e-05\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0463 - custom_f1: 0.9914 - val_loss: 7.0527 - val_custom_f1: 0.7610\n",
            "Epoch 14: lr: 9.999999747378752e-05\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1302 - custom_f1: 0.9709 - val_loss: 0.4193 - val_custom_f1: 0.8007\n",
            "Epoch 15: lr: 9.999999747378752e-05\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0552 - custom_f1: 0.9853 - val_loss: 9.2679 - val_custom_f1: 0.0000e+00\n",
            "Epoch 16: lr: 9.999999747378752e-05\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1078 - custom_f1: 0.9710 - val_loss: 1.6986 - val_custom_f1: 0.7666\n",
            "Epoch 17: lr: 9.999999747378752e-05\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1425 - custom_f1: 0.9650 - val_loss: 64.6575 - val_custom_f1: 0.7534\n",
            "Epoch 18: lr: 9.999999747378752e-05\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1717 - custom_f1: 0.9612 - val_loss: 36.5207 - val_custom_f1: 0.7534\n",
            "Epoch 19: lr: 9.999999747378752e-05\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0892 - custom_f1: 0.9838 - val_loss: 36.7603 - val_custom_f1: 0.7534\n",
            "Epoch 20: lr: 9.999999747378752e-05\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0305 - custom_f1: 0.9982\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 13s 111ms/step - loss: 0.0305 - custom_f1: 0.9982 - val_loss: 0.2201 - val_custom_f1: 0.9151\n",
            "Epoch 21: lr: 9.999999747378752e-05\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0488 - custom_f1: 0.9899 - val_loss: 0.6423 - val_custom_f1: 0.7024\n",
            "Epoch 22: lr: 9.999999747378752e-05\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0761 - custom_f1: 0.9805 - val_loss: 17.8293 - val_custom_f1: 0.7534\n",
            "Epoch 23: lr: 9.999999747378752e-05\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0410 - custom_f1: 0.9912 - val_loss: 10.0640 - val_custom_f1: 0.7610\n",
            "Epoch 24: lr: 9.999999747378752e-05\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1003 - custom_f1: 0.9735 - val_loss: 1.2586 - val_custom_f1: 0.8046\n",
            "Epoch 25: lr: 9.999999747378752e-05\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1139 - custom_f1: 0.9646 - val_loss: 0.2834 - val_custom_f1: 0.9111\n",
            "Epoch 26: lr: 9.999999747378752e-05\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0925 - custom_f1: 0.9735 - val_loss: 0.3493 - val_custom_f1: 0.8732\n",
            "Epoch 27: lr: 9.999999747378752e-05\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0466 - custom_f1: 0.9912 - val_loss: 0.2552 - val_custom_f1: 0.8918\n",
            "Epoch 28: lr: 9.999999747378752e-05\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0674 - custom_f1: 0.9823 - val_loss: 0.9005 - val_custom_f1: 0.6494\n",
            "Epoch 29: lr: 9.999999747378752e-05\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0385 - custom_f1: 0.9912\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 13s 111ms/step - loss: 0.0385 - custom_f1: 0.9912 - val_loss: 0.1750 - val_custom_f1: 0.9429\n",
            "Epoch 30: lr: 9.999999747378752e-05\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0893 - custom_f1: 0.9735 - val_loss: 0.4412 - val_custom_f1: 0.8913\n",
            "Epoch 31: lr: 9.999999747378752e-05\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0585 - custom_f1: 0.9823 - val_loss: 0.9584 - val_custom_f1: 0.5944\n",
            "Epoch 32: lr: 9.999999747378752e-05\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1165 - custom_f1: 0.9661 - val_loss: 136.8871 - val_custom_f1: 0.7534\n",
            "Epoch 33: lr: 9.999999747378752e-05\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.3285 - custom_f1: 0.8959 - val_loss: 0.5691 - val_custom_f1: 0.7750\n",
            "Epoch 34: lr: 9.999999747378752e-05\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.2134 - custom_f1: 0.9339 - val_loss: 1.3419 - val_custom_f1: 0.7742\n",
            "Epoch 35: lr: 9.999999747378752e-05\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1114 - custom_f1: 0.9678 - val_loss: 0.6892 - val_custom_f1: 0.8286\n",
            "Epoch 36: lr: 9.999999747378752e-05\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1395 - custom_f1: 0.9559 - val_loss: 39.4886 - val_custom_f1: 0.7534\n",
            "Epoch 37: lr: 9.999999747378752e-05\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0874 - custom_f1: 0.9730 - val_loss: 10.2934 - val_custom_f1: 0.0000e+00\n",
            "Epoch 38: lr: 9.999999747378752e-05\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0835 - custom_f1: 0.9767 - val_loss: 1.3207 - val_custom_f1: 0.6083\n",
            "Epoch 39: lr: 9.999999747378752e-05\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0744 - custom_f1: 0.9810 - val_loss: 41.1633 - val_custom_f1: 0.7534\n",
            "Epoch 40: lr: 9.999999747378752e-05\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0400 - custom_f1: 0.9912 - val_loss: 0.1839 - val_custom_f1: 0.9167\n",
            "Epoch 41: lr: 9.999999747378752e-05\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0409 - custom_f1: 0.9912 - val_loss: 8.9771 - val_custom_f1: 0.7610\n",
            "Epoch 42: lr: 9.999999747378752e-05\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0862 - custom_f1: 0.9735 - val_loss: 0.4286 - val_custom_f1: 0.8769\n",
            "Epoch 43: lr: 9.999999747378752e-05\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0136 - custom_f1: 1.0000 - val_loss: 0.2711 - val_custom_f1: 0.9327\n",
            "Epoch 44: lr: 9.999999747378752e-05\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0073 - custom_f1: 1.0000 - val_loss: 0.2990 - val_custom_f1: 0.9327\n",
            "Epoch 45: lr: 9.999999747378752e-05\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0861 - custom_f1: 0.9823 - val_loss: 0.6871 - val_custom_f1: 0.7742\n",
            "Epoch 46: lr: 9.999999747378752e-05\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0503 - custom_f1: 0.9886 - val_loss: 10.3455 - val_custom_f1: 0.0000e+00\n",
            "Epoch 47: lr: 9.999999747378752e-05\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0940 - custom_f1: 0.9744 - val_loss: 134.6211 - val_custom_f1: 0.7534\n",
            "Epoch 48: lr: 9.999999747378752e-05\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1358 - custom_f1: 0.9515 - val_loss: 3.6792 - val_custom_f1: 0.7534\n",
            "Epoch 49: lr: 9.999999747378752e-05\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0532 - custom_f1: 0.9868 - val_loss: 1.6186 - val_custom_f1: 0.7821\n",
            "Epoch 50: lr: 9.999999747378752e-05\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0918 - custom_f1: 0.9815 - val_loss: 98.1571 - val_custom_f1: 0.7534\n",
            "Epoch 51: lr: 9.999999747378752e-05\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0583 - custom_f1: 0.9908\n",
            "lr is fixed to 9.999999747378752e-06\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0583 - custom_f1: 0.9908 - val_loss: 0.9142 - val_custom_f1: 0.8284\n",
            "Epoch 52: lr: 9.999999747378752e-06\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0839 - custom_f1: 0.9823 - val_loss: 0.2456 - val_custom_f1: 0.8952\n",
            "Epoch 53: lr: 9.999999747378752e-06\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0117 - custom_f1: 1.0000 - val_loss: 0.2047 - val_custom_f1: 0.9058\n",
            "Epoch 54: lr: 9.999999747378752e-06\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0108 - custom_f1: 1.0000 - val_loss: 0.2135 - val_custom_f1: 0.9058\n",
            "Epoch 55: lr: 9.999999747378752e-06\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0958 - custom_f1: 0.9705 - val_loss: 0.2319 - val_custom_f1: 0.8952\n",
            "Epoch 56: lr: 9.999999747378752e-06\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0668 - custom_f1: 0.9794 - val_loss: 0.1825 - val_custom_f1: 0.9273\n",
            "Epoch 57: lr: 9.999999747378752e-06\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.1100 - custom_f1: 0.9646 - val_loss: 0.1866 - val_custom_f1: 0.9058\n",
            "Epoch 58: lr: 9.999999747378752e-06\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0315 - custom_f1: 0.9912 - val_loss: 0.1752 - val_custom_f1: 0.9273\n",
            "Epoch 59: lr: 9.999999747378752e-06\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0686 - custom_f1: 0.9823 - val_loss: 0.2764 - val_custom_f1: 0.8754\n",
            "Epoch 60: lr: 9.999999747378752e-06\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0845 - custom_f1: 0.9646 - val_loss: 0.1931 - val_custom_f1: 0.8952\n",
            "Epoch 61: lr: 9.999999747378752e-06\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0506 - custom_f1: 0.9823 - val_loss: 0.1821 - val_custom_f1: 0.9384\n",
            "Epoch 62: lr: 9.999999747378752e-06\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0364 - custom_f1: 0.9912 - val_loss: 0.2847 - val_custom_f1: 0.8754\n",
            "Epoch 63: lr: 9.999999747378752e-06\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0417 - custom_f1: 0.9823 - val_loss: 0.1913 - val_custom_f1: 0.8851\n",
            "Epoch 64: lr: 9.999999747378752e-06\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 11s 100ms/step - loss: 0.0109 - custom_f1: 1.0000 - val_loss: 0.2293 - val_custom_f1: 0.8754\n",
            "Epoch 65: lr: 9.999999747378752e-06\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 12s 102ms/step - loss: 0.0267 - custom_f1: 0.9912 - val_loss: 0.2164 - val_custom_f1: 0.8851\n",
            "Epoch 66: lr: 9.999999747378752e-06\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0256 - custom_f1: 0.9912 - val_loss: 0.2041 - val_custom_f1: 0.8851\n",
            "Epoch 67: lr: 9.999999747378752e-06\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0278 - custom_f1: 0.9912 - val_loss: 0.2012 - val_custom_f1: 0.9167\n",
            "Epoch 68: lr: 9.999999747378752e-06\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0073 - custom_f1: 1.0000 - val_loss: 0.2203 - val_custom_f1: 0.8851\n",
            "Epoch 69: lr: 9.999999747378752e-06\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0249 - custom_f1: 0.9912 - val_loss: 0.2010 - val_custom_f1: 0.8952\n",
            "Epoch 70: lr: 9.999999747378752e-06\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0328 - custom_f1: 0.9912 - val_loss: 0.1781 - val_custom_f1: 0.9273\n",
            "Epoch 71: lr: 9.999999747378752e-06\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0063 - custom_f1: 1.0000 - val_loss: 0.2014 - val_custom_f1: 0.9065\n",
            "Epoch 72: lr: 9.999999747378752e-06\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0056 - custom_f1: 1.0000 - val_loss: 0.2230 - val_custom_f1: 0.9065\n",
            "Epoch 73: lr: 9.999999747378752e-06\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0940 - custom_f1: 0.9469 - val_loss: 0.2312 - val_custom_f1: 0.9444\n",
            "Epoch 74: lr: 9.999999747378752e-06\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0193 - custom_f1: 0.9912 - val_loss: 0.1959 - val_custom_f1: 0.9167\n",
            "Epoch 75: lr: 9.999999747378752e-06\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0170 - custom_f1: 0.9912 - val_loss: 0.2094 - val_custom_f1: 0.9167\n",
            "Epoch 76: lr: 9.999999747378752e-06\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0197 - custom_f1: 0.9912 - val_loss: 0.2234 - val_custom_f1: 0.9273\n",
            "Epoch 77: lr: 9.999999747378752e-06\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0242 - custom_f1: 0.9823 - val_loss: 0.2245 - val_custom_f1: 0.8851\n",
            "Epoch 78: lr: 9.999999747378752e-06\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 11s 98ms/step - loss: 0.0346 - custom_f1: 0.9735 - val_loss: 0.4211 - val_custom_f1: 0.8634\n",
            "Epoch 79: lr: 9.999999747378752e-06\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0251 - custom_f1: 0.9823 - val_loss: 0.2133 - val_custom_f1: 0.9444\n",
            "Epoch 80: lr: 9.999999747378752e-06\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0057 - custom_f1: 1.0000 - val_loss: 0.1963 - val_custom_f1: 0.9273\n",
            "Epoch 81: lr: 9.999999747378752e-06\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0037 - custom_f1: 1.0000 - val_loss: 0.2809 - val_custom_f1: 0.9065\n",
            "Epoch 82: lr: 9.999999747378752e-06\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0208 - custom_f1: 0.9823 - val_loss: 0.1961 - val_custom_f1: 0.9384\n",
            "Epoch 83: lr: 9.999999747378752e-06\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0042 - custom_f1: 1.0000 - val_loss: 0.1958 - val_custom_f1: 0.9273\n",
            "Epoch 84: lr: 9.999999747378752e-06\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0361 - custom_f1: 0.9735\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.0361 - custom_f1: 0.9735 - val_loss: 0.1704 - val_custom_f1: 0.9621\n",
            "Epoch 85: lr: 9.999999747378752e-06\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0185 - custom_f1: 0.9735 - val_loss: 0.1979 - val_custom_f1: 0.9273\n",
            "Epoch 86: lr: 9.999999747378752e-06\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0114 - custom_f1: 0.9912 - val_loss: 0.8239 - val_custom_f1: 0.8465\n",
            "Epoch 87: lr: 9.999999747378752e-06\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0090 - custom_f1: 0.9912 - val_loss: 0.1705 - val_custom_f1: 0.9384\n",
            "Epoch 88: lr: 9.999999747378752e-06\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0038 - custom_f1: 1.0000 - val_loss: 0.2389 - val_custom_f1: 0.9167\n",
            "Epoch 89: lr: 9.999999747378752e-06\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0137 - custom_f1: 0.9823 - val_loss: 0.4515 - val_custom_f1: 0.8377\n",
            "Epoch 90: lr: 9.999999747378752e-06\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0035 - custom_f1: 1.0000 - val_loss: 0.2219 - val_custom_f1: 0.9273\n",
            "Epoch 91: lr: 9.999999747378752e-06\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0069 - custom_f1: 0.9912 - val_loss: 0.2277 - val_custom_f1: 0.9167\n",
            "Epoch 92: lr: 9.999999747378752e-06\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0030 - custom_f1: 1.0000 - val_loss: 0.2199 - val_custom_f1: 0.9273\n",
            "Epoch 93: lr: 9.999999747378752e-06\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0027 - custom_f1: 1.0000 - val_loss: 0.3125 - val_custom_f1: 0.8754\n",
            "Epoch 94: lr: 9.999999747378752e-06\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0025 - custom_f1: 1.0000 - val_loss: 0.2613 - val_custom_f1: 0.8851\n",
            "Epoch 95: lr: 9.999999747378752e-06\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0073 - custom_f1: 0.9912 - val_loss: 0.1978 - val_custom_f1: 0.9273\n",
            "Epoch 96: lr: 9.999999747378752e-06\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0133 - custom_f1: 0.9735 - val_loss: 0.2869 - val_custom_f1: 0.8851\n",
            "Epoch 97: lr: 9.999999747378752e-06\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0058 - custom_f1: 0.9912 - val_loss: 0.1923 - val_custom_f1: 0.9273\n",
            "Epoch 98: lr: 9.999999747378752e-06\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0023 - custom_f1: 1.0000 - val_loss: 0.2103 - val_custom_f1: 0.9273\n",
            "Epoch 99: lr: 9.999999747378752e-06\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0109 - custom_f1: 0.9735 - val_loss: 0.2185 - val_custom_f1: 0.9273\n",
            "Epoch 100: lr: 9.999999747378752e-06\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 11s 99ms/step - loss: 0.0023 - custom_f1: 1.0000 - val_loss: 0.2313 - val_custom_f1: 0.9273\n",
            "weights are setted to best weights (epochs 84)\n",
            "######################\n",
            "##                  ##\n",
            "##    Test STEP     ##\n",
            "##                  ##\n",
            "######################\n",
            "Fold 1/10\n",
            "4/4 [==============================] - 3s 349ms/step\n",
            "Fold 2/10\n",
            "4/4 [==============================] - 0s 134ms/step\n",
            "Fold 3/10\n",
            "4/4 [==============================] - 0s 134ms/step\n",
            "Fold 4/10\n",
            "4/4 [==============================] - 0s 134ms/step\n",
            "Fold 5/10\n",
            "4/4 [==============================] - 0s 134ms/step\n",
            "Fold 6/10\n",
            "4/4 [==============================] - 0s 132ms/step\n",
            "Fold 7/10\n",
            "4/4 [==============================] - 0s 134ms/step\n",
            "Fold 8/10\n",
            "4/4 [==============================] - 0s 134ms/step\n",
            "Fold 9/10\n",
            "4/4 [==============================] - 1s 134ms/step\n",
            "Fold 10/10\n",
            "4/4 [==============================] - 0s 135ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow\n",
        "import tensorflow.keras.applications\n",
        "\n",
        "###CONFIG#####\n",
        "train = False\n",
        "im_size = (512,512)\n",
        "save = '/content/drive/MyDrive/SyntekaBio/weights'\n",
        "path = '/content/drive/MyDrive/SyntekaBio/train/PNG'\n",
        "epochs = 100\n",
        "batch_size = 4\n",
        "fold = 10\n",
        "lr = 1e-4\n",
        "###############\n",
        "\n",
        "data = data_load(path,input_shape = im_size) \n",
        "model = keras_resnet(im_size) \n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "#trainning step\n",
        "print('######################')\n",
        "print('##                  ##')\n",
        "print('##   Train Models   ##')\n",
        "print('##                  ##')\n",
        "print('######################')\n",
        "    \n",
        "training(data, model, \n",
        "        epochs = epochs,\n",
        "        batch_size = batch_size,\n",
        "        fold = fold, \n",
        "        save=save,\n",
        "        r=50, \n",
        "        decay=0.1,\n",
        "        lr = lr)\n",
        "\n",
        "\n",
        "#trainning step\n",
        "print('######################')\n",
        "print('##                  ##')\n",
        "print('##    Test STEP     ##')\n",
        "print('##                  ##')\n",
        "print('######################')\n",
        "testing(data, model, thr = 0.5, save=save)"
      ],
      "metadata": {
        "id": "C6Fz9R24cglE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8a504e43-edc5-4076-b5a3-f1e82ee3dfec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train img load...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 501/501 [00:20<00:00, 24.04it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test img load...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 126/126 [00:05<00:00, 24.27it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 512, 512, 3)]     0         \n",
            "                                                                 \n",
            " model_4 (Functional)        (None, 2048)              23564800  \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 2049      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,566,849\n",
            "Trainable params: 23,521,409\n",
            "Non-trainable params: 45,440\n",
            "_________________________________________________________________\n",
            "######################\n",
            "##                  ##\n",
            "##   Train Models   ##\n",
            "##                  ##\n",
            "######################\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 1 [0,50]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.5586 - custom_f1: 0.8062\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 17s 105ms/step - loss: 0.5586 - custom_f1: 0.8062 - val_loss: 7.5323 - val_custom_f1: 0.7846\n",
            "Epoch 2: lr: 9.999999747378752e-05\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.4191 - custom_f1: 0.8522 - val_loss: 17.0233 - val_custom_f1: 0.7846\n",
            "Epoch 3: lr: 9.999999747378752e-05\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.2844 - custom_f1: 0.9064 - val_loss: 43.7338 - val_custom_f1: 0.7846\n",
            "Epoch 4: lr: 9.999999747378752e-05\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.2516 - custom_f1: 0.9099 - val_loss: 20.8602 - val_custom_f1: 0.7846\n",
            "Epoch 5: lr: 9.999999747378752e-05\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.2348 - custom_f1: 0.9203 - val_loss: 7.8610 - val_custom_f1: 0.7846\n",
            "Epoch 6: lr: 9.999999747378752e-05\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.2917 - custom_f1: 0.8953\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 88ms/step - loss: 0.2917 - custom_f1: 0.8953 - val_loss: 5.7339 - val_custom_f1: 0.7846\n",
            "Epoch 7: lr: 9.999999747378752e-05\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1781 - custom_f1: 0.9341\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 9s 82ms/step - loss: 0.1781 - custom_f1: 0.9341 - val_loss: 0.4804 - val_custom_f1: 0.8871\n",
            "Epoch 8: lr: 9.999999747378752e-05\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.2121 - custom_f1: 0.9270 - val_loss: 6.3902 - val_custom_f1: 0.0000e+00\n",
            "Epoch 9: lr: 9.999999747378752e-05\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.2303 - custom_f1: 0.9279 - val_loss: 3.3121 - val_custom_f1: 0.0000e+00\n",
            "Epoch 10: lr: 9.999999747378752e-05\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1704 - custom_f1: 0.9435\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 89ms/step - loss: 0.1704 - custom_f1: 0.9435 - val_loss: 0.4792 - val_custom_f1: 0.7847\n",
            "Epoch 11: lr: 9.999999747378752e-05\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1385 - custom_f1: 0.9583 - val_loss: 2.9601 - val_custom_f1: 0.0476\n",
            "Epoch 12: lr: 9.999999747378752e-05\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1611 - custom_f1: 0.9547 - val_loss: 1.3566 - val_custom_f1: 0.8138\n",
            "Epoch 13: lr: 9.999999747378752e-05\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1246 - custom_f1: 0.9642\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 90ms/step - loss: 0.1246 - custom_f1: 0.9642 - val_loss: 0.3953 - val_custom_f1: 0.7667\n",
            "Epoch 14: lr: 9.999999747378752e-05\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1354 - custom_f1: 0.9440 - val_loss: 0.5951 - val_custom_f1: 0.8486\n",
            "Epoch 15: lr: 9.999999747378752e-05\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1344 - custom_f1: 0.9528 - val_loss: 1.7721 - val_custom_f1: 0.2436\n",
            "Epoch 16: lr: 9.999999747378752e-05\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1537 - custom_f1: 0.9594 - val_loss: 0.7247 - val_custom_f1: 0.7097\n",
            "Epoch 17: lr: 9.999999747378752e-05\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1092 - custom_f1: 0.9684\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 90ms/step - loss: 0.1092 - custom_f1: 0.9684 - val_loss: 0.3691 - val_custom_f1: 0.8738\n",
            "Epoch 18: lr: 9.999999747378752e-05\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0688 - custom_f1: 0.9821 - val_loss: 0.3893 - val_custom_f1: 0.8924\n",
            "Epoch 19: lr: 9.999999747378752e-05\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1716 - custom_f1: 0.9494 - val_loss: 0.4538 - val_custom_f1: 0.7927\n",
            "Epoch 20: lr: 9.999999747378752e-05\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1310 - custom_f1: 0.9577\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 90ms/step - loss: 0.1310 - custom_f1: 0.9577 - val_loss: 0.2959 - val_custom_f1: 0.8982\n",
            "Epoch 21: lr: 9.999999747378752e-05\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0957 - custom_f1: 0.9745 - val_loss: 0.3203 - val_custom_f1: 0.8893\n",
            "Epoch 22: lr: 9.999999747378752e-05\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0843 - custom_f1: 0.9772 - val_loss: 0.3840 - val_custom_f1: 0.8871\n",
            "Epoch 23: lr: 9.999999747378752e-05\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1102 - custom_f1: 0.9627 - val_loss: 1.6844 - val_custom_f1: 0.3736\n",
            "Epoch 24: lr: 9.999999747378752e-05\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1020 - custom_f1: 0.9779 - val_loss: 0.5256 - val_custom_f1: 0.7083\n",
            "Epoch 25: lr: 9.999999747378752e-05\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1048 - custom_f1: 0.9605 - val_loss: 0.6272 - val_custom_f1: 0.8241\n",
            "Epoch 26: lr: 9.999999747378752e-05\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0572 - custom_f1: 0.9886 - val_loss: 0.3504 - val_custom_f1: 0.8848\n",
            "Epoch 27: lr: 9.999999747378752e-05\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0497 - custom_f1: 0.9896 - val_loss: 0.3189 - val_custom_f1: 0.8444\n",
            "Epoch 28: lr: 9.999999747378752e-05\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0275 - custom_f1: 0.9975 - val_loss: 1.3551 - val_custom_f1: 0.8059\n",
            "Epoch 29: lr: 9.999999747378752e-05\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0146 - custom_f1: 0.9987 - val_loss: 0.3284 - val_custom_f1: 0.8591\n",
            "Epoch 30: lr: 9.999999747378752e-05\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0369 - custom_f1: 0.9864 - val_loss: 0.3131 - val_custom_f1: 0.8706\n",
            "Epoch 31: lr: 9.999999747378752e-05\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0527 - custom_f1: 0.9763 - val_loss: 1.3998 - val_custom_f1: 0.4308\n",
            "Epoch 32: lr: 9.999999747378752e-05\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0607 - custom_f1: 0.9864 - val_loss: 0.6247 - val_custom_f1: 0.7222\n",
            "Epoch 33: lr: 9.999999747378752e-05\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1602 - custom_f1: 0.9489 - val_loss: 0.4459 - val_custom_f1: 0.8549\n",
            "Epoch 34: lr: 9.999999747378752e-05\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - 9s 76ms/step - loss: 0.0738 - custom_f1: 0.9737 - val_loss: 0.4124 - val_custom_f1: 0.8530\n",
            "Epoch 35: lr: 9.999999747378752e-05\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0752 - custom_f1: 0.9733 - val_loss: 0.5123 - val_custom_f1: 0.7059\n",
            "Epoch 36: lr: 9.999999747378752e-05\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1136 - custom_f1: 0.9597 - val_loss: 0.6776 - val_custom_f1: 0.6000\n",
            "Epoch 37: lr: 9.999999747378752e-05\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0774 - custom_f1: 0.9738 - val_loss: 0.5541 - val_custom_f1: 0.7602\n",
            "Epoch 38: lr: 9.999999747378752e-05\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0567 - custom_f1: 0.9886 - val_loss: 2.0329 - val_custom_f1: 0.0000e+00\n",
            "Epoch 39: lr: 9.999999747378752e-05\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0666 - custom_f1: 0.9699 - val_loss: 0.3702 - val_custom_f1: 0.8634\n",
            "Epoch 40: lr: 9.999999747378752e-05\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0412 - custom_f1: 0.9881 - val_loss: 0.5120 - val_custom_f1: 0.8199\n",
            "Epoch 41: lr: 9.999999747378752e-05\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0242 - custom_f1: 0.9912 - val_loss: 0.5401 - val_custom_f1: 0.8675\n",
            "Epoch 42: lr: 9.999999747378752e-05\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0368 - custom_f1: 0.9722 - val_loss: 0.6897 - val_custom_f1: 0.6881\n",
            "Epoch 43: lr: 9.999999747378752e-05\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0116 - custom_f1: 0.9912 - val_loss: 0.4599 - val_custom_f1: 0.8080\n",
            "Epoch 44: lr: 9.999999747378752e-05\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0028 - custom_f1: 0.9912 - val_loss: 0.5509 - val_custom_f1: 0.7636\n",
            "Epoch 45: lr: 9.999999747378752e-05\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0062 - custom_f1: 0.9823 - val_loss: 0.5937 - val_custom_f1: 0.7976\n",
            "Epoch 46: lr: 9.999999747378752e-05\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0186 - custom_f1: 0.9781 - val_loss: 1.0942 - val_custom_f1: 0.8782\n",
            "Epoch 47: lr: 9.999999747378752e-05\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0367 - custom_f1: 0.9823 - val_loss: 0.4311 - val_custom_f1: 0.8763\n",
            "Epoch 48: lr: 9.999999747378752e-05\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0192 - custom_f1: 0.9911 - val_loss: 0.5462 - val_custom_f1: 0.8346\n",
            "Epoch 49: lr: 9.999999747378752e-05\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0173 - custom_f1: 0.9735 - val_loss: 0.3911 - val_custom_f1: 0.8944\n",
            "Epoch 50: lr: 9.999999747378752e-05\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0089 - custom_f1: 0.9823 - val_loss: 0.5138 - val_custom_f1: 0.7658\n",
            "Epoch 51: lr: 9.999999747378752e-05\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0469 - custom_f1: 0.9776\n",
            "lr is fixed to 9.999999747378752e-06\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0469 - custom_f1: 0.9776 - val_loss: 0.9512 - val_custom_f1: 0.5357\n",
            "Epoch 52: lr: 9.999999747378752e-06\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0397 - custom_f1: 0.9658 - val_loss: 0.3984 - val_custom_f1: 0.8413\n",
            "Epoch 53: lr: 9.999999747378752e-06\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0071 - custom_f1: 0.9912 - val_loss: 0.4105 - val_custom_f1: 0.8924\n",
            "Epoch 54: lr: 9.999999747378752e-06\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0062 - custom_f1: 0.9912 - val_loss: 0.4079 - val_custom_f1: 0.8924\n",
            "Epoch 55: lr: 9.999999747378752e-06\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0052 - custom_f1: 0.9912 - val_loss: 0.3938 - val_custom_f1: 0.8924\n",
            "Epoch 56: lr: 9.999999747378752e-06\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0096 - custom_f1: 0.9912 - val_loss: 0.3844 - val_custom_f1: 0.8690\n",
            "Epoch 57: lr: 9.999999747378752e-06\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0036 - custom_f1: 0.9912 - val_loss: 0.3881 - val_custom_f1: 0.8690\n",
            "Epoch 58: lr: 9.999999747378752e-06\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0021 - custom_f1: 1.0000 - val_loss: 0.3997 - val_custom_f1: 0.8924\n",
            "Epoch 59: lr: 9.999999747378752e-06\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0029 - custom_f1: 0.9912 - val_loss: 0.3879 - val_custom_f1: 0.8924\n",
            "Epoch 60: lr: 9.999999747378752e-06\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0047 - custom_f1: 0.9823 - val_loss: 0.3731 - val_custom_f1: 0.8690\n",
            "Epoch 61: lr: 9.999999747378752e-06\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0036 - custom_f1: 0.9823 - val_loss: 0.3855 - val_custom_f1: 0.8690\n",
            "Epoch 62: lr: 9.999999747378752e-06\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0037 - custom_f1: 0.9735 - val_loss: 0.3773 - val_custom_f1: 0.8557\n",
            "Epoch 63: lr: 9.999999747378752e-06\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0020 - custom_f1: 0.9823 - val_loss: 0.3793 - val_custom_f1: 0.8690\n",
            "Epoch 64: lr: 9.999999747378752e-06\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0013 - custom_f1: 1.0000 - val_loss: 0.3890 - val_custom_f1: 0.8690\n",
            "Epoch 65: lr: 9.999999747378752e-06\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0012 - custom_f1: 1.0000 - val_loss: 0.3992 - val_custom_f1: 0.8924\n",
            "Epoch 66: lr: 9.999999747378752e-06\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0013 - custom_f1: 0.9912 - val_loss: 0.3938 - val_custom_f1: 0.8924\n",
            "Epoch 67: lr: 9.999999747378752e-06\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0011 - custom_f1: 0.9912 - val_loss: 0.3918 - val_custom_f1: 0.8924\n",
            "Epoch 68: lr: 9.999999747378752e-06\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0030 - custom_f1: 0.9646 - val_loss: 0.3729 - val_custom_f1: 0.8690\n",
            "Epoch 69: lr: 9.999999747378752e-06\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.4577e-04 - custom_f1: 1.0000 - val_loss: 0.3833 - val_custom_f1: 0.8924\n",
            "Epoch 70: lr: 9.999999747378752e-06\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0011 - custom_f1: 0.9912 - val_loss: 0.3836 - val_custom_f1: 0.8924\n",
            "Epoch 71: lr: 9.999999747378752e-06\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0014 - custom_f1: 0.9735 - val_loss: 0.3734 - val_custom_f1: 0.8690\n",
            "Epoch 72: lr: 9.999999747378752e-06\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 8.5850e-04 - custom_f1: 1.0000 - val_loss: 0.3912 - val_custom_f1: 0.8924\n",
            "Epoch 73: lr: 9.999999747378752e-06\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0022 - custom_f1: 0.9646 - val_loss: 0.3602 - val_custom_f1: 0.8690\n",
            "Epoch 74: lr: 9.999999747378752e-06\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 8.5228e-04 - custom_f1: 0.9823 - val_loss: 0.3643 - val_custom_f1: 0.8924\n",
            "Epoch 75: lr: 9.999999747378752e-06\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0014 - custom_f1: 0.9735 - val_loss: 0.3520 - val_custom_f1: 0.8690\n",
            "Epoch 76: lr: 9.999999747378752e-06\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.6995e-04 - custom_f1: 0.9823 - val_loss: 0.3590 - val_custom_f1: 0.8690\n",
            "Epoch 77: lr: 9.999999747378752e-06\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.5158e-04 - custom_f1: 0.9912 - val_loss: 0.3684 - val_custom_f1: 0.8924\n",
            "Epoch 78: lr: 9.999999747378752e-06\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0018 - custom_f1: 0.9646 - val_loss: 0.3665 - val_custom_f1: 0.8690\n",
            "Epoch 79: lr: 9.999999747378752e-06\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.9004e-04 - custom_f1: 0.9912 - val_loss: 0.3760 - val_custom_f1: 0.8690\n",
            "Epoch 80: lr: 9.999999747378752e-06\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.4195e-04 - custom_f1: 0.9912 - val_loss: 0.3703 - val_custom_f1: 0.8690\n",
            "Epoch 81: lr: 9.999999747378752e-06\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.9589e-04 - custom_f1: 0.9912 - val_loss: 0.3695 - val_custom_f1: 0.8690\n",
            "Epoch 82: lr: 9.999999747378752e-06\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.4316e-04 - custom_f1: 0.9823 - val_loss: 0.3723 - val_custom_f1: 0.8690\n",
            "Epoch 83: lr: 9.999999747378752e-06\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.2027e-04 - custom_f1: 0.9912 - val_loss: 0.3718 - val_custom_f1: 0.8690\n",
            "Epoch 84: lr: 9.999999747378752e-06\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.7709e-04 - custom_f1: 0.9912 - val_loss: 0.3690 - val_custom_f1: 0.8690\n",
            "Epoch 85: lr: 9.999999747378752e-06\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.5294e-04 - custom_f1: 0.9912 - val_loss: 0.3631 - val_custom_f1: 0.8690\n",
            "Epoch 86: lr: 9.999999747378752e-06\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.9557e-04 - custom_f1: 0.9912 - val_loss: 0.3601 - val_custom_f1: 0.8690\n",
            "Epoch 87: lr: 9.999999747378752e-06\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.6550e-04 - custom_f1: 0.9823 - val_loss: 0.3632 - val_custom_f1: 0.8690\n",
            "Epoch 88: lr: 9.999999747378752e-06\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.9706e-04 - custom_f1: 0.9912 - val_loss: 0.3678 - val_custom_f1: 0.8690\n",
            "Epoch 89: lr: 9.999999747378752e-06\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.5675e-04 - custom_f1: 0.9912 - val_loss: 0.3760 - val_custom_f1: 0.8712\n",
            "Epoch 90: lr: 9.999999747378752e-06\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.8477e-04 - custom_f1: 0.9912 - val_loss: 0.3680 - val_custom_f1: 0.8712\n",
            "Epoch 91: lr: 9.999999747378752e-06\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.7762e-04 - custom_f1: 0.9735 - val_loss: 0.3576 - val_custom_f1: 0.8585\n",
            "Epoch 92: lr: 9.999999747378752e-06\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.6799e-04 - custom_f1: 1.0000 - val_loss: 0.3741 - val_custom_f1: 0.8712\n",
            "Epoch 93: lr: 9.999999747378752e-06\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.0719e-04 - custom_f1: 0.9912 - val_loss: 0.3746 - val_custom_f1: 0.8712\n",
            "Epoch 94: lr: 9.999999747378752e-06\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.1138e-04 - custom_f1: 0.9469 - val_loss: 0.3551 - val_custom_f1: 0.8690\n",
            "Epoch 95: lr: 9.999999747378752e-06\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.6907e-04 - custom_f1: 0.9735 - val_loss: 0.3646 - val_custom_f1: 0.8712\n",
            "Epoch 96: lr: 9.999999747378752e-06\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.1855e-04 - custom_f1: 0.9823 - val_loss: 0.3759 - val_custom_f1: 0.8712\n",
            "Epoch 97: lr: 9.999999747378752e-06\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.6323e-04 - custom_f1: 0.9912 - val_loss: 0.3748 - val_custom_f1: 0.8712\n",
            "Epoch 98: lr: 9.999999747378752e-06\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.0936e-04 - custom_f1: 0.9823 - val_loss: 0.3687 - val_custom_f1: 0.8712\n",
            "Epoch 99: lr: 9.999999747378752e-06\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.4305e-04 - custom_f1: 0.9735 - val_loss: 0.3434 - val_custom_f1: 0.8585\n",
            "Epoch 100: lr: 9.999999747378752e-06\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.0487e-04 - custom_f1: 0.9912 - val_loss: 0.3498 - val_custom_f1: 0.8585\n",
            "weights are setted to best weights (epochs 20)\n",
            "fold 2 [50,100]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.5825 - custom_f1: 0.8047\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 9s 83ms/step - loss: 0.5825 - custom_f1: 0.8047 - val_loss: 22.4574 - val_custom_f1: 0.7646\n",
            "Epoch 2: lr: 9.999999747378752e-05\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.3667 - custom_f1: 0.8681\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 88ms/step - loss: 0.3667 - custom_f1: 0.8681 - val_loss: 20.4560 - val_custom_f1: 0.7646\n",
            "Epoch 3: lr: 9.999999747378752e-05\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.2647 - custom_f1: 0.9019\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 92ms/step - loss: 0.2647 - custom_f1: 0.9019 - val_loss: 18.3297 - val_custom_f1: 0.7646\n",
            "Epoch 4: lr: 9.999999747378752e-05\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.2179 - custom_f1: 0.9188 - val_loss: 21.6132 - val_custom_f1: 0.7646\n",
            "Epoch 5: lr: 9.999999747378752e-05\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1329 - custom_f1: 0.9537\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 92ms/step - loss: 0.1329 - custom_f1: 0.9537 - val_loss: 7.4393 - val_custom_f1: 0.7646\n",
            "Epoch 6: lr: 9.999999747378752e-05\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.2221 - custom_f1: 0.9187\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 9s 81ms/step - loss: 0.2221 - custom_f1: 0.9187 - val_loss: 0.8237 - val_custom_f1: 0.8314\n",
            "Epoch 7: lr: 9.999999747378752e-05\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0982 - custom_f1: 0.9633\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 89ms/step - loss: 0.0982 - custom_f1: 0.9633 - val_loss: 0.6123 - val_custom_f1: 0.8611\n",
            "Epoch 8: lr: 9.999999747378752e-05\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1157 - custom_f1: 0.9617 - val_loss: 1.8925 - val_custom_f1: 0.4519\n",
            "Epoch 9: lr: 9.999999747378752e-05\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1267 - custom_f1: 0.9610\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 88ms/step - loss: 0.1267 - custom_f1: 0.9610 - val_loss: 0.4132 - val_custom_f1: 0.8564\n",
            "Epoch 10: lr: 9.999999747378752e-05\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1139 - custom_f1: 0.9692 - val_loss: 0.4552 - val_custom_f1: 0.9000\n",
            "Epoch 11: lr: 9.999999747378752e-05\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1055 - custom_f1: 0.9742 - val_loss: 0.5233 - val_custom_f1: 0.8756\n",
            "Epoch 12: lr: 9.999999747378752e-05\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0864 - custom_f1: 0.9684 - val_loss: 0.4994 - val_custom_f1: 0.8557\n",
            "Epoch 13: lr: 9.999999747378752e-05\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0909 - custom_f1: 0.9756 - val_loss: 0.4240 - val_custom_f1: 0.8341\n",
            "Epoch 14: lr: 9.999999747378752e-05\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0416 - custom_f1: 0.9913 - val_loss: 0.5032 - val_custom_f1: 0.8286\n",
            "Epoch 15: lr: 9.999999747378752e-05\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0528 - custom_f1: 0.9853 - val_loss: 0.5128 - val_custom_f1: 0.7833\n",
            "Epoch 16: lr: 9.999999747378752e-05\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0466 - custom_f1: 0.9852 - val_loss: 0.4428 - val_custom_f1: 0.8690\n",
            "Epoch 17: lr: 9.999999747378752e-05\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0429 - custom_f1: 0.9853 - val_loss: 0.6646 - val_custom_f1: 0.7418\n",
            "Epoch 18: lr: 9.999999747378752e-05\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0738 - custom_f1: 0.9721 - val_loss: 2.3254 - val_custom_f1: 0.8017\n",
            "Epoch 19: lr: 9.999999747378752e-05\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0219 - custom_f1: 0.9987 - val_loss: 0.9512 - val_custom_f1: 0.8172\n",
            "Epoch 20: lr: 9.999999747378752e-05\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0492 - custom_f1: 0.9717\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 88ms/step - loss: 0.0492 - custom_f1: 0.9717 - val_loss: 0.4072 - val_custom_f1: 0.8432\n",
            "Epoch 21: lr: 9.999999747378752e-05\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0216 - custom_f1: 0.9882\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 9s 82ms/step - loss: 0.0216 - custom_f1: 0.9882 - val_loss: 0.4039 - val_custom_f1: 0.8690\n",
            "Epoch 22: lr: 9.999999747378752e-05\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0163 - custom_f1: 0.9912 - val_loss: 0.5092 - val_custom_f1: 0.8611\n",
            "Epoch 23: lr: 9.999999747378752e-05\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0424 - custom_f1: 0.9912\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 89ms/step - loss: 0.0424 - custom_f1: 0.9912 - val_loss: 0.3405 - val_custom_f1: 0.8634\n",
            "Epoch 24: lr: 9.999999747378752e-05\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0156 - custom_f1: 0.9882 - val_loss: 0.7642 - val_custom_f1: 0.8017\n",
            "Epoch 25: lr: 9.999999747378752e-05\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0048 - custom_f1: 1.0000 - val_loss: 0.5276 - val_custom_f1: 0.8411\n",
            "Epoch 26: lr: 9.999999747378752e-05\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0266 - custom_f1: 0.9793 - val_loss: 0.5326 - val_custom_f1: 0.8514\n",
            "Epoch 27: lr: 9.999999747378752e-05\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0027 - custom_f1: 1.0000 - val_loss: 0.4024 - val_custom_f1: 0.8499\n",
            "Epoch 28: lr: 9.999999747378752e-05\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0067 - custom_f1: 0.9912 - val_loss: 0.8810 - val_custom_f1: 0.6261\n",
            "Epoch 29: lr: 9.999999747378752e-05\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0068 - custom_f1: 1.0000 - val_loss: 0.4022 - val_custom_f1: 0.8493\n",
            "Epoch 30: lr: 9.999999747378752e-05\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0064 - custom_f1: 0.9912 - val_loss: 0.5482 - val_custom_f1: 0.8476\n",
            "Epoch 31: lr: 9.999999747378752e-05\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0620 - custom_f1: 0.9734 - val_loss: 0.6303 - val_custom_f1: 0.7421\n",
            "Epoch 32: lr: 9.999999747378752e-05\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0216 - custom_f1: 0.9987 - val_loss: 1.1236 - val_custom_f1: 0.6624\n",
            "Epoch 33: lr: 9.999999747378752e-05\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0188 - custom_f1: 0.9912 - val_loss: 0.5572 - val_custom_f1: 0.8029\n",
            "Epoch 34: lr: 9.999999747378752e-05\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0338 - custom_f1: 0.9940 - val_loss: 0.5472 - val_custom_f1: 0.8291\n",
            "Epoch 35: lr: 9.999999747378752e-05\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0226 - custom_f1: 0.9912 - val_loss: 0.4922 - val_custom_f1: 0.8402\n",
            "Epoch 36: lr: 9.999999747378752e-05\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0116 - custom_f1: 0.9899 - val_loss: 0.5069 - val_custom_f1: 0.8904\n",
            "Epoch 37: lr: 9.999999747378752e-05\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0688 - custom_f1: 0.9671 - val_loss: 0.4361 - val_custom_f1: 0.8890\n",
            "Epoch 38: lr: 9.999999747378752e-05\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0252 - custom_f1: 0.9930 - val_loss: 0.4549 - val_custom_f1: 0.8634\n",
            "Epoch 39: lr: 9.999999747378752e-05\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0167 - custom_f1: 0.9823 - val_loss: 0.7721 - val_custom_f1: 0.8172\n",
            "Epoch 40: lr: 9.999999747378752e-05\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0090 - custom_f1: 0.9823 - val_loss: 0.5079 - val_custom_f1: 0.7875\n",
            "Epoch 41: lr: 9.999999747378752e-05\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0046 - custom_f1: 0.9823 - val_loss: 0.5329 - val_custom_f1: 0.8848\n",
            "Epoch 42: lr: 9.999999747378752e-05\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0017 - custom_f1: 0.9912 - val_loss: 0.5001 - val_custom_f1: 0.9014\n",
            "Epoch 43: lr: 9.999999747378752e-05\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0036 - custom_f1: 0.9735 - val_loss: 0.6672 - val_custom_f1: 0.8411\n",
            "Epoch 44: lr: 9.999999747378752e-05\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.5022e-04 - custom_f1: 0.9912 - val_loss: 0.5118 - val_custom_f1: 0.8939\n",
            "Epoch 45: lr: 9.999999747378752e-05\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.3264e-04 - custom_f1: 0.9912 - val_loss: 0.6038 - val_custom_f1: 0.8565\n",
            "Epoch 46: lr: 9.999999747378752e-05\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.1751e-04 - custom_f1: 1.0000 - val_loss: 0.5977 - val_custom_f1: 0.8732\n",
            "Epoch 47: lr: 9.999999747378752e-05\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.3777e-04 - custom_f1: 0.9735 - val_loss: 0.5454 - val_custom_f1: 0.8833\n",
            "Epoch 48: lr: 9.999999747378752e-05\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.7418e-04 - custom_f1: 0.9823 - val_loss: 0.5653 - val_custom_f1: 0.8732\n",
            "Epoch 49: lr: 9.999999747378752e-05\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.5717e-04 - custom_f1: 1.0000 - val_loss: 0.6061 - val_custom_f1: 0.8565\n",
            "Epoch 50: lr: 9.999999747378752e-05\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.5205e-04 - custom_f1: 0.9912 - val_loss: 0.5533 - val_custom_f1: 0.8833\n",
            "Epoch 51: lr: 9.999999747378752e-05\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 1.4336e-04 - custom_f1: 1.0000\n",
            "lr is fixed to 9.999999747378752e-06\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.4336e-04 - custom_f1: 1.0000 - val_loss: 0.5950 - val_custom_f1: 0.8565\n",
            "Epoch 52: lr: 9.999999747378752e-06\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.3704e-04 - custom_f1: 0.9735 - val_loss: 0.5738 - val_custom_f1: 0.8732\n",
            "Epoch 53: lr: 9.999999747378752e-06\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.5456e-04 - custom_f1: 0.9912 - val_loss: 0.5946 - val_custom_f1: 0.8565\n",
            "Epoch 54: lr: 9.999999747378752e-06\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.1241e-04 - custom_f1: 0.9646 - val_loss: 0.5813 - val_custom_f1: 0.8565\n",
            "Epoch 55: lr: 9.999999747378752e-06\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.2869e-04 - custom_f1: 0.9912 - val_loss: 0.5917 - val_custom_f1: 0.8565\n",
            "Epoch 56: lr: 9.999999747378752e-06\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 1.2719e-04 - custom_f1: 1.0000 - val_loss: 0.6092 - val_custom_f1: 0.8565\n",
            "Epoch 57: lr: 9.999999747378752e-06\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.2767e-04 - custom_f1: 0.9735 - val_loss: 0.6128 - val_custom_f1: 0.8468\n",
            "Epoch 58: lr: 9.999999747378752e-06\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.0335e-04 - custom_f1: 1.0000 - val_loss: 0.6238 - val_custom_f1: 0.8468\n",
            "Epoch 59: lr: 9.999999747378752e-06\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.7659e-05 - custom_f1: 1.0000 - val_loss: 0.6220 - val_custom_f1: 0.8468\n",
            "Epoch 60: lr: 9.999999747378752e-06\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 3.7807e-04 - custom_f1: 0.9558 - val_loss: 0.6041 - val_custom_f1: 0.8565\n",
            "Epoch 61: lr: 9.999999747378752e-06\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.2947e-04 - custom_f1: 1.0000 - val_loss: 0.6059 - val_custom_f1: 0.8565\n",
            "Epoch 62: lr: 9.999999747378752e-06\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.7819e-04 - custom_f1: 0.9912 - val_loss: 0.6068 - val_custom_f1: 0.8565\n",
            "Epoch 63: lr: 9.999999747378752e-06\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.4798e-04 - custom_f1: 0.9912 - val_loss: 0.6006 - val_custom_f1: 0.8565\n",
            "Epoch 64: lr: 9.999999747378752e-06\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.7980e-04 - custom_f1: 0.9823 - val_loss: 0.5969 - val_custom_f1: 0.8565\n",
            "Epoch 65: lr: 9.999999747378752e-06\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.5969e-04 - custom_f1: 0.9912 - val_loss: 0.5987 - val_custom_f1: 0.8565\n",
            "Epoch 66: lr: 9.999999747378752e-06\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.5679e-04 - custom_f1: 0.9912 - val_loss: 0.6073 - val_custom_f1: 0.8468\n",
            "Epoch 67: lr: 9.999999747378752e-06\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.4122e-04 - custom_f1: 0.9912 - val_loss: 0.6013 - val_custom_f1: 0.8565\n",
            "Epoch 68: lr: 9.999999747378752e-06\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.3850e-04 - custom_f1: 0.9823 - val_loss: 0.6045 - val_custom_f1: 0.8565\n",
            "Epoch 69: lr: 9.999999747378752e-06\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.5852e-04 - custom_f1: 0.9912 - val_loss: 0.5963 - val_custom_f1: 0.8565\n",
            "Epoch 70: lr: 9.999999747378752e-06\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.9408e-04 - custom_f1: 0.9912 - val_loss: 0.5759 - val_custom_f1: 0.8833\n",
            "Epoch 71: lr: 9.999999747378752e-06\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.8807e-04 - custom_f1: 0.9735 - val_loss: 0.6015 - val_custom_f1: 0.8565\n",
            "Epoch 72: lr: 9.999999747378752e-06\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.1017e-04 - custom_f1: 1.0000 - val_loss: 0.6056 - val_custom_f1: 0.8468\n",
            "Epoch 73: lr: 9.999999747378752e-06\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.4651e-04 - custom_f1: 0.9912 - val_loss: 0.6128 - val_custom_f1: 0.8468\n",
            "Epoch 74: lr: 9.999999747378752e-06\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.1563e-04 - custom_f1: 0.9646 - val_loss: 0.5933 - val_custom_f1: 0.8565\n",
            "Epoch 75: lr: 9.999999747378752e-06\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.0186e-04 - custom_f1: 0.9912 - val_loss: 0.6091 - val_custom_f1: 0.8468\n",
            "Epoch 76: lr: 9.999999747378752e-06\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.1072e-04 - custom_f1: 0.9646 - val_loss: 0.5999 - val_custom_f1: 0.8468\n",
            "Epoch 77: lr: 9.999999747378752e-06\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.2399e-04 - custom_f1: 0.9735 - val_loss: 0.6139 - val_custom_f1: 0.8468\n",
            "Epoch 78: lr: 9.999999747378752e-06\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.0156e-04 - custom_f1: 0.9823 - val_loss: 0.6156 - val_custom_f1: 0.8468\n",
            "Epoch 79: lr: 9.999999747378752e-06\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 8.9995e-05 - custom_f1: 1.0000 - val_loss: 0.6359 - val_custom_f1: 0.8314\n",
            "Epoch 80: lr: 9.999999747378752e-06\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.3509e-04 - custom_f1: 0.9912 - val_loss: 0.6385 - val_custom_f1: 0.8314\n",
            "Epoch 81: lr: 9.999999747378752e-06\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.5132e-04 - custom_f1: 0.9823 - val_loss: 0.6385 - val_custom_f1: 0.8314\n",
            "Epoch 82: lr: 9.999999747378752e-06\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.4507e-05 - custom_f1: 1.0000 - val_loss: 0.6470 - val_custom_f1: 0.8314\n",
            "Epoch 83: lr: 9.999999747378752e-06\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 6.8599e-05 - custom_f1: 1.0000 - val_loss: 0.6532 - val_custom_f1: 0.8314\n",
            "Epoch 84: lr: 9.999999747378752e-06\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.2763e-05 - custom_f1: 1.0000 - val_loss: 0.6570 - val_custom_f1: 0.8314\n",
            "Epoch 85: lr: 9.999999747378752e-06\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.0633e-04 - custom_f1: 0.9912 - val_loss: 0.6350 - val_custom_f1: 0.8468\n",
            "Epoch 86: lr: 9.999999747378752e-06\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.6345e-05 - custom_f1: 0.9912 - val_loss: 0.6422 - val_custom_f1: 0.8314\n",
            "Epoch 87: lr: 9.999999747378752e-06\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.1732e-04 - custom_f1: 0.9646 - val_loss: 0.5211 - val_custom_f1: 0.8833\n",
            "Epoch 88: lr: 9.999999747378752e-06\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.8647e-05 - custom_f1: 0.9912 - val_loss: 0.5641 - val_custom_f1: 0.8732\n",
            "Epoch 89: lr: 9.999999747378752e-06\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.7432e-04 - custom_f1: 0.9735 - val_loss: 0.6079 - val_custom_f1: 0.8635\n",
            "Epoch 90: lr: 9.999999747378752e-06\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.4053e-04 - custom_f1: 0.9735 - val_loss: 0.6251 - val_custom_f1: 0.8314\n",
            "Epoch 91: lr: 9.999999747378752e-06\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.1316e-04 - custom_f1: 0.9735 - val_loss: 0.6335 - val_custom_f1: 0.8314\n",
            "Epoch 92: lr: 9.999999747378752e-06\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 8.6166e-05 - custom_f1: 0.9912 - val_loss: 0.6748 - val_custom_f1: 0.8314\n",
            "Epoch 93: lr: 9.999999747378752e-06\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.6374e-05 - custom_f1: 1.0000 - val_loss: 0.6530 - val_custom_f1: 0.8314\n",
            "Epoch 94: lr: 9.999999747378752e-06\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 8.3510e-05 - custom_f1: 0.9823 - val_loss: 0.6560 - val_custom_f1: 0.8314\n",
            "Epoch 95: lr: 9.999999747378752e-06\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 8.0880e-05 - custom_f1: 0.9646 - val_loss: 0.6503 - val_custom_f1: 0.8314\n",
            "Epoch 96: lr: 9.999999747378752e-06\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.4661e-05 - custom_f1: 0.9912 - val_loss: 0.6327 - val_custom_f1: 0.8468\n",
            "Epoch 97: lr: 9.999999747378752e-06\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 4.5193e-05 - custom_f1: 1.0000 - val_loss: 0.6378 - val_custom_f1: 0.8314\n",
            "Epoch 98: lr: 9.999999747378752e-06\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.6056e-05 - custom_f1: 1.0000 - val_loss: 0.6417 - val_custom_f1: 0.8314\n",
            "Epoch 99: lr: 9.999999747378752e-06\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.9218e-05 - custom_f1: 1.0000 - val_loss: 0.6228 - val_custom_f1: 0.8635\n",
            "Epoch 100: lr: 9.999999747378752e-06\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 8.5368e-05 - custom_f1: 0.9912 - val_loss: 0.6358 - val_custom_f1: 0.8314\n",
            "weights are setted to best weights (epochs 23)\n",
            "fold 3 [100,150]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.6377 - custom_f1: 0.7555\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 9s 82ms/step - loss: 0.6377 - custom_f1: 0.7555 - val_loss: 14.6211 - val_custom_f1: 0.7393\n",
            "Epoch 2: lr: 9.999999747378752e-05\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.4756 - custom_f1: 0.8284 - val_loss: 21.6568 - val_custom_f1: 0.7393\n",
            "Epoch 3: lr: 9.999999747378752e-05\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.3574 - custom_f1: 0.8788\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 88ms/step - loss: 0.3574 - custom_f1: 0.8788 - val_loss: 13.0467 - val_custom_f1: 0.7393\n",
            "Epoch 4: lr: 9.999999747378752e-05\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.2360 - custom_f1: 0.9135 - val_loss: 37.9360 - val_custom_f1: 0.7393\n",
            "Epoch 5: lr: 9.999999747378752e-05\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.2120 - custom_f1: 0.9232 - val_loss: 16.5764 - val_custom_f1: 0.7393\n",
            "Epoch 6: lr: 9.999999747378752e-05\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1779 - custom_f1: 0.9479\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 88ms/step - loss: 0.1779 - custom_f1: 0.9479 - val_loss: 0.9967 - val_custom_f1: 0.7842\n",
            "Epoch 7: lr: 9.999999747378752e-05\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1401 - custom_f1: 0.9535 - val_loss: 1.8562 - val_custom_f1: 0.7758\n",
            "Epoch 8: lr: 9.999999747378752e-05\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1698 - custom_f1: 0.9464\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 89ms/step - loss: 0.1698 - custom_f1: 0.9464 - val_loss: 0.8784 - val_custom_f1: 0.8144\n",
            "Epoch 9: lr: 9.999999747378752e-05\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0952 - custom_f1: 0.9749 - val_loss: 1.6243 - val_custom_f1: 0.7987\n",
            "Epoch 10: lr: 9.999999747378752e-05\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0817 - custom_f1: 0.9753 - val_loss: 1.0504 - val_custom_f1: 0.8231\n",
            "Epoch 11: lr: 9.999999747378752e-05\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1665 - custom_f1: 0.9444\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 89ms/step - loss: 0.1665 - custom_f1: 0.9444 - val_loss: 0.3785 - val_custom_f1: 0.8536\n",
            "Epoch 12: lr: 9.999999747378752e-05\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1521 - custom_f1: 0.9493 - val_loss: 1.0413 - val_custom_f1: 0.4554\n",
            "Epoch 13: lr: 9.999999747378752e-05\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1502 - custom_f1: 0.9488\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 88ms/step - loss: 0.1502 - custom_f1: 0.9488 - val_loss: 0.3493 - val_custom_f1: 0.8756\n",
            "Epoch 14: lr: 9.999999747378752e-05\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1264 - custom_f1: 0.9650 - val_loss: 0.6844 - val_custom_f1: 0.8769\n",
            "Epoch 15: lr: 9.999999747378752e-05\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0360 - custom_f1: 0.9916 - val_loss: 0.7990 - val_custom_f1: 0.8491\n",
            "Epoch 16: lr: 9.999999747378752e-05\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0290 - custom_f1: 0.9911\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 88ms/step - loss: 0.0290 - custom_f1: 0.9911 - val_loss: 0.3392 - val_custom_f1: 0.8904\n",
            "Epoch 17: lr: 9.999999747378752e-05\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0807 - custom_f1: 0.9781 - val_loss: 0.3508 - val_custom_f1: 0.8283\n",
            "Epoch 18: lr: 9.999999747378752e-05\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0741 - custom_f1: 0.9780 - val_loss: 0.4285 - val_custom_f1: 0.8795\n",
            "Epoch 19: lr: 9.999999747378752e-05\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0463 - custom_f1: 0.9928\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 90ms/step - loss: 0.0463 - custom_f1: 0.9928 - val_loss: 0.2320 - val_custom_f1: 0.9140\n",
            "Epoch 20: lr: 9.999999747378752e-05\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1218 - custom_f1: 0.9582 - val_loss: 0.9152 - val_custom_f1: 0.4317\n",
            "Epoch 21: lr: 9.999999747378752e-05\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0401 - custom_f1: 0.9880 - val_loss: 0.9457 - val_custom_f1: 0.8231\n",
            "Epoch 22: lr: 9.999999747378752e-05\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0342 - custom_f1: 0.9912 - val_loss: 0.8164 - val_custom_f1: 0.8322\n",
            "Epoch 23: lr: 9.999999747378752e-05\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0915 - custom_f1: 0.9562 - val_loss: 1.2599 - val_custom_f1: 0.7824\n",
            "Epoch 24: lr: 9.999999747378752e-05\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1125 - custom_f1: 0.9539 - val_loss: 0.4427 - val_custom_f1: 0.8598\n",
            "Epoch 25: lr: 9.999999747378752e-05\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0806 - custom_f1: 0.9650 - val_loss: 0.3994 - val_custom_f1: 0.8942\n",
            "Epoch 26: lr: 9.999999747378752e-05\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0497 - custom_f1: 0.9657 - val_loss: 0.3910 - val_custom_f1: 0.8129\n",
            "Epoch 27: lr: 9.999999747378752e-05\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0456 - custom_f1: 0.9646 - val_loss: 0.6143 - val_custom_f1: 0.6863\n",
            "Epoch 28: lr: 9.999999747378752e-05\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0222 - custom_f1: 0.9941 - val_loss: 0.4822 - val_custom_f1: 0.8833\n",
            "Epoch 29: lr: 9.999999747378752e-05\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0186 - custom_f1: 0.9810 - val_loss: 1.2626 - val_custom_f1: 0.7770\n",
            "Epoch 30: lr: 9.999999747378752e-05\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0346 - custom_f1: 0.9840 - val_loss: 0.9922 - val_custom_f1: 0.7981\n",
            "Epoch 31: lr: 9.999999747378752e-05\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0508 - custom_f1: 0.9705 - val_loss: 0.5245 - val_custom_f1: 0.8586\n",
            "Epoch 32: lr: 9.999999747378752e-05\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0324 - custom_f1: 0.9722 - val_loss: 0.3380 - val_custom_f1: 0.8712\n",
            "Epoch 33: lr: 9.999999747378752e-05\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0386 - custom_f1: 0.9709 - val_loss: 0.5494 - val_custom_f1: 0.8790\n",
            "Epoch 34: lr: 9.999999747378752e-05\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0076 - custom_f1: 0.9912 - val_loss: 0.4094 - val_custom_f1: 0.8598\n",
            "Epoch 35: lr: 9.999999747378752e-05\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0085 - custom_f1: 0.9823 - val_loss: 0.3656 - val_custom_f1: 0.9033\n",
            "Epoch 36: lr: 9.999999747378752e-05\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0020 - custom_f1: 1.0000 - val_loss: 0.4462 - val_custom_f1: 0.9033\n",
            "Epoch 37: lr: 9.999999747378752e-05\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0026 - custom_f1: 0.9823 - val_loss: 0.4872 - val_custom_f1: 0.9033\n",
            "Epoch 38: lr: 9.999999747378752e-05\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0013 - custom_f1: 0.9912 - val_loss: 0.5134 - val_custom_f1: 0.9033\n",
            "Epoch 39: lr: 9.999999747378752e-05\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.4792e-04 - custom_f1: 0.9912 - val_loss: 0.5277 - val_custom_f1: 0.9033\n",
            "Epoch 40: lr: 9.999999747378752e-05\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 6.5012e-04 - custom_f1: 1.0000 - val_loss: 0.5703 - val_custom_f1: 0.8974\n",
            "Epoch 41: lr: 9.999999747378752e-05\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 8.4505e-04 - custom_f1: 0.9823 - val_loss: 0.5502 - val_custom_f1: 0.9033\n",
            "Epoch 42: lr: 9.999999747378752e-05\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.2082e-04 - custom_f1: 1.0000 - val_loss: 0.5638 - val_custom_f1: 0.9033\n",
            "Epoch 43: lr: 9.999999747378752e-05\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.6810e-04 - custom_f1: 0.9823 - val_loss: 0.5277 - val_custom_f1: 0.9033\n",
            "Epoch 44: lr: 9.999999747378752e-05\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 8.4528e-04 - custom_f1: 0.9823 - val_loss: 0.6303 - val_custom_f1: 0.8730\n",
            "Epoch 45: lr: 9.999999747378752e-05\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0019 - custom_f1: 0.9823 - val_loss: 0.6675 - val_custom_f1: 0.8730\n",
            "Epoch 46: lr: 9.999999747378752e-05\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0035 - custom_f1: 0.9735 - val_loss: 0.9221 - val_custom_f1: 0.8447\n",
            "Epoch 47: lr: 9.999999747378752e-05\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0024 - custom_f1: 1.0000 - val_loss: 0.3609 - val_custom_f1: 0.8859\n",
            "Epoch 48: lr: 9.999999747378752e-05\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0012 - custom_f1: 0.9912 - val_loss: 0.4773 - val_custom_f1: 0.8795\n",
            "Epoch 49: lr: 9.999999747378752e-05\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.0401e-04 - custom_f1: 0.9823 - val_loss: 0.5065 - val_custom_f1: 0.8795\n",
            "Epoch 50: lr: 9.999999747378752e-05\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.9217e-04 - custom_f1: 0.9823 - val_loss: 0.4748 - val_custom_f1: 0.8795\n",
            "Epoch 51: lr: 9.999999747378752e-05\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 3.8340e-04 - custom_f1: 0.9823\n",
            "lr is fixed to 9.999999747378752e-06\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.8340e-04 - custom_f1: 0.9823 - val_loss: 0.5127 - val_custom_f1: 0.8795\n",
            "Epoch 52: lr: 9.999999747378752e-06\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.4445e-04 - custom_f1: 0.9823 - val_loss: 0.5164 - val_custom_f1: 0.8795\n",
            "Epoch 53: lr: 9.999999747378752e-06\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.6551e-04 - custom_f1: 0.9912 - val_loss: 0.5261 - val_custom_f1: 0.9033\n",
            "Epoch 54: lr: 9.999999747378752e-06\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.4319e-04 - custom_f1: 0.9912 - val_loss: 0.5504 - val_custom_f1: 0.8929\n",
            "Epoch 55: lr: 9.999999747378752e-06\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.3017e-04 - custom_f1: 0.9912 - val_loss: 0.5531 - val_custom_f1: 0.8929\n",
            "Epoch 56: lr: 9.999999747378752e-06\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.6643e-04 - custom_f1: 0.9912 - val_loss: 0.5602 - val_custom_f1: 0.8929\n",
            "Epoch 57: lr: 9.999999747378752e-06\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.3796e-04 - custom_f1: 1.0000 - val_loss: 0.5693 - val_custom_f1: 0.8929\n",
            "Epoch 58: lr: 9.999999747378752e-06\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.8147e-04 - custom_f1: 0.9823 - val_loss: 0.5723 - val_custom_f1: 0.8929\n",
            "Epoch 59: lr: 9.999999747378752e-06\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.9724e-04 - custom_f1: 0.9912 - val_loss: 0.5767 - val_custom_f1: 0.8730\n",
            "Epoch 60: lr: 9.999999747378752e-06\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.1493e-04 - custom_f1: 1.0000 - val_loss: 0.5817 - val_custom_f1: 0.8730\n",
            "Epoch 61: lr: 9.999999747378752e-06\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.3907e-04 - custom_f1: 0.9823 - val_loss: 0.5747 - val_custom_f1: 0.8929\n",
            "Epoch 62: lr: 9.999999747378752e-06\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.8858e-04 - custom_f1: 0.9823 - val_loss: 0.5781 - val_custom_f1: 0.8929\n",
            "Epoch 63: lr: 9.999999747378752e-06\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.3443e-04 - custom_f1: 0.9912 - val_loss: 0.5941 - val_custom_f1: 0.8730\n",
            "Epoch 64: lr: 9.999999747378752e-06\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.9826e-04 - custom_f1: 1.0000 - val_loss: 0.5939 - val_custom_f1: 0.8730\n",
            "Epoch 65: lr: 9.999999747378752e-06\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.3241e-04 - custom_f1: 0.9735 - val_loss: 0.5761 - val_custom_f1: 0.8929\n",
            "Epoch 66: lr: 9.999999747378752e-06\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.9278e-04 - custom_f1: 0.9823 - val_loss: 0.5596 - val_custom_f1: 0.8929\n",
            "Epoch 67: lr: 9.999999747378752e-06\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.8695e-04 - custom_f1: 1.0000 - val_loss: 0.5744 - val_custom_f1: 0.8929\n",
            "Epoch 68: lr: 9.999999747378752e-06\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.6252e-04 - custom_f1: 0.9646 - val_loss: 0.5798 - val_custom_f1: 0.8546\n",
            "Epoch 69: lr: 9.999999747378752e-06\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.5341e-04 - custom_f1: 0.9912 - val_loss: 0.5819 - val_custom_f1: 0.8730\n",
            "Epoch 70: lr: 9.999999747378752e-06\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.5922e-04 - custom_f1: 0.9735 - val_loss: 0.5935 - val_custom_f1: 0.8546\n",
            "Epoch 71: lr: 9.999999747378752e-06\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.7111e-04 - custom_f1: 1.0000 - val_loss: 0.6280 - val_custom_f1: 0.8546\n",
            "Epoch 72: lr: 9.999999747378752e-06\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.2613e-04 - custom_f1: 0.9823 - val_loss: 0.6257 - val_custom_f1: 0.8546\n",
            "Epoch 73: lr: 9.999999747378752e-06\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.6103e-04 - custom_f1: 0.9823 - val_loss: 0.5959 - val_custom_f1: 0.8546\n",
            "Epoch 74: lr: 9.999999747378752e-06\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.4740e-04 - custom_f1: 0.9735 - val_loss: 0.5962 - val_custom_f1: 0.8546\n",
            "Epoch 75: lr: 9.999999747378752e-06\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.5341e-04 - custom_f1: 0.9912 - val_loss: 0.6081 - val_custom_f1: 0.8546\n",
            "Epoch 76: lr: 9.999999747378752e-06\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.0422e-04 - custom_f1: 0.9912 - val_loss: 0.6247 - val_custom_f1: 0.8546\n",
            "Epoch 77: lr: 9.999999747378752e-06\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.6650e-04 - custom_f1: 0.9912 - val_loss: 0.6499 - val_custom_f1: 0.8546\n",
            "Epoch 78: lr: 9.999999747378752e-06\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.4913e-04 - custom_f1: 0.9823 - val_loss: 0.5662 - val_custom_f1: 0.8730\n",
            "Epoch 79: lr: 9.999999747378752e-06\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.4038e-04 - custom_f1: 0.9823 - val_loss: 0.5685 - val_custom_f1: 0.8730\n",
            "Epoch 80: lr: 9.999999747378752e-06\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.9687e-04 - custom_f1: 0.9823 - val_loss: 0.5775 - val_custom_f1: 0.8730\n",
            "Epoch 81: lr: 9.999999747378752e-06\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.8135e-04 - custom_f1: 0.9735 - val_loss: 0.5913 - val_custom_f1: 0.8730\n",
            "Epoch 82: lr: 9.999999747378752e-06\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.3718e-04 - custom_f1: 1.0000 - val_loss: 0.6259 - val_custom_f1: 0.8546\n",
            "Epoch 83: lr: 9.999999747378752e-06\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.5114e-04 - custom_f1: 0.9823 - val_loss: 0.6375 - val_custom_f1: 0.8546\n",
            "Epoch 84: lr: 9.999999747378752e-06\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.1807e-04 - custom_f1: 1.0000 - val_loss: 0.6449 - val_custom_f1: 0.8546\n",
            "Epoch 85: lr: 9.999999747378752e-06\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.6321e-05 - custom_f1: 1.0000 - val_loss: 0.6630 - val_custom_f1: 0.8546\n",
            "Epoch 86: lr: 9.999999747378752e-06\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.5275e-04 - custom_f1: 0.9912 - val_loss: 0.6503 - val_custom_f1: 0.8546\n",
            "Epoch 87: lr: 9.999999747378752e-06\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.2153e-04 - custom_f1: 0.9912 - val_loss: 0.6524 - val_custom_f1: 0.8546\n",
            "Epoch 88: lr: 9.999999747378752e-06\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 1.1550e-04 - custom_f1: 0.9912 - val_loss: 0.6483 - val_custom_f1: 0.8546\n",
            "Epoch 89: lr: 9.999999747378752e-06\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 1.3136e-04 - custom_f1: 0.9912 - val_loss: 0.6564 - val_custom_f1: 0.8546\n",
            "Epoch 90: lr: 9.999999747378752e-06\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.8840e-05 - custom_f1: 0.9912 - val_loss: 0.6763 - val_custom_f1: 0.8546\n",
            "Epoch 91: lr: 9.999999747378752e-06\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.1765e-04 - custom_f1: 0.9912 - val_loss: 0.6661 - val_custom_f1: 0.8546\n",
            "Epoch 92: lr: 9.999999747378752e-06\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 8.9209e-05 - custom_f1: 1.0000 - val_loss: 0.6917 - val_custom_f1: 0.8546\n",
            "Epoch 93: lr: 9.999999747378752e-06\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.8978e-05 - custom_f1: 0.9912 - val_loss: 0.6854 - val_custom_f1: 0.8546\n",
            "Epoch 94: lr: 9.999999747378752e-06\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.1578e-04 - custom_f1: 0.9912 - val_loss: 0.7035 - val_custom_f1: 0.8686\n",
            "Epoch 95: lr: 9.999999747378752e-06\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 8.3462e-05 - custom_f1: 0.9912 - val_loss: 0.7010 - val_custom_f1: 0.8686\n",
            "Epoch 96: lr: 9.999999747378752e-06\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.0941e-04 - custom_f1: 0.9912 - val_loss: 0.5095 - val_custom_f1: 0.8833\n",
            "Epoch 97: lr: 9.999999747378752e-06\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.8175e-04 - custom_f1: 0.9912 - val_loss: 0.5899 - val_custom_f1: 0.8730\n",
            "Epoch 98: lr: 9.999999747378752e-06\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.5118e-05 - custom_f1: 0.9912 - val_loss: 0.6371 - val_custom_f1: 0.8730\n",
            "Epoch 99: lr: 9.999999747378752e-06\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.9467e-05 - custom_f1: 1.0000 - val_loss: 0.6640 - val_custom_f1: 0.8546\n",
            "Epoch 100: lr: 9.999999747378752e-06\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.3073e-04 - custom_f1: 0.9823 - val_loss: 0.6209 - val_custom_f1: 0.8730\n",
            "weights are setted to best weights (epochs 19)\n",
            "fold 4 [150,200]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.6181 - custom_f1: 0.7515\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 9s 82ms/step - loss: 0.6181 - custom_f1: 0.7515 - val_loss: 13.9427 - val_custom_f1: 0.7755\n",
            "Epoch 2: lr: 9.999999747378752e-05\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.3764 - custom_f1: 0.8579 - val_loss: 15.7704 - val_custom_f1: 0.7755\n",
            "Epoch 3: lr: 9.999999747378752e-05\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.2944 - custom_f1: 0.8890 - val_loss: 39.9100 - val_custom_f1: 0.7755\n",
            "Epoch 4: lr: 9.999999747378752e-05\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.2819 - custom_f1: 0.9131 - val_loss: 20.1873 - val_custom_f1: 0.7755\n",
            "Epoch 5: lr: 9.999999747378752e-05\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1289 - custom_f1: 0.9620 - val_loss: 18.1515 - val_custom_f1: 0.7755\n",
            "Epoch 6: lr: 9.999999747378752e-05\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1976 - custom_f1: 0.9297\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 91ms/step - loss: 0.1976 - custom_f1: 0.9297 - val_loss: 2.0202 - val_custom_f1: 0.7832\n",
            "Epoch 7: lr: 9.999999747378752e-05\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.2072 - custom_f1: 0.9429 - val_loss: 3.4577 - val_custom_f1: 0.7755\n",
            "Epoch 8: lr: 9.999999747378752e-05\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.2041 - custom_f1: 0.9286\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 88ms/step - loss: 0.2041 - custom_f1: 0.9286 - val_loss: 0.2676 - val_custom_f1: 0.8893\n",
            "Epoch 9: lr: 9.999999747378752e-05\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1225 - custom_f1: 0.9585 - val_loss: 0.4214 - val_custom_f1: 0.8500\n",
            "Epoch 10: lr: 9.999999747378752e-05\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0890 - custom_f1: 0.9789 - val_loss: 1.0507 - val_custom_f1: 0.8360\n",
            "Epoch 11: lr: 9.999999747378752e-05\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1224 - custom_f1: 0.9643 - val_loss: 1.2215 - val_custom_f1: 0.8360\n",
            "Epoch 12: lr: 9.999999747378752e-05\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0858 - custom_f1: 0.9857 - val_loss: 0.3378 - val_custom_f1: 0.8958\n",
            "Epoch 13: lr: 9.999999747378752e-05\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0334 - custom_f1: 0.9886 - val_loss: 0.4394 - val_custom_f1: 0.8868\n",
            "Epoch 14: lr: 9.999999747378752e-05\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0217 - custom_f1: 0.9971 - val_loss: 0.2707 - val_custom_f1: 0.8810\n",
            "Epoch 15: lr: 9.999999747378752e-05\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0694 - custom_f1: 0.9827\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 88ms/step - loss: 0.0694 - custom_f1: 0.9827 - val_loss: 0.2440 - val_custom_f1: 0.8676\n",
            "Epoch 16: lr: 9.999999747378752e-05\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0714 - custom_f1: 0.9815 - val_loss: 0.5794 - val_custom_f1: 0.7847\n",
            "Epoch 17: lr: 9.999999747378752e-05\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0951 - custom_f1: 0.9722 - val_loss: 0.3289 - val_custom_f1: 0.8570\n",
            "Epoch 18: lr: 9.999999747378752e-05\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0569 - custom_f1: 0.9894 - val_loss: 0.3096 - val_custom_f1: 0.9115\n",
            "Epoch 19: lr: 9.999999747378752e-05\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0366 - custom_f1: 0.9899 - val_loss: 0.3231 - val_custom_f1: 0.8554\n",
            "Epoch 20: lr: 9.999999747378752e-05\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0077 - custom_f1: 1.0000 - val_loss: 0.3023 - val_custom_f1: 0.9051\n",
            "Epoch 21: lr: 9.999999747378752e-05\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0152 - custom_f1: 0.9912 - val_loss: 0.3773 - val_custom_f1: 0.8711\n",
            "Epoch 22: lr: 9.999999747378752e-05\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0421 - custom_f1: 0.9735 - val_loss: 0.5921 - val_custom_f1: 0.8360\n",
            "Epoch 23: lr: 9.999999747378752e-05\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0520 - custom_f1: 0.9822 - val_loss: 0.4083 - val_custom_f1: 0.8606\n",
            "Epoch 24: lr: 9.999999747378752e-05\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0204 - custom_f1: 0.9882 - val_loss: 0.2985 - val_custom_f1: 0.8755\n",
            "Epoch 25: lr: 9.999999747378752e-05\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0144 - custom_f1: 0.9912 - val_loss: 0.4617 - val_custom_f1: 0.8265\n",
            "Epoch 26: lr: 9.999999747378752e-05\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0147 - custom_f1: 0.9971 - val_loss: 0.3969 - val_custom_f1: 0.9149\n",
            "Epoch 27: lr: 9.999999747378752e-05\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0061 - custom_f1: 0.9912 - val_loss: 1.2843 - val_custom_f1: 0.8046\n",
            "Epoch 28: lr: 9.999999747378752e-05\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0092 - custom_f1: 0.9912 - val_loss: 0.3353 - val_custom_f1: 0.9067\n",
            "Epoch 29: lr: 9.999999747378752e-05\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0158 - custom_f1: 0.9776 - val_loss: 0.8662 - val_custom_f1: 0.8274\n",
            "Epoch 30: lr: 9.999999747378752e-05\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0081 - custom_f1: 0.9735 - val_loss: 0.2494 - val_custom_f1: 0.9545\n",
            "Epoch 31: lr: 9.999999747378752e-05\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0015 - custom_f1: 1.0000\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 88ms/step - loss: 0.0015 - custom_f1: 1.0000 - val_loss: 0.2430 - val_custom_f1: 0.9434\n",
            "Epoch 32: lr: 9.999999747378752e-05\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0038 - custom_f1: 0.9912 - val_loss: 0.3934 - val_custom_f1: 0.8447\n",
            "Epoch 33: lr: 9.999999747378752e-05\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.4183e-04 - custom_f1: 1.0000 - val_loss: 0.2663 - val_custom_f1: 0.9545\n",
            "Epoch 34: lr: 9.999999747378752e-05\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.8168e-04 - custom_f1: 1.0000 - val_loss: 0.2936 - val_custom_f1: 0.9227\n",
            "Epoch 35: lr: 9.999999747378752e-05\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.0879e-04 - custom_f1: 0.9912 - val_loss: 0.2866 - val_custom_f1: 0.9227\n",
            "Epoch 36: lr: 9.999999747378752e-05\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.5114e-04 - custom_f1: 1.0000 - val_loss: 0.3024 - val_custom_f1: 0.9227\n",
            "Epoch 37: lr: 9.999999747378752e-05\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0017 - custom_f1: 0.9735 - val_loss: 0.7328 - val_custom_f1: 0.8214\n",
            "Epoch 38: lr: 9.999999747378752e-05\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0012 - custom_f1: 0.9912\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 88ms/step - loss: 0.0012 - custom_f1: 0.9912 - val_loss: 0.2247 - val_custom_f1: 0.9449\n",
            "Epoch 39: lr: 9.999999747378752e-05\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 8.3673e-04 - custom_f1: 0.9735\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 9s 82ms/step - loss: 8.3673e-04 - custom_f1: 0.9735 - val_loss: 0.2204 - val_custom_f1: 0.9449\n",
            "Epoch 40: lr: 9.999999747378752e-05\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 3.9383e-04 - custom_f1: 0.9823\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 92ms/step - loss: 3.9383e-04 - custom_f1: 0.9823 - val_loss: 0.2141 - val_custom_f1: 0.9449\n",
            "Epoch 41: lr: 9.999999747378752e-05\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.1945e-04 - custom_f1: 0.9823 - val_loss: 0.2391 - val_custom_f1: 0.9449\n",
            "Epoch 42: lr: 9.999999747378752e-05\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.8108e-04 - custom_f1: 1.0000 - val_loss: 0.2519 - val_custom_f1: 0.9449\n",
            "Epoch 43: lr: 9.999999747378752e-05\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.5168e-04 - custom_f1: 0.9912 - val_loss: 0.2502 - val_custom_f1: 0.9449\n",
            "Epoch 44: lr: 9.999999747378752e-05\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.2011e-04 - custom_f1: 0.9912 - val_loss: 0.2158 - val_custom_f1: 0.9449\n",
            "Epoch 45: lr: 9.999999747378752e-05\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.0491e-04 - custom_f1: 1.0000 - val_loss: 0.2515 - val_custom_f1: 0.9449\n",
            "Epoch 46: lr: 9.999999747378752e-05\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0182 - custom_f1: 0.9690 - val_loss: 4.5887 - val_custom_f1: 0.0000e+00\n",
            "Epoch 47: lr: 9.999999747378752e-05\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.2098 - custom_f1: 0.9184 - val_loss: 6.4286 - val_custom_f1: 0.7755\n",
            "Epoch 48: lr: 9.999999747378752e-05\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1814 - custom_f1: 0.9363 - val_loss: 1.5221 - val_custom_f1: 0.3393\n",
            "Epoch 49: lr: 9.999999747378752e-05\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0741 - custom_f1: 0.9731 - val_loss: 0.5189 - val_custom_f1: 0.8221\n",
            "Epoch 50: lr: 9.999999747378752e-05\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0493 - custom_f1: 0.9781 - val_loss: 0.6098 - val_custom_f1: 0.7115\n",
            "Epoch 51: lr: 9.999999747378752e-05\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0081 - custom_f1: 0.9912\n",
            "lr is fixed to 9.999999747378752e-06\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0081 - custom_f1: 0.9912 - val_loss: 0.3189 - val_custom_f1: 0.8667\n",
            "Epoch 52: lr: 9.999999747378752e-06\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0064 - custom_f1: 0.9912 - val_loss: 0.2365 - val_custom_f1: 0.9197\n",
            "Epoch 53: lr: 9.999999747378752e-06\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0071 - custom_f1: 0.9823 - val_loss: 0.2422 - val_custom_f1: 0.8990\n",
            "Epoch 54: lr: 9.999999747378752e-06\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0031 - custom_f1: 1.0000 - val_loss: 0.2583 - val_custom_f1: 0.8723\n",
            "Epoch 55: lr: 9.999999747378752e-06\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0023 - custom_f1: 1.0000 - val_loss: 0.2697 - val_custom_f1: 0.8723\n",
            "Epoch 56: lr: 9.999999747378752e-06\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0056 - custom_f1: 0.9823 - val_loss: 0.2431 - val_custom_f1: 0.8723\n",
            "Epoch 57: lr: 9.999999747378752e-06\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0046 - custom_f1: 0.9912 - val_loss: 0.2512 - val_custom_f1: 0.8723\n",
            "Epoch 58: lr: 9.999999747378752e-06\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0055 - custom_f1: 0.9735 - val_loss: 0.2393 - val_custom_f1: 0.8816\n",
            "Epoch 59: lr: 9.999999747378752e-06\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0022 - custom_f1: 0.9912 - val_loss: 0.2600 - val_custom_f1: 0.8723\n",
            "Epoch 60: lr: 9.999999747378752e-06\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0039 - custom_f1: 0.9912 - val_loss: 0.2330 - val_custom_f1: 0.8816\n",
            "Epoch 61: lr: 9.999999747378752e-06\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0032 - custom_f1: 0.9823 - val_loss: 0.2477 - val_custom_f1: 0.8816\n",
            "Epoch 62: lr: 9.999999747378752e-06\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0033 - custom_f1: 0.9823 - val_loss: 0.2733 - val_custom_f1: 0.8958\n",
            "Epoch 63: lr: 9.999999747378752e-06\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0052 - custom_f1: 0.9558 - val_loss: 0.2433 - val_custom_f1: 0.8816\n",
            "Epoch 64: lr: 9.999999747378752e-06\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0020 - custom_f1: 0.9912 - val_loss: 0.2566 - val_custom_f1: 0.8723\n",
            "Epoch 65: lr: 9.999999747378752e-06\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0017 - custom_f1: 0.9912 - val_loss: 0.2777 - val_custom_f1: 0.8723\n",
            "Epoch 66: lr: 9.999999747378752e-06\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0019 - custom_f1: 0.9823 - val_loss: 0.2757 - val_custom_f1: 0.8723\n",
            "Epoch 67: lr: 9.999999747378752e-06\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0017 - custom_f1: 0.9823 - val_loss: 0.2745 - val_custom_f1: 0.8723\n",
            "Epoch 68: lr: 9.999999747378752e-06\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0031 - custom_f1: 0.9823 - val_loss: 0.2479 - val_custom_f1: 0.8816\n",
            "Epoch 69: lr: 9.999999747378752e-06\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0019 - custom_f1: 0.9912 - val_loss: 0.2429 - val_custom_f1: 0.8816\n",
            "Epoch 70: lr: 9.999999747378752e-06\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0013 - custom_f1: 0.9912 - val_loss: 0.2636 - val_custom_f1: 0.8816\n",
            "Epoch 71: lr: 9.999999747378752e-06\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0027 - custom_f1: 0.9823 - val_loss: 0.2791 - val_custom_f1: 0.8723\n",
            "Epoch 72: lr: 9.999999747378752e-06\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 7.9671e-04 - custom_f1: 1.0000 - val_loss: 0.2895 - val_custom_f1: 0.8723\n",
            "Epoch 73: lr: 9.999999747378752e-06\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.3297e-04 - custom_f1: 0.9823 - val_loss: 0.3085 - val_custom_f1: 0.8723\n",
            "Epoch 74: lr: 9.999999747378752e-06\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0012 - custom_f1: 0.9912 - val_loss: 0.2971 - val_custom_f1: 0.8723\n",
            "Epoch 75: lr: 9.999999747378752e-06\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.8946e-04 - custom_f1: 0.9912 - val_loss: 0.3107 - val_custom_f1: 0.8958\n",
            "Epoch 76: lr: 9.999999747378752e-06\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0010 - custom_f1: 0.9912 - val_loss: 0.3165 - val_custom_f1: 0.8958\n",
            "Epoch 77: lr: 9.999999747378752e-06\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 4.8820e-04 - custom_f1: 1.0000 - val_loss: 0.3159 - val_custom_f1: 0.8958\n",
            "Epoch 78: lr: 9.999999747378752e-06\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.9422e-04 - custom_f1: 0.9912 - val_loss: 0.3069 - val_custom_f1: 0.8958\n",
            "Epoch 79: lr: 9.999999747378752e-06\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0012 - custom_f1: 0.9646 - val_loss: 0.2830 - val_custom_f1: 0.8723\n",
            "Epoch 80: lr: 9.999999747378752e-06\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.9576e-04 - custom_f1: 1.0000 - val_loss: 0.3071 - val_custom_f1: 0.8723\n",
            "Epoch 81: lr: 9.999999747378752e-06\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.5326e-04 - custom_f1: 1.0000 - val_loss: 0.3221 - val_custom_f1: 0.8958\n",
            "Epoch 82: lr: 9.999999747378752e-06\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.1950e-04 - custom_f1: 0.9912 - val_loss: 0.2982 - val_custom_f1: 0.8723\n",
            "Epoch 83: lr: 9.999999747378752e-06\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.5007e-04 - custom_f1: 0.9912 - val_loss: 0.3204 - val_custom_f1: 0.8958\n",
            "Epoch 84: lr: 9.999999747378752e-06\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 5.0355e-04 - custom_f1: 0.9912 - val_loss: 0.3317 - val_custom_f1: 0.8958\n",
            "Epoch 85: lr: 9.999999747378752e-06\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.2248e-04 - custom_f1: 0.9912 - val_loss: 0.3436 - val_custom_f1: 0.8775\n",
            "Epoch 86: lr: 9.999999747378752e-06\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.1279e-04 - custom_f1: 0.9912 - val_loss: 0.2880 - val_custom_f1: 0.8542\n",
            "Epoch 87: lr: 9.999999747378752e-06\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.4397e-04 - custom_f1: 0.9823 - val_loss: 0.3220 - val_custom_f1: 0.8775\n",
            "Epoch 88: lr: 9.999999747378752e-06\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.4895e-04 - custom_f1: 0.9912 - val_loss: 0.3494 - val_custom_f1: 0.8775\n",
            "Epoch 89: lr: 9.999999747378752e-06\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.9623e-04 - custom_f1: 0.9735 - val_loss: 0.3520 - val_custom_f1: 0.8775\n",
            "Epoch 90: lr: 9.999999747378752e-06\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.2217e-04 - custom_f1: 0.9912 - val_loss: 0.3541 - val_custom_f1: 0.8775\n",
            "Epoch 91: lr: 9.999999747378752e-06\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.4241e-04 - custom_f1: 1.0000 - val_loss: 0.3632 - val_custom_f1: 0.8775\n",
            "Epoch 92: lr: 9.999999747378752e-06\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.0008e-04 - custom_f1: 0.9912 - val_loss: 0.3757 - val_custom_f1: 0.8775\n",
            "Epoch 93: lr: 9.999999747378752e-06\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.2689e-04 - custom_f1: 0.9735 - val_loss: 0.3720 - val_custom_f1: 0.8775\n",
            "Epoch 94: lr: 9.999999747378752e-06\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.1018e-04 - custom_f1: 0.9912 - val_loss: 0.3734 - val_custom_f1: 0.8775\n",
            "Epoch 95: lr: 9.999999747378752e-06\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.0739e-04 - custom_f1: 0.9823 - val_loss: 0.3748 - val_custom_f1: 0.8775\n",
            "Epoch 96: lr: 9.999999747378752e-06\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.8028e-04 - custom_f1: 1.0000 - val_loss: 0.3782 - val_custom_f1: 0.8775\n",
            "Epoch 97: lr: 9.999999747378752e-06\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.5869e-04 - custom_f1: 0.9735 - val_loss: 0.3728 - val_custom_f1: 0.8775\n",
            "Epoch 98: lr: 9.999999747378752e-06\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.4872e-04 - custom_f1: 0.9823 - val_loss: 0.3625 - val_custom_f1: 0.8775\n",
            "Epoch 99: lr: 9.999999747378752e-06\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.6659e-04 - custom_f1: 1.0000 - val_loss: 0.3898 - val_custom_f1: 0.8775\n",
            "Epoch 100: lr: 9.999999747378752e-06\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.5638e-04 - custom_f1: 0.9646 - val_loss: 0.3886 - val_custom_f1: 0.8775\n",
            "weights are setted to best weights (epochs 40)\n",
            "fold 5 [200,250]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.5664 - custom_f1: 0.7556\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 9s 83ms/step - loss: 0.5664 - custom_f1: 0.7556 - val_loss: 9.3425 - val_custom_f1: 0.8557\n",
            "Epoch 2: lr: 9.999999747378752e-05\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.3807 - custom_f1: 0.8698 - val_loss: 22.8178 - val_custom_f1: 0.8557\n",
            "Epoch 3: lr: 9.999999747378752e-05\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.2956 - custom_f1: 0.9006 - val_loss: 18.7430 - val_custom_f1: 0.8557\n",
            "Epoch 4: lr: 9.999999747378752e-05\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.2361 - custom_f1: 0.9223 - val_loss: 17.9383 - val_custom_f1: 0.8557\n",
            "Epoch 5: lr: 9.999999747378752e-05\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1653 - custom_f1: 0.9398\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 87ms/step - loss: 0.1653 - custom_f1: 0.9398 - val_loss: 7.2553 - val_custom_f1: 0.8557\n",
            "Epoch 6: lr: 9.999999747378752e-05\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1708 - custom_f1: 0.9409\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 9s 82ms/step - loss: 0.1708 - custom_f1: 0.9409 - val_loss: 0.7087 - val_custom_f1: 0.8885\n",
            "Epoch 7: lr: 9.999999747378752e-05\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.2107 - custom_f1: 0.9279\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 89ms/step - loss: 0.2107 - custom_f1: 0.9279 - val_loss: 0.3281 - val_custom_f1: 0.9318\n",
            "Epoch 8: lr: 9.999999747378752e-05\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1803 - custom_f1: 0.9343 - val_loss: 1.7121 - val_custom_f1: 0.3704\n",
            "Epoch 9: lr: 9.999999747378752e-05\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1572 - custom_f1: 0.9405\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 89ms/step - loss: 0.1572 - custom_f1: 0.9405 - val_loss: 0.2562 - val_custom_f1: 0.9380\n",
            "Epoch 10: lr: 9.999999747378752e-05\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0691 - custom_f1: 0.9780 - val_loss: 0.3045 - val_custom_f1: 0.9135\n",
            "Epoch 11: lr: 9.999999747378752e-05\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0766 - custom_f1: 0.9736 - val_loss: 0.5652 - val_custom_f1: 0.8462\n",
            "Epoch 12: lr: 9.999999747378752e-05\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1215 - custom_f1: 0.9638 - val_loss: 0.6811 - val_custom_f1: 0.9069\n",
            "Epoch 13: lr: 9.999999747378752e-05\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1436 - custom_f1: 0.9552 - val_loss: 0.3463 - val_custom_f1: 0.9081\n",
            "Epoch 14: lr: 9.999999747378752e-05\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0483 - custom_f1: 0.9815 - val_loss: 0.4257 - val_custom_f1: 0.8499\n",
            "Epoch 15: lr: 9.999999747378752e-05\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0814 - custom_f1: 0.9781\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 88ms/step - loss: 0.0814 - custom_f1: 0.9781 - val_loss: 0.2207 - val_custom_f1: 0.9508\n",
            "Epoch 16: lr: 9.999999747378752e-05\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0777 - custom_f1: 0.9662 - val_loss: 0.6858 - val_custom_f1: 0.9116\n",
            "Epoch 17: lr: 9.999999747378752e-05\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0732 - custom_f1: 0.9686 - val_loss: 0.2225 - val_custom_f1: 0.9324\n",
            "Epoch 18: lr: 9.999999747378752e-05\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0539 - custom_f1: 0.9821 - val_loss: 0.2245 - val_custom_f1: 0.9449\n",
            "Epoch 19: lr: 9.999999747378752e-05\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1175 - custom_f1: 0.9347 - val_loss: 0.4309 - val_custom_f1: 0.8615\n",
            "Epoch 20: lr: 9.999999747378752e-05\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0398 - custom_f1: 0.9912 - val_loss: 0.2731 - val_custom_f1: 0.9494\n",
            "Epoch 21: lr: 9.999999747378752e-05\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0613 - custom_f1: 0.9604 - val_loss: 1.0588 - val_custom_f1: 0.4965\n",
            "Epoch 22: lr: 9.999999747378752e-05\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0236 - custom_f1: 0.9853 - val_loss: 0.3182 - val_custom_f1: 0.9419\n",
            "Epoch 23: lr: 9.999999747378752e-05\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0334 - custom_f1: 0.9735 - val_loss: 0.3350 - val_custom_f1: 0.9135\n",
            "Epoch 24: lr: 9.999999747378752e-05\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0243 - custom_f1: 0.9882 - val_loss: 0.5668 - val_custom_f1: 0.8291\n",
            "Epoch 25: lr: 9.999999747378752e-05\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0176 - custom_f1: 0.9958 - val_loss: 0.4653 - val_custom_f1: 0.9146\n",
            "Epoch 26: lr: 9.999999747378752e-05\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0393 - custom_f1: 0.9798 - val_loss: 0.8270 - val_custom_f1: 0.5894\n",
            "Epoch 27: lr: 9.999999747378752e-05\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0272 - custom_f1: 0.9781 - val_loss: 0.5328 - val_custom_f1: 0.9197\n",
            "Epoch 28: lr: 9.999999747378752e-05\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0099 - custom_f1: 0.9735 - val_loss: 0.3252 - val_custom_f1: 0.9232\n",
            "Epoch 29: lr: 9.999999747378752e-05\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0071 - custom_f1: 0.9912 - val_loss: 0.3593 - val_custom_f1: 0.9232\n",
            "Epoch 30: lr: 9.999999747378752e-05\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0037 - custom_f1: 0.9823 - val_loss: 0.5188 - val_custom_f1: 0.8643\n",
            "Epoch 31: lr: 9.999999747378752e-05\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0019 - custom_f1: 0.9823 - val_loss: 0.3740 - val_custom_f1: 0.8829\n",
            "Epoch 32: lr: 9.999999747378752e-05\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0017 - custom_f1: 0.9823 - val_loss: 0.3763 - val_custom_f1: 0.8789\n",
            "Epoch 33: lr: 9.999999747378752e-05\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 7.5163e-04 - custom_f1: 0.9912 - val_loss: 0.3375 - val_custom_f1: 0.9232\n",
            "Epoch 34: lr: 9.999999747378752e-05\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0042 - custom_f1: 0.9823 - val_loss: 0.3423 - val_custom_f1: 0.9111\n",
            "Epoch 35: lr: 9.999999747378752e-05\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0089 - custom_f1: 0.9805 - val_loss: 0.8298 - val_custom_f1: 0.9069\n",
            "Epoch 36: lr: 9.999999747378752e-05\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0015 - custom_f1: 0.9823 - val_loss: 0.3549 - val_custom_f1: 0.9232\n",
            "Epoch 37: lr: 9.999999747378752e-05\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0015 - custom_f1: 0.9735 - val_loss: 0.3715 - val_custom_f1: 0.9246\n",
            "Epoch 38: lr: 9.999999747378752e-05\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0014 - custom_f1: 0.9912 - val_loss: 0.3705 - val_custom_f1: 0.9250\n",
            "Epoch 39: lr: 9.999999747378752e-05\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0013 - custom_f1: 0.9823 - val_loss: 0.3840 - val_custom_f1: 0.9232\n",
            "Epoch 40: lr: 9.999999747378752e-05\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.2605e-04 - custom_f1: 0.9912 - val_loss: 0.3451 - val_custom_f1: 0.9111\n",
            "Epoch 41: lr: 9.999999747378752e-05\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 3.2115e-04 - custom_f1: 0.9823 - val_loss: 0.3555 - val_custom_f1: 0.9111\n",
            "Epoch 42: lr: 9.999999747378752e-05\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.8499e-04 - custom_f1: 1.0000 - val_loss: 0.3611 - val_custom_f1: 0.9111\n",
            "Epoch 43: lr: 9.999999747378752e-05\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.2683e-04 - custom_f1: 0.9735 - val_loss: 0.3780 - val_custom_f1: 0.9146\n",
            "Epoch 44: lr: 9.999999747378752e-05\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.0128e-04 - custom_f1: 1.0000 - val_loss: 0.3730 - val_custom_f1: 0.9111\n",
            "Epoch 45: lr: 9.999999747378752e-05\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.7553e-04 - custom_f1: 1.0000 - val_loss: 0.3775 - val_custom_f1: 0.9111\n",
            "Epoch 46: lr: 9.999999747378752e-05\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.4982e-04 - custom_f1: 1.0000 - val_loss: 0.3895 - val_custom_f1: 0.9111\n",
            "Epoch 47: lr: 9.999999747378752e-05\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.1930e-04 - custom_f1: 0.9823 - val_loss: 0.3398 - val_custom_f1: 0.9373\n",
            "Epoch 48: lr: 9.999999747378752e-05\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.7202e-04 - custom_f1: 0.9823 - val_loss: 0.3768 - val_custom_f1: 0.9348\n",
            "Epoch 49: lr: 9.999999747378752e-05\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.5818e-04 - custom_f1: 1.0000 - val_loss: 0.3751 - val_custom_f1: 0.9348\n",
            "Epoch 50: lr: 9.999999747378752e-05\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.6964e-04 - custom_f1: 0.9912 - val_loss: 0.3803 - val_custom_f1: 0.9348\n",
            "Epoch 51: lr: 9.999999747378752e-05\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 1.0248e-04 - custom_f1: 1.0000\n",
            "lr is fixed to 9.999999747378752e-06\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 1.0248e-04 - custom_f1: 1.0000 - val_loss: 0.3834 - val_custom_f1: 0.9348\n",
            "Epoch 52: lr: 9.999999747378752e-06\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.7769e-04 - custom_f1: 0.9823 - val_loss: 0.3869 - val_custom_f1: 0.9348\n",
            "Epoch 53: lr: 9.999999747378752e-06\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.7044e-04 - custom_f1: 0.9735 - val_loss: 0.3845 - val_custom_f1: 0.9348\n",
            "Epoch 54: lr: 9.999999747378752e-06\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 2.1551e-04 - custom_f1: 0.9735 - val_loss: 0.3932 - val_custom_f1: 0.9197\n",
            "Epoch 55: lr: 9.999999747378752e-06\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 1.1154e-04 - custom_f1: 0.9912 - val_loss: 0.3845 - val_custom_f1: 0.9348\n",
            "Epoch 56: lr: 9.999999747378752e-06\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 1.5148e-04 - custom_f1: 0.9823 - val_loss: 0.3818 - val_custom_f1: 0.9348\n",
            "Epoch 57: lr: 9.999999747378752e-06\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 9.3670e-05 - custom_f1: 0.9912 - val_loss: 0.3870 - val_custom_f1: 0.9348\n",
            "Epoch 58: lr: 9.999999747378752e-06\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.2682e-04 - custom_f1: 0.9823 - val_loss: 0.3847 - val_custom_f1: 0.9232\n",
            "Epoch 59: lr: 9.999999747378752e-06\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 8.0535e-05 - custom_f1: 1.0000 - val_loss: 0.3881 - val_custom_f1: 0.9348\n",
            "Epoch 60: lr: 9.999999747378752e-06\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.8097e-04 - custom_f1: 0.9823 - val_loss: 0.3886 - val_custom_f1: 0.9232\n",
            "Epoch 61: lr: 9.999999747378752e-06\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 8.4863e-05 - custom_f1: 0.9912 - val_loss: 0.3886 - val_custom_f1: 0.9232\n",
            "Epoch 62: lr: 9.999999747378752e-06\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.3013e-05 - custom_f1: 1.0000 - val_loss: 0.3949 - val_custom_f1: 0.9197\n",
            "Epoch 63: lr: 9.999999747378752e-06\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.4314e-04 - custom_f1: 0.9823 - val_loss: 0.3878 - val_custom_f1: 0.9348\n",
            "Epoch 64: lr: 9.999999747378752e-06\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 1.1100e-04 - custom_f1: 0.9912 - val_loss: 0.3854 - val_custom_f1: 0.9232\n",
            "Epoch 65: lr: 9.999999747378752e-06\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.4413e-04 - custom_f1: 0.9823 - val_loss: 0.3932 - val_custom_f1: 0.9197\n",
            "Epoch 66: lr: 9.999999747378752e-06\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.8708e-05 - custom_f1: 1.0000 - val_loss: 0.3907 - val_custom_f1: 0.9232\n",
            "Epoch 67: lr: 9.999999747378752e-06\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.0430e-04 - custom_f1: 0.9912 - val_loss: 0.3846 - val_custom_f1: 0.9232\n",
            "Epoch 68: lr: 9.999999747378752e-06\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.4352e-04 - custom_f1: 0.9646 - val_loss: 0.3765 - val_custom_f1: 0.9232\n",
            "Epoch 69: lr: 9.999999747378752e-06\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.0672e-04 - custom_f1: 0.9823 - val_loss: 0.3788 - val_custom_f1: 0.9232\n",
            "Epoch 70: lr: 9.999999747378752e-06\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.0863e-05 - custom_f1: 0.9912 - val_loss: 0.3819 - val_custom_f1: 0.9232\n",
            "Epoch 71: lr: 9.999999747378752e-06\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.8956e-05 - custom_f1: 0.9823 - val_loss: 0.3888 - val_custom_f1: 0.9232\n",
            "Epoch 72: lr: 9.999999747378752e-06\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.5899e-05 - custom_f1: 0.9912 - val_loss: 0.3894 - val_custom_f1: 0.9232\n",
            "Epoch 73: lr: 9.999999747378752e-06\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.3092e-05 - custom_f1: 0.9823 - val_loss: 0.3939 - val_custom_f1: 0.9232\n",
            "Epoch 74: lr: 9.999999747378752e-06\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.3757e-04 - custom_f1: 0.9646 - val_loss: 0.3889 - val_custom_f1: 0.9232\n",
            "Epoch 75: lr: 9.999999747378752e-06\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 6.6066e-05 - custom_f1: 1.0000 - val_loss: 0.3955 - val_custom_f1: 0.9232\n",
            "Epoch 76: lr: 9.999999747378752e-06\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.5203e-04 - custom_f1: 0.9646 - val_loss: 0.3841 - val_custom_f1: 0.9232\n",
            "Epoch 77: lr: 9.999999747378752e-06\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.0648e-04 - custom_f1: 0.9823 - val_loss: 0.3845 - val_custom_f1: 0.9232\n",
            "Epoch 78: lr: 9.999999747378752e-06\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.8765e-05 - custom_f1: 1.0000 - val_loss: 0.3972 - val_custom_f1: 0.9081\n",
            "Epoch 79: lr: 9.999999747378752e-06\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.5977e-05 - custom_f1: 0.9735 - val_loss: 0.3969 - val_custom_f1: 0.9081\n",
            "Epoch 80: lr: 9.999999747378752e-06\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.0636e-05 - custom_f1: 0.9823 - val_loss: 0.3928 - val_custom_f1: 0.9232\n",
            "Epoch 81: lr: 9.999999747378752e-06\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.0658e-05 - custom_f1: 1.0000 - val_loss: 0.3977 - val_custom_f1: 0.9081\n",
            "Epoch 82: lr: 9.999999747378752e-06\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.6203e-05 - custom_f1: 0.9912 - val_loss: 0.4113 - val_custom_f1: 0.9081\n",
            "Epoch 83: lr: 9.999999747378752e-06\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.8696e-05 - custom_f1: 0.9823 - val_loss: 0.4139 - val_custom_f1: 0.9081\n",
            "Epoch 84: lr: 9.999999747378752e-06\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.7546e-05 - custom_f1: 0.9912 - val_loss: 0.4187 - val_custom_f1: 0.9081\n",
            "Epoch 85: lr: 9.999999747378752e-06\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.1161e-05 - custom_f1: 0.9823 - val_loss: 0.4240 - val_custom_f1: 0.9197\n",
            "Epoch 86: lr: 9.999999747378752e-06\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.7327e-05 - custom_f1: 0.9912 - val_loss: 0.4228 - val_custom_f1: 0.9197\n",
            "Epoch 87: lr: 9.999999747378752e-06\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.9497e-05 - custom_f1: 0.9735 - val_loss: 0.4131 - val_custom_f1: 0.9081\n",
            "Epoch 88: lr: 9.999999747378752e-06\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.2215e-05 - custom_f1: 0.9735 - val_loss: 0.4134 - val_custom_f1: 0.9081\n",
            "Epoch 89: lr: 9.999999747378752e-06\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.8060e-05 - custom_f1: 1.0000 - val_loss: 0.4115 - val_custom_f1: 0.9232\n",
            "Epoch 90: lr: 9.999999747378752e-06\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.4608e-05 - custom_f1: 0.9912 - val_loss: 0.4060 - val_custom_f1: 0.9232\n",
            "Epoch 91: lr: 9.999999747378752e-06\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.4945e-05 - custom_f1: 0.9912 - val_loss: 0.4256 - val_custom_f1: 0.9081\n",
            "Epoch 92: lr: 9.999999747378752e-06\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.2546e-05 - custom_f1: 0.9823 - val_loss: 0.4126 - val_custom_f1: 0.9081\n",
            "Epoch 93: lr: 9.999999747378752e-06\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.8423e-05 - custom_f1: 1.0000 - val_loss: 0.4395 - val_custom_f1: 0.9197\n",
            "Epoch 94: lr: 9.999999747378752e-06\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.9873e-05 - custom_f1: 0.9912 - val_loss: 0.4250 - val_custom_f1: 0.9081\n",
            "Epoch 95: lr: 9.999999747378752e-06\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.8016e-05 - custom_f1: 0.9912 - val_loss: 0.4390 - val_custom_f1: 0.9197\n",
            "Epoch 96: lr: 9.999999747378752e-06\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.2947e-05 - custom_f1: 0.9735 - val_loss: 0.4333 - val_custom_f1: 0.9197\n",
            "Epoch 97: lr: 9.999999747378752e-06\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.1799e-05 - custom_f1: 0.9912 - val_loss: 0.4370 - val_custom_f1: 0.9081\n",
            "Epoch 98: lr: 9.999999747378752e-06\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.4174e-05 - custom_f1: 0.9912 - val_loss: 0.4205 - val_custom_f1: 0.9081\n",
            "Epoch 99: lr: 9.999999747378752e-06\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.4371e-05 - custom_f1: 1.0000 - val_loss: 0.4307 - val_custom_f1: 0.9081\n",
            "Epoch 100: lr: 9.999999747378752e-06\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.5823e-05 - custom_f1: 0.9646 - val_loss: 0.4315 - val_custom_f1: 0.9081\n",
            "weights are setted to best weights (epochs 15)\n",
            "fold 6 [250,300]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.6215 - custom_f1: 0.7541\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 9s 83ms/step - loss: 0.6215 - custom_f1: 0.7541 - val_loss: 7.9240 - val_custom_f1: 0.7725\n",
            "Epoch 2: lr: 9.999999747378752e-05\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.4719 - custom_f1: 0.8190 - val_loss: 32.0885 - val_custom_f1: 0.7725\n",
            "Epoch 3: lr: 9.999999747378752e-05\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.3347 - custom_f1: 0.8919 - val_loss: 15.3599 - val_custom_f1: 0.7725\n",
            "Epoch 4: lr: 9.999999747378752e-05\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.2816 - custom_f1: 0.8886 - val_loss: 15.9887 - val_custom_f1: 0.7725\n",
            "Epoch 5: lr: 9.999999747378752e-05\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.2239 - custom_f1: 0.9270\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 88ms/step - loss: 0.2239 - custom_f1: 0.9270 - val_loss: 3.3258 - val_custom_f1: 0.7725\n",
            "Epoch 6: lr: 9.999999747378752e-05\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1429 - custom_f1: 0.9555\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 9s 82ms/step - loss: 0.1429 - custom_f1: 0.9555 - val_loss: 0.5290 - val_custom_f1: 0.8863\n",
            "Epoch 7: lr: 9.999999747378752e-05\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1687 - custom_f1: 0.9476\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 89ms/step - loss: 0.1687 - custom_f1: 0.9476 - val_loss: 0.3153 - val_custom_f1: 0.8452\n",
            "Epoch 8: lr: 9.999999747378752e-05\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1214 - custom_f1: 0.9616 - val_loss: 0.9164 - val_custom_f1: 0.5733\n",
            "Epoch 9: lr: 9.999999747378752e-05\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.1021 - custom_f1: 0.9592 - val_loss: 1.7317 - val_custom_f1: 0.2952\n",
            "Epoch 10: lr: 9.999999747378752e-05\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1797 - custom_f1: 0.9377 - val_loss: 2.7616 - val_custom_f1: 0.0000e+00\n",
            "Epoch 11: lr: 9.999999747378752e-05\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1101 - custom_f1: 0.9710 - val_loss: 0.4073 - val_custom_f1: 0.8838\n",
            "Epoch 12: lr: 9.999999747378752e-05\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0545 - custom_f1: 0.9831 - val_loss: 0.8907 - val_custom_f1: 0.8268\n",
            "Epoch 13: lr: 9.999999747378752e-05\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1062 - custom_f1: 0.9665 - val_loss: 0.4001 - val_custom_f1: 0.8838\n",
            "Epoch 14: lr: 9.999999747378752e-05\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1067 - custom_f1: 0.9650\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 89ms/step - loss: 0.1067 - custom_f1: 0.9650 - val_loss: 0.2588 - val_custom_f1: 0.8900\n",
            "Epoch 15: lr: 9.999999747378752e-05\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0852 - custom_f1: 0.9738\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 9s 82ms/step - loss: 0.0852 - custom_f1: 0.9738 - val_loss: 0.2130 - val_custom_f1: 0.9211\n",
            "Epoch 16: lr: 9.999999747378752e-05\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0499 - custom_f1: 0.9798 - val_loss: 0.4772 - val_custom_f1: 0.9222\n",
            "Epoch 17: lr: 9.999999747378752e-05\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1188 - custom_f1: 0.9623 - val_loss: 1.6914 - val_custom_f1: 0.1929\n",
            "Epoch 18: lr: 9.999999747378752e-05\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1128 - custom_f1: 0.9743 - val_loss: 0.3587 - val_custom_f1: 0.8348\n",
            "Epoch 19: lr: 9.999999747378752e-05\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0804 - custom_f1: 0.9680 - val_loss: 0.3041 - val_custom_f1: 0.8571\n",
            "Epoch 20: lr: 9.999999747378752e-05\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0533 - custom_f1: 0.9898 - val_loss: 0.3426 - val_custom_f1: 0.9146\n",
            "Epoch 21: lr: 9.999999747378752e-05\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0498 - custom_f1: 0.9912 - val_loss: 0.5998 - val_custom_f1: 0.8667\n",
            "Epoch 22: lr: 9.999999747378752e-05\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0366 - custom_f1: 0.9912 - val_loss: 0.3314 - val_custom_f1: 0.9146\n",
            "Epoch 23: lr: 9.999999747378752e-05\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0219 - custom_f1: 0.9894 - val_loss: 0.3021 - val_custom_f1: 0.9474\n",
            "Epoch 24: lr: 9.999999747378752e-05\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0320 - custom_f1: 0.9941 - val_loss: 0.3646 - val_custom_f1: 0.9419\n",
            "Epoch 25: lr: 9.999999747378752e-05\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0755 - custom_f1: 0.9692 - val_loss: 0.3337 - val_custom_f1: 0.8846\n",
            "Epoch 26: lr: 9.999999747378752e-05\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0468 - custom_f1: 0.9726 - val_loss: 0.4224 - val_custom_f1: 0.8545\n",
            "Epoch 27: lr: 9.999999747378752e-05\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0139 - custom_f1: 0.9912 - val_loss: 0.3095 - val_custom_f1: 0.8885\n",
            "Epoch 28: lr: 9.999999747378752e-05\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0045 - custom_f1: 1.0000 - val_loss: 0.3010 - val_custom_f1: 0.9390\n",
            "Epoch 29: lr: 9.999999747378752e-05\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0160 - custom_f1: 0.9823 - val_loss: 0.3433 - val_custom_f1: 0.8648\n",
            "Epoch 30: lr: 9.999999747378752e-05\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0227 - custom_f1: 0.9894 - val_loss: 0.2822 - val_custom_f1: 0.8969\n",
            "Epoch 31: lr: 9.999999747378752e-05\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0220 - custom_f1: 0.9965 - val_loss: 0.2762 - val_custom_f1: 0.9033\n",
            "Epoch 32: lr: 9.999999747378752e-05\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0122 - custom_f1: 0.9823 - val_loss: 0.2958 - val_custom_f1: 0.9219\n",
            "Epoch 33: lr: 9.999999747378752e-05\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0086 - custom_f1: 0.9912 - val_loss: 0.2964 - val_custom_f1: 0.8986\n",
            "Epoch 34: lr: 9.999999747378752e-05\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0092 - custom_f1: 0.9987 - val_loss: 0.2260 - val_custom_f1: 0.9286\n",
            "Epoch 35: lr: 9.999999747378752e-05\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0037 - custom_f1: 0.9823\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 89ms/step - loss: 0.0037 - custom_f1: 0.9823 - val_loss: 0.1931 - val_custom_f1: 0.9500\n",
            "Epoch 36: lr: 9.999999747378752e-05\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0099 - custom_f1: 0.9912 - val_loss: 0.2386 - val_custom_f1: 0.9324\n",
            "Epoch 37: lr: 9.999999747378752e-05\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0654 - custom_f1: 0.9669 - val_loss: 0.3300 - val_custom_f1: 0.8946\n",
            "Epoch 38: lr: 9.999999747378752e-05\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0189 - custom_f1: 0.9953 - val_loss: 0.4623 - val_custom_f1: 0.7952\n",
            "Epoch 39: lr: 9.999999747378752e-05\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0159 - custom_f1: 0.9823 - val_loss: 0.3941 - val_custom_f1: 0.8497\n",
            "Epoch 40: lr: 9.999999747378752e-05\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0478 - custom_f1: 0.9589 - val_loss: 0.8344 - val_custom_f1: 0.6369\n",
            "Epoch 41: lr: 9.999999747378752e-05\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0224 - custom_f1: 0.9810 - val_loss: 0.3568 - val_custom_f1: 0.8838\n",
            "Epoch 42: lr: 9.999999747378752e-05\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0051 - custom_f1: 0.9912 - val_loss: 0.3029 - val_custom_f1: 0.8863\n",
            "Epoch 43: lr: 9.999999747378752e-05\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0069 - custom_f1: 0.9735 - val_loss: 0.2739 - val_custom_f1: 0.9242\n",
            "Epoch 44: lr: 9.999999747378752e-05\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0161 - custom_f1: 0.9705 - val_loss: 0.2146 - val_custom_f1: 0.9500\n",
            "Epoch 45: lr: 9.999999747378752e-05\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0016 - custom_f1: 1.0000 - val_loss: 0.2312 - val_custom_f1: 0.9115\n",
            "Epoch 46: lr: 9.999999747378752e-05\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0011 - custom_f1: 0.9823 - val_loss: 0.2491 - val_custom_f1: 0.9115\n",
            "Epoch 47: lr: 9.999999747378752e-05\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0012 - custom_f1: 0.9823 - val_loss: 0.2187 - val_custom_f1: 0.9115\n",
            "Epoch 48: lr: 9.999999747378752e-05\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.1872e-04 - custom_f1: 0.9912 - val_loss: 0.2136 - val_custom_f1: 0.9300\n",
            "Epoch 49: lr: 9.999999747378752e-05\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.5882e-04 - custom_f1: 0.9912 - val_loss: 0.2046 - val_custom_f1: 0.9300\n",
            "Epoch 50: lr: 9.999999747378752e-05\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.1799e-04 - custom_f1: 0.9912 - val_loss: 0.2086 - val_custom_f1: 0.9300\n",
            "Epoch 51: lr: 9.999999747378752e-05\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 3.4181e-04 - custom_f1: 0.9912\n",
            "lr is fixed to 9.999999747378752e-06\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.4181e-04 - custom_f1: 0.9912 - val_loss: 0.2119 - val_custom_f1: 0.9300\n",
            "Epoch 52: lr: 9.999999747378752e-06\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.9059e-04 - custom_f1: 0.9823 - val_loss: 0.2133 - val_custom_f1: 0.9300\n",
            "Epoch 53: lr: 9.999999747378752e-06\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.0691e-04 - custom_f1: 1.0000 - val_loss: 0.2104 - val_custom_f1: 0.9300\n",
            "Epoch 54: lr: 9.999999747378752e-06\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.2346e-04 - custom_f1: 0.9912 - val_loss: 0.2136 - val_custom_f1: 0.9300\n",
            "Epoch 55: lr: 9.999999747378752e-06\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.1704e-04 - custom_f1: 0.9823 - val_loss: 0.2045 - val_custom_f1: 0.9300\n",
            "Epoch 56: lr: 9.999999747378752e-06\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.0975e-04 - custom_f1: 0.9912 - val_loss: 0.1996 - val_custom_f1: 0.9300\n",
            "Epoch 57: lr: 9.999999747378752e-06\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.6883e-04 - custom_f1: 1.0000 - val_loss: 0.2011 - val_custom_f1: 0.9300\n",
            "Epoch 58: lr: 9.999999747378752e-06\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.0824e-04 - custom_f1: 0.9912 - val_loss: 0.2041 - val_custom_f1: 0.9300\n",
            "Epoch 59: lr: 9.999999747378752e-06\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 2.9859e-04 - custom_f1: 1.0000 - val_loss: 0.2038 - val_custom_f1: 0.9300\n",
            "Epoch 60: lr: 9.999999747378752e-06\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.7979e-04 - custom_f1: 0.9823 - val_loss: 0.2006 - val_custom_f1: 0.9300\n",
            "Epoch 61: lr: 9.999999747378752e-06\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.2200e-04 - custom_f1: 0.9735 - val_loss: 0.2000 - val_custom_f1: 0.9300\n",
            "Epoch 62: lr: 9.999999747378752e-06\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.6714e-04 - custom_f1: 0.9912 - val_loss: 0.1975 - val_custom_f1: 0.9300\n",
            "Epoch 63: lr: 9.999999747378752e-06\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.4262e-04 - custom_f1: 0.9735 - val_loss: 0.1993 - val_custom_f1: 0.9300\n",
            "Epoch 64: lr: 9.999999747378752e-06\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.9985e-04 - custom_f1: 0.9912 - val_loss: 0.1980 - val_custom_f1: 0.9300\n",
            "Epoch 65: lr: 9.999999747378752e-06\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.8460e-04 - custom_f1: 0.9912 - val_loss: 0.1985 - val_custom_f1: 0.9500\n",
            "Epoch 66: lr: 9.999999747378752e-06\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.8196e-04 - custom_f1: 0.9912 - val_loss: 0.2033 - val_custom_f1: 0.9300\n",
            "Epoch 67: lr: 9.999999747378752e-06\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 2.8734e-04 - custom_f1: 0.9823 - val_loss: 0.2019 - val_custom_f1: 0.9300\n",
            "Epoch 68: lr: 9.999999747378752e-06\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 4.2901e-04 - custom_f1: 0.9823 - val_loss: 0.1947 - val_custom_f1: 0.9500\n",
            "Epoch 69: lr: 9.999999747378752e-06\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 4.1107e-04 - custom_f1: 0.9646 - val_loss: 0.1962 - val_custom_f1: 0.9300\n",
            "Epoch 70: lr: 9.999999747378752e-06\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.5643e-04 - custom_f1: 0.9912 - val_loss: 0.1975 - val_custom_f1: 0.9300\n",
            "Epoch 71: lr: 9.999999747378752e-06\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.9120e-04 - custom_f1: 0.9469 - val_loss: 0.2026 - val_custom_f1: 0.9300\n",
            "Epoch 72: lr: 9.999999747378752e-06\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.4646e-04 - custom_f1: 0.9823 - val_loss: 0.1978 - val_custom_f1: 0.9300\n",
            "Epoch 73: lr: 9.999999747378752e-06\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.6835e-04 - custom_f1: 0.9823 - val_loss: 0.1977 - val_custom_f1: 0.9300\n",
            "Epoch 74: lr: 9.999999747378752e-06\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.0355e-04 - custom_f1: 0.9912 - val_loss: 0.1968 - val_custom_f1: 0.9300\n",
            "Epoch 75: lr: 9.999999747378752e-06\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.3801e-04 - custom_f1: 0.9912 - val_loss: 0.1971 - val_custom_f1: 0.9300\n",
            "Epoch 76: lr: 9.999999747378752e-06\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 4.4404e-04 - custom_f1: 0.9558\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 90ms/step - loss: 4.4404e-04 - custom_f1: 0.9558 - val_loss: 0.1868 - val_custom_f1: 0.9500\n",
            "Epoch 77: lr: 9.999999747378752e-06\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 3.4519e-04 - custom_f1: 0.9912\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 9s 82ms/step - loss: 3.4519e-04 - custom_f1: 0.9912 - val_loss: 0.1742 - val_custom_f1: 0.9500\n",
            "Epoch 78: lr: 9.999999747378752e-06\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 2.2968e-04 - custom_f1: 0.9912 - val_loss: 0.1790 - val_custom_f1: 0.9500\n",
            "Epoch 79: lr: 9.999999747378752e-06\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.5549e-04 - custom_f1: 0.9912 - val_loss: 0.1862 - val_custom_f1: 0.9500\n",
            "Epoch 80: lr: 9.999999747378752e-06\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 4.9372e-04 - custom_f1: 0.9646\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 88ms/step - loss: 4.9372e-04 - custom_f1: 0.9646 - val_loss: 0.1589 - val_custom_f1: 0.9737\n",
            "Epoch 81: lr: 9.999999747378752e-06\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 1.9110e-04 - custom_f1: 0.9912 - val_loss: 0.1718 - val_custom_f1: 0.9500\n",
            "Epoch 82: lr: 9.999999747378752e-06\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.3929e-04 - custom_f1: 0.9823 - val_loss: 0.1834 - val_custom_f1: 0.9500\n",
            "Epoch 83: lr: 9.999999747378752e-06\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.2515e-04 - custom_f1: 0.9823 - val_loss: 0.1959 - val_custom_f1: 0.9500\n",
            "Epoch 84: lr: 9.999999747378752e-06\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.5660e-04 - custom_f1: 0.9735 - val_loss: 0.2021 - val_custom_f1: 0.9300\n",
            "Epoch 85: lr: 9.999999747378752e-06\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.4548e-04 - custom_f1: 1.0000 - val_loss: 0.1966 - val_custom_f1: 0.9500\n",
            "Epoch 86: lr: 9.999999747378752e-06\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.0079e-04 - custom_f1: 0.9646 - val_loss: 0.1955 - val_custom_f1: 0.9500\n",
            "Epoch 87: lr: 9.999999747378752e-06\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.8081e-04 - custom_f1: 0.9912 - val_loss: 0.1917 - val_custom_f1: 0.9500\n",
            "Epoch 88: lr: 9.999999747378752e-06\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.5887e-04 - custom_f1: 0.9823 - val_loss: 0.1978 - val_custom_f1: 0.9300\n",
            "Epoch 89: lr: 9.999999747378752e-06\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.1494e-04 - custom_f1: 0.9912 - val_loss: 0.1983 - val_custom_f1: 0.9300\n",
            "Epoch 90: lr: 9.999999747378752e-06\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.3685e-04 - custom_f1: 0.9912 - val_loss: 0.1974 - val_custom_f1: 0.9300\n",
            "Epoch 91: lr: 9.999999747378752e-06\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.2139e-04 - custom_f1: 1.0000 - val_loss: 0.1997 - val_custom_f1: 0.9300\n",
            "Epoch 92: lr: 9.999999747378752e-06\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.5453e-04 - custom_f1: 0.9912 - val_loss: 0.1974 - val_custom_f1: 0.9500\n",
            "Epoch 93: lr: 9.999999747378752e-06\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.4933e-04 - custom_f1: 0.9912 - val_loss: 0.2029 - val_custom_f1: 0.9500\n",
            "Epoch 94: lr: 9.999999747378752e-06\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.5043e-04 - custom_f1: 0.9823 - val_loss: 0.1988 - val_custom_f1: 0.9500\n",
            "Epoch 95: lr: 9.999999747378752e-06\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.1731e-04 - custom_f1: 1.0000 - val_loss: 0.2087 - val_custom_f1: 0.9115\n",
            "Epoch 96: lr: 9.999999747378752e-06\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.0972e-04 - custom_f1: 1.0000 - val_loss: 0.2132 - val_custom_f1: 0.9115\n",
            "Epoch 97: lr: 9.999999747378752e-06\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.1422e-04 - custom_f1: 0.9823 - val_loss: 0.2095 - val_custom_f1: 0.9115\n",
            "Epoch 98: lr: 9.999999747378752e-06\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 8.8802e-05 - custom_f1: 1.0000 - val_loss: 0.2043 - val_custom_f1: 0.9300\n",
            "Epoch 99: lr: 9.999999747378752e-06\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.8839e-05 - custom_f1: 0.9823 - val_loss: 0.2007 - val_custom_f1: 0.9300\n",
            "Epoch 100: lr: 9.999999747378752e-06\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.3718e-04 - custom_f1: 0.9735 - val_loss: 0.1996 - val_custom_f1: 0.9500\n",
            "weights are setted to best weights (epochs 80)\n",
            "fold 7 [300,350]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.6063 - custom_f1: 0.7791\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 9s 82ms/step - loss: 0.6063 - custom_f1: 0.7791 - val_loss: 14.1584 - val_custom_f1: 0.8074\n",
            "Epoch 2: lr: 9.999999747378752e-05\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.4006 - custom_f1: 0.8514\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 88ms/step - loss: 0.4006 - custom_f1: 0.8514 - val_loss: 5.3051 - val_custom_f1: 0.8074\n",
            "Epoch 3: lr: 9.999999747378752e-05\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.2691 - custom_f1: 0.9091 - val_loss: 18.6054 - val_custom_f1: 0.8074\n",
            "Epoch 4: lr: 9.999999747378752e-05\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.2447 - custom_f1: 0.9104 - val_loss: 9.0614 - val_custom_f1: 0.8074\n",
            "Epoch 5: lr: 9.999999747378752e-05\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.2171 - custom_f1: 0.9293\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 88ms/step - loss: 0.2171 - custom_f1: 0.9293 - val_loss: 4.7263 - val_custom_f1: 0.8074\n",
            "Epoch 6: lr: 9.999999747378752e-05\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1803 - custom_f1: 0.9276\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 9s 82ms/step - loss: 0.1803 - custom_f1: 0.9276 - val_loss: 1.3246 - val_custom_f1: 0.8151\n",
            "Epoch 7: lr: 9.999999747378752e-05\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1269 - custom_f1: 0.9578\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 90ms/step - loss: 0.1269 - custom_f1: 0.9578 - val_loss: 0.3386 - val_custom_f1: 0.8983\n",
            "Epoch 8: lr: 9.999999747378752e-05\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0711 - custom_f1: 0.9759 - val_loss: 0.7421 - val_custom_f1: 0.8400\n",
            "Epoch 9: lr: 9.999999747378752e-05\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1055 - custom_f1: 0.9671 - val_loss: 0.3810 - val_custom_f1: 0.8450\n",
            "Epoch 10: lr: 9.999999747378752e-05\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0881 - custom_f1: 0.9697 - val_loss: 1.3653 - val_custom_f1: 0.8231\n",
            "Epoch 11: lr: 9.999999747378752e-05\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0966 - custom_f1: 0.9661 - val_loss: 2.3157 - val_custom_f1: 0.8074\n",
            "Epoch 12: lr: 9.999999747378752e-05\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0952 - custom_f1: 0.9648 - val_loss: 0.4569 - val_custom_f1: 0.7714\n",
            "Epoch 13: lr: 9.999999747378752e-05\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0437 - custom_f1: 0.9822 - val_loss: 0.8611 - val_custom_f1: 0.5355\n",
            "Epoch 14: lr: 9.999999747378752e-05\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0251 - custom_f1: 0.9958\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 88ms/step - loss: 0.0251 - custom_f1: 0.9958 - val_loss: 0.3227 - val_custom_f1: 0.8814\n",
            "Epoch 15: lr: 9.999999747378752e-05\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0239 - custom_f1: 0.9933\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 9s 81ms/step - loss: 0.0239 - custom_f1: 0.9933 - val_loss: 0.2631 - val_custom_f1: 0.9081\n",
            "Epoch 16: lr: 9.999999747378752e-05\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0436 - custom_f1: 0.9840 - val_loss: 0.6400 - val_custom_f1: 0.8934\n",
            "Epoch 17: lr: 9.999999747378752e-05\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1065 - custom_f1: 0.9608\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 87ms/step - loss: 0.1065 - custom_f1: 0.9608 - val_loss: 0.2620 - val_custom_f1: 0.9197\n",
            "Epoch 18: lr: 9.999999747378752e-05\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0940 - custom_f1: 0.9643\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 9s 82ms/step - loss: 0.0940 - custom_f1: 0.9643 - val_loss: 0.2161 - val_custom_f1: 0.9417\n",
            "Epoch 19: lr: 9.999999747378752e-05\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0703 - custom_f1: 0.9776 - val_loss: 2.2182 - val_custom_f1: 0.0000e+00\n",
            "Epoch 20: lr: 9.999999747378752e-05\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0908 - custom_f1: 0.9598 - val_loss: 0.4106 - val_custom_f1: 0.8634\n",
            "Epoch 21: lr: 9.999999747378752e-05\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0288 - custom_f1: 0.9899 - val_loss: 0.3555 - val_custom_f1: 0.8340\n",
            "Epoch 22: lr: 9.999999747378752e-05\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0301 - custom_f1: 0.9805 - val_loss: 0.4509 - val_custom_f1: 0.8474\n",
            "Epoch 23: lr: 9.999999747378752e-05\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0387 - custom_f1: 0.9847 - val_loss: 0.4461 - val_custom_f1: 0.8500\n",
            "Epoch 24: lr: 9.999999747378752e-05\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0525 - custom_f1: 0.9746\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 91ms/step - loss: 0.0525 - custom_f1: 0.9746 - val_loss: 0.1665 - val_custom_f1: 0.9583\n",
            "Epoch 25: lr: 9.999999747378752e-05\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0181 - custom_f1: 0.9705 - val_loss: 0.5375 - val_custom_f1: 0.6863\n",
            "Epoch 26: lr: 9.999999747378752e-05\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0131 - custom_f1: 0.9853 - val_loss: 0.3772 - val_custom_f1: 0.9028\n",
            "Epoch 27: lr: 9.999999747378752e-05\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0072 - custom_f1: 0.9912 - val_loss: 0.2221 - val_custom_f1: 0.9183\n",
            "Epoch 28: lr: 9.999999747378752e-05\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0018 - custom_f1: 1.0000 - val_loss: 0.2075 - val_custom_f1: 0.9289\n",
            "Epoch 29: lr: 9.999999747378752e-05\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0011 - custom_f1: 1.0000 - val_loss: 0.2142 - val_custom_f1: 0.9183\n",
            "Epoch 30: lr: 9.999999747378752e-05\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0074 - custom_f1: 0.9823 - val_loss: 0.2276 - val_custom_f1: 0.9356\n",
            "Epoch 31: lr: 9.999999747378752e-05\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0057 - custom_f1: 0.9982 - val_loss: 0.5627 - val_custom_f1: 0.7222\n",
            "Epoch 32: lr: 9.999999747378752e-05\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0429 - custom_f1: 0.9715 - val_loss: 0.2735 - val_custom_f1: 0.9296\n",
            "Epoch 33: lr: 9.999999747378752e-05\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0147 - custom_f1: 0.9823 - val_loss: 0.2301 - val_custom_f1: 0.9212\n",
            "Epoch 34: lr: 9.999999747378752e-05\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0262 - custom_f1: 0.9704 - val_loss: 0.2838 - val_custom_f1: 0.8853\n",
            "Epoch 35: lr: 9.999999747378752e-05\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0043 - custom_f1: 0.9912 - val_loss: 0.2412 - val_custom_f1: 0.9348\n",
            "Epoch 36: lr: 9.999999747378752e-05\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0085 - custom_f1: 0.9823 - val_loss: 0.3979 - val_custom_f1: 0.9081\n",
            "Epoch 37: lr: 9.999999747378752e-05\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0220 - custom_f1: 0.9805 - val_loss: 1.2804 - val_custom_f1: 0.1863\n",
            "Epoch 38: lr: 9.999999747378752e-05\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0119 - custom_f1: 0.9899 - val_loss: 1.3733 - val_custom_f1: 0.4352\n",
            "Epoch 39: lr: 9.999999747378752e-05\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0111 - custom_f1: 0.9899 - val_loss: 0.3891 - val_custom_f1: 0.8848\n",
            "Epoch 40: lr: 9.999999747378752e-05\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0042 - custom_f1: 0.9823 - val_loss: 0.3680 - val_custom_f1: 0.8681\n",
            "Epoch 41: lr: 9.999999747378752e-05\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0016 - custom_f1: 0.9823 - val_loss: 0.3665 - val_custom_f1: 0.8848\n",
            "Epoch 42: lr: 9.999999747378752e-05\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0015 - custom_f1: 0.9646 - val_loss: 0.3451 - val_custom_f1: 0.8681\n",
            "Epoch 43: lr: 9.999999747378752e-05\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0010 - custom_f1: 0.9912 - val_loss: 0.3442 - val_custom_f1: 0.8949\n",
            "Epoch 44: lr: 9.999999747378752e-05\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.9379e-04 - custom_f1: 0.9735 - val_loss: 0.3404 - val_custom_f1: 0.8848\n",
            "Epoch 45: lr: 9.999999747378752e-05\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.6199e-04 - custom_f1: 0.9646 - val_loss: 0.3187 - val_custom_f1: 0.8949\n",
            "Epoch 46: lr: 9.999999747378752e-05\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.4109e-04 - custom_f1: 0.9912 - val_loss: 0.3360 - val_custom_f1: 0.8848\n",
            "Epoch 47: lr: 9.999999747378752e-05\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.9786e-04 - custom_f1: 0.9912 - val_loss: 0.3468 - val_custom_f1: 0.8848\n",
            "Epoch 48: lr: 9.999999747378752e-05\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.3099e-04 - custom_f1: 1.0000 - val_loss: 0.3534 - val_custom_f1: 0.8848\n",
            "Epoch 49: lr: 9.999999747378752e-05\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.2266e-04 - custom_f1: 0.9735 - val_loss: 0.3358 - val_custom_f1: 0.8848\n",
            "Epoch 50: lr: 9.999999747378752e-05\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.1930e-04 - custom_f1: 0.9912 - val_loss: 0.3568 - val_custom_f1: 0.8848\n",
            "Epoch 51: lr: 9.999999747378752e-05\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 2.2046e-04 - custom_f1: 0.9823\n",
            "lr is fixed to 9.999999747378752e-06\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.2046e-04 - custom_f1: 0.9823 - val_loss: 0.3387 - val_custom_f1: 0.8848\n",
            "Epoch 52: lr: 9.999999747378752e-06\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.6910e-04 - custom_f1: 0.9823 - val_loss: 0.3421 - val_custom_f1: 0.8848\n",
            "Epoch 53: lr: 9.999999747378752e-06\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.9142e-04 - custom_f1: 0.9912 - val_loss: 0.3353 - val_custom_f1: 0.8848\n",
            "Epoch 54: lr: 9.999999747378752e-06\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 2.7251e-04 - custom_f1: 0.9823 - val_loss: 0.3428 - val_custom_f1: 0.8848\n",
            "Epoch 55: lr: 9.999999747378752e-06\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.6419e-04 - custom_f1: 0.9912 - val_loss: 0.3380 - val_custom_f1: 0.8848\n",
            "Epoch 56: lr: 9.999999747378752e-06\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.1776e-04 - custom_f1: 0.9823 - val_loss: 0.3333 - val_custom_f1: 0.8949\n",
            "Epoch 57: lr: 9.999999747378752e-06\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.3480e-04 - custom_f1: 0.9735 - val_loss: 0.3343 - val_custom_f1: 0.8949\n",
            "Epoch 58: lr: 9.999999747378752e-06\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.4172e-04 - custom_f1: 0.9823 - val_loss: 0.3349 - val_custom_f1: 0.8848\n",
            "Epoch 59: lr: 9.999999747378752e-06\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.0271e-04 - custom_f1: 0.9823 - val_loss: 0.3373 - val_custom_f1: 0.8848\n",
            "Epoch 60: lr: 9.999999747378752e-06\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.5158e-04 - custom_f1: 0.9912 - val_loss: 0.3412 - val_custom_f1: 0.8848\n",
            "Epoch 61: lr: 9.999999747378752e-06\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 2.0243e-04 - custom_f1: 0.9823 - val_loss: 0.3332 - val_custom_f1: 0.8949\n",
            "Epoch 62: lr: 9.999999747378752e-06\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.9630e-04 - custom_f1: 0.9912 - val_loss: 0.3348 - val_custom_f1: 0.8848\n",
            "Epoch 63: lr: 9.999999747378752e-06\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.7395e-04 - custom_f1: 0.9735 - val_loss: 0.3335 - val_custom_f1: 0.8848\n",
            "Epoch 64: lr: 9.999999747378752e-06\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.4016e-04 - custom_f1: 0.9823 - val_loss: 0.3385 - val_custom_f1: 0.8848\n",
            "Epoch 65: lr: 9.999999747378752e-06\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.3182e-04 - custom_f1: 0.9735 - val_loss: 0.3349 - val_custom_f1: 0.8848\n",
            "Epoch 66: lr: 9.999999747378752e-06\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.4422e-04 - custom_f1: 0.9912 - val_loss: 0.3387 - val_custom_f1: 0.8848\n",
            "Epoch 67: lr: 9.999999747378752e-06\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.7958e-04 - custom_f1: 0.9912 - val_loss: 0.3333 - val_custom_f1: 0.8848\n",
            "Epoch 68: lr: 9.999999747378752e-06\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.3802e-04 - custom_f1: 1.0000 - val_loss: 0.3382 - val_custom_f1: 0.8848\n",
            "Epoch 69: lr: 9.999999747378752e-06\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.8970e-04 - custom_f1: 0.9823 - val_loss: 0.3405 - val_custom_f1: 0.8848\n",
            "Epoch 70: lr: 9.999999747378752e-06\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.1496e-04 - custom_f1: 0.9912 - val_loss: 0.3427 - val_custom_f1: 0.8848\n",
            "Epoch 71: lr: 9.999999747378752e-06\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.6359e-04 - custom_f1: 0.9823 - val_loss: 0.3376 - val_custom_f1: 0.8848\n",
            "Epoch 72: lr: 9.999999747378752e-06\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.7520e-04 - custom_f1: 0.9912 - val_loss: 0.3356 - val_custom_f1: 0.8848\n",
            "Epoch 73: lr: 9.999999747378752e-06\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 1.8297e-04 - custom_f1: 0.9912 - val_loss: 0.3336 - val_custom_f1: 0.8848\n",
            "Epoch 74: lr: 9.999999747378752e-06\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.5198e-04 - custom_f1: 0.9735 - val_loss: 0.3354 - val_custom_f1: 0.8848\n",
            "Epoch 75: lr: 9.999999747378752e-06\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.1495e-04 - custom_f1: 1.0000 - val_loss: 0.3380 - val_custom_f1: 0.8848\n",
            "Epoch 76: lr: 9.999999747378752e-06\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.5092e-04 - custom_f1: 0.9823 - val_loss: 0.3328 - val_custom_f1: 0.8848\n",
            "Epoch 77: lr: 9.999999747378752e-06\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.4054e-04 - custom_f1: 0.9912 - val_loss: 0.3325 - val_custom_f1: 0.8848\n",
            "Epoch 78: lr: 9.999999747378752e-06\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 9.2529e-05 - custom_f1: 1.0000 - val_loss: 0.3414 - val_custom_f1: 0.8848\n",
            "Epoch 79: lr: 9.999999747378752e-06\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.1531e-04 - custom_f1: 0.9912 - val_loss: 0.3382 - val_custom_f1: 0.8848\n",
            "Epoch 80: lr: 9.999999747378752e-06\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.4164e-04 - custom_f1: 0.9912 - val_loss: 0.3307 - val_custom_f1: 0.8848\n",
            "Epoch 81: lr: 9.999999747378752e-06\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 8.0666e-05 - custom_f1: 0.9912 - val_loss: 0.3423 - val_custom_f1: 0.8848\n",
            "Epoch 82: lr: 9.999999747378752e-06\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.1390e-04 - custom_f1: 0.9823 - val_loss: 0.3469 - val_custom_f1: 0.8848\n",
            "Epoch 83: lr: 9.999999747378752e-06\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 8.5255e-05 - custom_f1: 1.0000 - val_loss: 0.3431 - val_custom_f1: 0.8848\n",
            "Epoch 84: lr: 9.999999747378752e-06\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 8.7662e-05 - custom_f1: 0.9912 - val_loss: 0.3455 - val_custom_f1: 0.8848\n",
            "Epoch 85: lr: 9.999999747378752e-06\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.5029e-04 - custom_f1: 0.9823 - val_loss: 0.3426 - val_custom_f1: 0.8848\n",
            "Epoch 86: lr: 9.999999747378752e-06\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.8022e-04 - custom_f1: 0.9823 - val_loss: 0.3262 - val_custom_f1: 0.8949\n",
            "Epoch 87: lr: 9.999999747378752e-06\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.9654e-05 - custom_f1: 0.9912 - val_loss: 0.3349 - val_custom_f1: 0.8848\n",
            "Epoch 88: lr: 9.999999747378752e-06\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.0509e-04 - custom_f1: 0.9912 - val_loss: 0.3345 - val_custom_f1: 0.8848\n",
            "Epoch 89: lr: 9.999999747378752e-06\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.5329e-05 - custom_f1: 1.0000 - val_loss: 0.3377 - val_custom_f1: 0.8848\n",
            "Epoch 90: lr: 9.999999747378752e-06\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.0201e-04 - custom_f1: 0.9735 - val_loss: 0.3410 - val_custom_f1: 0.8848\n",
            "Epoch 91: lr: 9.999999747378752e-06\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.4183e-04 - custom_f1: 0.9558 - val_loss: 0.3303 - val_custom_f1: 0.8848\n",
            "Epoch 92: lr: 9.999999747378752e-06\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 8.1957e-05 - custom_f1: 0.9912 - val_loss: 0.3403 - val_custom_f1: 0.8848\n",
            "Epoch 93: lr: 9.999999747378752e-06\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.8381e-05 - custom_f1: 1.0000 - val_loss: 0.3522 - val_custom_f1: 0.8848\n",
            "Epoch 94: lr: 9.999999747378752e-06\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.2162e-05 - custom_f1: 1.0000 - val_loss: 0.3476 - val_custom_f1: 0.8848\n",
            "Epoch 95: lr: 9.999999747378752e-06\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.3520e-04 - custom_f1: 0.9735 - val_loss: 0.3438 - val_custom_f1: 0.8848\n",
            "Epoch 96: lr: 9.999999747378752e-06\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.2538e-05 - custom_f1: 0.9912 - val_loss: 0.3467 - val_custom_f1: 0.8848\n",
            "Epoch 97: lr: 9.999999747378752e-06\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.1208e-04 - custom_f1: 0.9823 - val_loss: 0.3332 - val_custom_f1: 0.8848\n",
            "Epoch 98: lr: 9.999999747378752e-06\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.0861e-05 - custom_f1: 0.9912 - val_loss: 0.3291 - val_custom_f1: 0.8848\n",
            "Epoch 99: lr: 9.999999747378752e-06\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 6.1554e-05 - custom_f1: 1.0000 - val_loss: 0.3332 - val_custom_f1: 0.8848\n",
            "Epoch 100: lr: 9.999999747378752e-06\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.4140e-05 - custom_f1: 0.9912 - val_loss: 0.3374 - val_custom_f1: 0.8848\n",
            "weights are setted to best weights (epochs 24)\n",
            "fold 8 [350,400]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.6144 - custom_f1: 0.7627\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 9s 82ms/step - loss: 0.6144 - custom_f1: 0.7627 - val_loss: 7.8537 - val_custom_f1: 0.8557\n",
            "Epoch 2: lr: 9.999999747378752e-05\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.4017 - custom_f1: 0.8394 - val_loss: 30.8799 - val_custom_f1: 0.8557\n",
            "Epoch 3: lr: 9.999999747378752e-05\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.2546 - custom_f1: 0.8901 - val_loss: 19.0951 - val_custom_f1: 0.8557\n",
            "Epoch 4: lr: 9.999999747378752e-05\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.2331 - custom_f1: 0.9184 - val_loss: 33.2437 - val_custom_f1: 0.8557\n",
            "Epoch 5: lr: 9.999999747378752e-05\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.2115 - custom_f1: 0.9172\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 88ms/step - loss: 0.2115 - custom_f1: 0.9172 - val_loss: 2.9290 - val_custom_f1: 0.8557\n",
            "Epoch 6: lr: 9.999999747378752e-05\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1499 - custom_f1: 0.9390\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 9s 82ms/step - loss: 0.1499 - custom_f1: 0.9390 - val_loss: 1.9957 - val_custom_f1: 0.8775\n",
            "Epoch 7: lr: 9.999999747378752e-05\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1226 - custom_f1: 0.9619\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 9s 82ms/step - loss: 0.1226 - custom_f1: 0.9619 - val_loss: 0.5267 - val_custom_f1: 0.8926\n",
            "Epoch 8: lr: 9.999999747378752e-05\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1236 - custom_f1: 0.9634\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 9s 82ms/step - loss: 0.1236 - custom_f1: 0.9634 - val_loss: 0.2972 - val_custom_f1: 0.9018\n",
            "Epoch 9: lr: 9.999999747378752e-05\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1126 - custom_f1: 0.9685\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 9s 83ms/step - loss: 0.1126 - custom_f1: 0.9685 - val_loss: 0.1997 - val_custom_f1: 0.9610\n",
            "Epoch 10: lr: 9.999999747378752e-05\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1407 - custom_f1: 0.9513 - val_loss: 1.5393 - val_custom_f1: 0.4113\n",
            "Epoch 11: lr: 9.999999747378752e-05\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0666 - custom_f1: 0.9856 - val_loss: 0.2709 - val_custom_f1: 0.9173\n",
            "Epoch 12: lr: 9.999999747378752e-05\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1014 - custom_f1: 0.9652 - val_loss: 0.5562 - val_custom_f1: 0.7783\n",
            "Epoch 13: lr: 9.999999747378752e-05\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0472 - custom_f1: 0.9911\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 11s 94ms/step - loss: 0.0472 - custom_f1: 0.9911 - val_loss: 0.1780 - val_custom_f1: 0.9597\n",
            "Epoch 14: lr: 9.999999747378752e-05\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0645 - custom_f1: 0.9853 - val_loss: 0.8763 - val_custom_f1: 0.8634\n",
            "Epoch 15: lr: 9.999999747378752e-05\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0809 - custom_f1: 0.9738\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 89ms/step - loss: 0.0809 - custom_f1: 0.9738 - val_loss: 0.1670 - val_custom_f1: 0.9681\n",
            "Epoch 16: lr: 9.999999747378752e-05\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0402 - custom_f1: 0.9883 - val_loss: 0.3770 - val_custom_f1: 0.9173\n",
            "Epoch 17: lr: 9.999999747378752e-05\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0998 - custom_f1: 0.9662 - val_loss: 0.2708 - val_custom_f1: 0.9289\n",
            "Epoch 18: lr: 9.999999747378752e-05\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0331 - custom_f1: 0.9899 - val_loss: 0.2110 - val_custom_f1: 0.9583\n",
            "Epoch 19: lr: 9.999999747378752e-05\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0219 - custom_f1: 0.9928 - val_loss: 0.2040 - val_custom_f1: 0.9398\n",
            "Epoch 20: lr: 9.999999747378752e-05\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0525 - custom_f1: 0.9842 - val_loss: 0.2080 - val_custom_f1: 0.9411\n",
            "Epoch 21: lr: 9.999999747378752e-05\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0973 - custom_f1: 0.9656 - val_loss: 0.3700 - val_custom_f1: 0.9058\n",
            "Epoch 22: lr: 9.999999747378752e-05\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0908 - custom_f1: 0.9713 - val_loss: 0.2022 - val_custom_f1: 0.9380\n",
            "Epoch 23: lr: 9.999999747378752e-05\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0983 - custom_f1: 0.9472 - val_loss: 0.7245 - val_custom_f1: 0.4706\n",
            "Epoch 24: lr: 9.999999747378752e-05\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0211 - custom_f1: 0.9941 - val_loss: 0.1889 - val_custom_f1: 0.9481\n",
            "Epoch 25: lr: 9.999999747378752e-05\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0178 - custom_f1: 0.9735 - val_loss: 0.2631 - val_custom_f1: 0.9388\n",
            "Epoch 26: lr: 9.999999747378752e-05\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0050 - custom_f1: 0.9823 - val_loss: 0.2411 - val_custom_f1: 0.9588\n",
            "Epoch 27: lr: 9.999999747378752e-05\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0014 - custom_f1: 1.0000 - val_loss: 0.2092 - val_custom_f1: 0.9783\n",
            "Epoch 28: lr: 9.999999747378752e-05\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0015 - custom_f1: 0.9912 - val_loss: 0.2498 - val_custom_f1: 0.9481\n",
            "Epoch 29: lr: 9.999999747378752e-05\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0017 - custom_f1: 0.9912 - val_loss: 0.1881 - val_custom_f1: 0.9783\n",
            "Epoch 30: lr: 9.999999747378752e-05\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0019 - custom_f1: 0.9912 - val_loss: 0.2531 - val_custom_f1: 0.8939\n",
            "Epoch 31: lr: 9.999999747378752e-05\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0022 - custom_f1: 0.9646 - val_loss: 0.2669 - val_custom_f1: 0.9173\n",
            "Epoch 32: lr: 9.999999747378752e-05\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 8.4211e-04 - custom_f1: 0.9912 - val_loss: 0.1922 - val_custom_f1: 0.9681\n",
            "Epoch 33: lr: 9.999999747378752e-05\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0017 - custom_f1: 0.9646 - val_loss: 0.2198 - val_custom_f1: 0.9583\n",
            "Epoch 34: lr: 9.999999747378752e-05\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.1038e-04 - custom_f1: 1.0000 - val_loss: 0.2320 - val_custom_f1: 0.9583\n",
            "Epoch 35: lr: 9.999999747378752e-05\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.6721e-04 - custom_f1: 0.9912 - val_loss: 0.2256 - val_custom_f1: 0.9583\n",
            "Epoch 36: lr: 9.999999747378752e-05\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.2126e-04 - custom_f1: 0.9735 - val_loss: 0.2154 - val_custom_f1: 0.9583\n",
            "Epoch 37: lr: 9.999999747378752e-05\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.8146e-04 - custom_f1: 0.9823 - val_loss: 0.2203 - val_custom_f1: 0.9583\n",
            "Epoch 38: lr: 9.999999747378752e-05\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.8059e-04 - custom_f1: 1.0000 - val_loss: 0.2244 - val_custom_f1: 0.9583\n",
            "Epoch 39: lr: 9.999999747378752e-05\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.6077e-04 - custom_f1: 0.9823 - val_loss: 0.2306 - val_custom_f1: 0.9583\n",
            "Epoch 40: lr: 9.999999747378752e-05\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.7819e-04 - custom_f1: 0.9912 - val_loss: 0.2284 - val_custom_f1: 0.9583\n",
            "Epoch 41: lr: 9.999999747378752e-05\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.5741e-04 - custom_f1: 0.9912 - val_loss: 0.4790 - val_custom_f1: 0.8437\n",
            "Epoch 42: lr: 9.999999747378752e-05\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0018 - custom_f1: 0.9823 - val_loss: 0.1920 - val_custom_f1: 0.9681\n",
            "Epoch 43: lr: 9.999999747378752e-05\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 2.8836e-04 - custom_f1: 1.0000 - val_loss: 0.1774 - val_custom_f1: 0.9583\n",
            "Epoch 44: lr: 9.999999747378752e-05\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.9748e-04 - custom_f1: 0.9912 - val_loss: 0.2397 - val_custom_f1: 0.9296\n",
            "Epoch 45: lr: 9.999999747378752e-05\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.7713e-04 - custom_f1: 0.9823 - val_loss: 0.2097 - val_custom_f1: 0.9583\n",
            "Epoch 46: lr: 9.999999747378752e-05\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.9327e-04 - custom_f1: 0.9823 - val_loss: 0.2054 - val_custom_f1: 0.9583\n",
            "Epoch 47: lr: 9.999999747378752e-05\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.6737e-04 - custom_f1: 0.9912 - val_loss: 0.2173 - val_custom_f1: 0.9583\n",
            "Epoch 48: lr: 9.999999747378752e-05\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.6393e-04 - custom_f1: 0.9823 - val_loss: 0.2096 - val_custom_f1: 0.9583\n",
            "Epoch 49: lr: 9.999999747378752e-05\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.5316e-04 - custom_f1: 0.9735 - val_loss: 0.2052 - val_custom_f1: 0.9583\n",
            "Epoch 50: lr: 9.999999747378752e-05\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 1.6052e-04 - custom_f1: 0.9823 - val_loss: 0.2150 - val_custom_f1: 0.9583\n",
            "Epoch 51: lr: 9.999999747378752e-05\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 7.3894e-05 - custom_f1: 0.9912\n",
            "lr is fixed to 9.999999747378752e-06\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.3894e-05 - custom_f1: 0.9912 - val_loss: 0.2342 - val_custom_f1: 0.9583\n",
            "Epoch 52: lr: 9.999999747378752e-06\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.1374e-04 - custom_f1: 0.9735 - val_loss: 0.2236 - val_custom_f1: 0.9583\n",
            "Epoch 53: lr: 9.999999747378752e-06\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.6527e-04 - custom_f1: 0.9912 - val_loss: 0.2222 - val_custom_f1: 0.9583\n",
            "Epoch 54: lr: 9.999999747378752e-06\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.3432e-05 - custom_f1: 0.9823 - val_loss: 0.2197 - val_custom_f1: 0.9583\n",
            "Epoch 55: lr: 9.999999747378752e-06\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.9090e-05 - custom_f1: 0.9912 - val_loss: 0.2249 - val_custom_f1: 0.9583\n",
            "Epoch 56: lr: 9.999999747378752e-06\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.0641e-04 - custom_f1: 0.9735 - val_loss: 0.2176 - val_custom_f1: 0.9583\n",
            "Epoch 57: lr: 9.999999747378752e-06\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.2616e-04 - custom_f1: 0.9823 - val_loss: 0.2167 - val_custom_f1: 0.9583\n",
            "Epoch 58: lr: 9.999999747378752e-06\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.0299e-04 - custom_f1: 0.9823 - val_loss: 0.2206 - val_custom_f1: 0.9583\n",
            "Epoch 59: lr: 9.999999747378752e-06\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.0938e-05 - custom_f1: 0.9912 - val_loss: 0.2281 - val_custom_f1: 0.9583\n",
            "Epoch 60: lr: 9.999999747378752e-06\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.7582e-05 - custom_f1: 1.0000 - val_loss: 0.2257 - val_custom_f1: 0.9583\n",
            "Epoch 61: lr: 9.999999747378752e-06\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.7281e-05 - custom_f1: 0.9912 - val_loss: 0.2276 - val_custom_f1: 0.9583\n",
            "Epoch 62: lr: 9.999999747378752e-06\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.0517e-05 - custom_f1: 0.9912 - val_loss: 0.2308 - val_custom_f1: 0.9583\n",
            "Epoch 63: lr: 9.999999747378752e-06\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.0923e-04 - custom_f1: 0.9823 - val_loss: 0.2231 - val_custom_f1: 0.9583\n",
            "Epoch 64: lr: 9.999999747378752e-06\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 8.0904e-05 - custom_f1: 0.9823 - val_loss: 0.2271 - val_custom_f1: 0.9583\n",
            "Epoch 65: lr: 9.999999747378752e-06\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 8.4852e-05 - custom_f1: 0.9735 - val_loss: 0.2281 - val_custom_f1: 0.9583\n",
            "Epoch 66: lr: 9.999999747378752e-06\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.9102e-05 - custom_f1: 1.0000 - val_loss: 0.2380 - val_custom_f1: 0.9583\n",
            "Epoch 67: lr: 9.999999747378752e-06\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.1948e-05 - custom_f1: 0.9912 - val_loss: 0.2238 - val_custom_f1: 0.9583\n",
            "Epoch 68: lr: 9.999999747378752e-06\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.1650e-05 - custom_f1: 0.9912 - val_loss: 0.2393 - val_custom_f1: 0.9583\n",
            "Epoch 69: lr: 9.999999747378752e-06\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.0434e-04 - custom_f1: 0.9823 - val_loss: 0.2304 - val_custom_f1: 0.9583\n",
            "Epoch 70: lr: 9.999999747378752e-06\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 8.4299e-05 - custom_f1: 0.9912 - val_loss: 0.2221 - val_custom_f1: 0.9583\n",
            "Epoch 71: lr: 9.999999747378752e-06\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.2922e-05 - custom_f1: 0.9823 - val_loss: 0.2273 - val_custom_f1: 0.9583\n",
            "Epoch 72: lr: 9.999999747378752e-06\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.6894e-05 - custom_f1: 0.9912 - val_loss: 0.2228 - val_custom_f1: 0.9583\n",
            "Epoch 73: lr: 9.999999747378752e-06\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 4.6518e-05 - custom_f1: 1.0000 - val_loss: 0.2376 - val_custom_f1: 0.9583\n",
            "Epoch 74: lr: 9.999999747378752e-06\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.3506e-05 - custom_f1: 1.0000 - val_loss: 0.2483 - val_custom_f1: 0.9411\n",
            "Epoch 75: lr: 9.999999747378752e-06\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.5352e-05 - custom_f1: 0.9823 - val_loss: 0.2309 - val_custom_f1: 0.9583\n",
            "Epoch 76: lr: 9.999999747378752e-06\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.2068e-04 - custom_f1: 0.9558 - val_loss: 0.2179 - val_custom_f1: 0.9583\n",
            "Epoch 77: lr: 9.999999747378752e-06\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.5265e-05 - custom_f1: 0.9823 - val_loss: 0.2297 - val_custom_f1: 0.9583\n",
            "Epoch 78: lr: 9.999999747378752e-06\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.9567e-05 - custom_f1: 0.9912 - val_loss: 0.2281 - val_custom_f1: 0.9583\n",
            "Epoch 79: lr: 9.999999747378752e-06\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 8.3730e-05 - custom_f1: 0.9735 - val_loss: 0.2210 - val_custom_f1: 0.9583\n",
            "Epoch 80: lr: 9.999999747378752e-06\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.0356e-05 - custom_f1: 1.0000 - val_loss: 0.2399 - val_custom_f1: 0.9411\n",
            "Epoch 81: lr: 9.999999747378752e-06\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.8504e-05 - custom_f1: 0.9912 - val_loss: 0.2416 - val_custom_f1: 0.9411\n",
            "Epoch 82: lr: 9.999999747378752e-06\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.0492e-05 - custom_f1: 0.9912 - val_loss: 0.2466 - val_custom_f1: 0.9411\n",
            "Epoch 83: lr: 9.999999747378752e-06\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.5206e-05 - custom_f1: 0.9823 - val_loss: 0.2429 - val_custom_f1: 0.9411\n",
            "Epoch 84: lr: 9.999999747378752e-06\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.2391e-05 - custom_f1: 0.9823 - val_loss: 0.2297 - val_custom_f1: 0.9583\n",
            "Epoch 85: lr: 9.999999747378752e-06\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.8658e-05 - custom_f1: 0.9912 - val_loss: 0.2448 - val_custom_f1: 0.9411\n",
            "Epoch 86: lr: 9.999999747378752e-06\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.8319e-05 - custom_f1: 0.9646 - val_loss: 0.2302 - val_custom_f1: 0.9583\n",
            "Epoch 87: lr: 9.999999747378752e-06\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.4774e-05 - custom_f1: 0.9735 - val_loss: 0.2329 - val_custom_f1: 0.9411\n",
            "Epoch 88: lr: 9.999999747378752e-06\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.3740e-05 - custom_f1: 0.9912 - val_loss: 0.2467 - val_custom_f1: 0.9411\n",
            "Epoch 89: lr: 9.999999747378752e-06\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.1425e-05 - custom_f1: 1.0000 - val_loss: 0.2528 - val_custom_f1: 0.9411\n",
            "Epoch 90: lr: 9.999999747378752e-06\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.0867e-05 - custom_f1: 0.9823 - val_loss: 0.2295 - val_custom_f1: 0.9411\n",
            "Epoch 91: lr: 9.999999747378752e-06\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.8231e-05 - custom_f1: 1.0000 - val_loss: 0.2683 - val_custom_f1: 0.9317\n",
            "Epoch 92: lr: 9.999999747378752e-06\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.9212e-05 - custom_f1: 0.9823 - val_loss: 0.2628 - val_custom_f1: 0.9317\n",
            "Epoch 93: lr: 9.999999747378752e-06\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.8237e-05 - custom_f1: 0.9823 - val_loss: 0.2711 - val_custom_f1: 0.9317\n",
            "Epoch 94: lr: 9.999999747378752e-06\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.0829e-05 - custom_f1: 0.9823 - val_loss: 0.2560 - val_custom_f1: 0.9411\n",
            "Epoch 95: lr: 9.999999747378752e-06\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.9994e-05 - custom_f1: 0.9646 - val_loss: 0.2351 - val_custom_f1: 0.9411\n",
            "Epoch 96: lr: 9.999999747378752e-06\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.7845e-05 - custom_f1: 0.9823 - val_loss: 0.2552 - val_custom_f1: 0.9411\n",
            "Epoch 97: lr: 9.999999747378752e-06\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.5944e-05 - custom_f1: 1.0000 - val_loss: 0.2421 - val_custom_f1: 0.9411\n",
            "Epoch 98: lr: 9.999999747378752e-06\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.6696e-05 - custom_f1: 0.9912 - val_loss: 0.2376 - val_custom_f1: 0.9411\n",
            "Epoch 99: lr: 9.999999747378752e-06\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.6803e-05 - custom_f1: 0.9912 - val_loss: 0.2580 - val_custom_f1: 0.9411\n",
            "Epoch 100: lr: 9.999999747378752e-06\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.0422e-05 - custom_f1: 0.9735 - val_loss: 0.2562 - val_custom_f1: 0.9411\n",
            "weights are setted to best weights (epochs 15)\n",
            "fold 9 [400,450]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.5866 - custom_f1: 0.7729\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 9s 83ms/step - loss: 0.5866 - custom_f1: 0.7729 - val_loss: 42.9991 - val_custom_f1: 0.7844\n",
            "Epoch 2: lr: 9.999999747378752e-05\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.4006 - custom_f1: 0.8608\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 91ms/step - loss: 0.4006 - custom_f1: 0.8608 - val_loss: 25.8579 - val_custom_f1: 0.7844\n",
            "Epoch 3: lr: 9.999999747378752e-05\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.2107 - custom_f1: 0.9190 - val_loss: 30.3573 - val_custom_f1: 0.7844\n",
            "Epoch 4: lr: 9.999999747378752e-05\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.2318 - custom_f1: 0.9196\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 90ms/step - loss: 0.2318 - custom_f1: 0.9196 - val_loss: 24.5653 - val_custom_f1: 0.7844\n",
            "Epoch 5: lr: 9.999999747378752e-05\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.2084 - custom_f1: 0.9188\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 9s 82ms/step - loss: 0.2084 - custom_f1: 0.9188 - val_loss: 5.2023 - val_custom_f1: 0.7844\n",
            "Epoch 6: lr: 9.999999747378752e-05\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1540 - custom_f1: 0.9530\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 89ms/step - loss: 0.1540 - custom_f1: 0.9530 - val_loss: 1.4947 - val_custom_f1: 0.7917\n",
            "Epoch 7: lr: 9.999999747378752e-05\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1670 - custom_f1: 0.9418\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 9s 82ms/step - loss: 0.1670 - custom_f1: 0.9418 - val_loss: 0.3927 - val_custom_f1: 0.8813\n",
            "Epoch 8: lr: 9.999999747378752e-05\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1142 - custom_f1: 0.9635\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 89ms/step - loss: 0.1142 - custom_f1: 0.9635 - val_loss: 0.1966 - val_custom_f1: 0.9161\n",
            "Epoch 9: lr: 9.999999747378752e-05\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1246 - custom_f1: 0.9550 - val_loss: 1.2155 - val_custom_f1: 0.4373\n",
            "Epoch 10: lr: 9.999999747378752e-05\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1108 - custom_f1: 0.9628 - val_loss: 0.6097 - val_custom_f1: 0.8564\n",
            "Epoch 11: lr: 9.999999747378752e-05\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0906 - custom_f1: 0.9713\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 88ms/step - loss: 0.0906 - custom_f1: 0.9713 - val_loss: 0.1776 - val_custom_f1: 0.9672\n",
            "Epoch 12: lr: 9.999999747378752e-05\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1259 - custom_f1: 0.9603 - val_loss: 0.9777 - val_custom_f1: 0.8212\n",
            "Epoch 13: lr: 9.999999747378752e-05\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0918 - custom_f1: 0.9699\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 89ms/step - loss: 0.0918 - custom_f1: 0.9699 - val_loss: 0.1609 - val_custom_f1: 0.9663\n",
            "Epoch 14: lr: 9.999999747378752e-05\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1315 - custom_f1: 0.9595 - val_loss: 0.1811 - val_custom_f1: 0.9248\n",
            "Epoch 15: lr: 9.999999747378752e-05\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0781 - custom_f1: 0.9760 - val_loss: 0.2335 - val_custom_f1: 0.9400\n",
            "Epoch 16: lr: 9.999999747378752e-05\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0768 - custom_f1: 0.9739 - val_loss: 0.7504 - val_custom_f1: 0.8470\n",
            "Epoch 17: lr: 9.999999747378752e-05\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0508 - custom_f1: 0.9863 - val_loss: 0.5824 - val_custom_f1: 0.7138\n",
            "Epoch 18: lr: 9.999999747378752e-05\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0255 - custom_f1: 0.9941 - val_loss: 0.2705 - val_custom_f1: 0.8917\n",
            "Epoch 19: lr: 9.999999747378752e-05\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0266 - custom_f1: 0.9903 - val_loss: 0.4942 - val_custom_f1: 0.8875\n",
            "Epoch 20: lr: 9.999999747378752e-05\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0679 - custom_f1: 0.9834 - val_loss: 1.0672 - val_custom_f1: 0.4904\n",
            "Epoch 21: lr: 9.999999747378752e-05\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0460 - custom_f1: 0.9898 - val_loss: 0.8713 - val_custom_f1: 0.4127\n",
            "Epoch 22: lr: 9.999999747378752e-05\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0385 - custom_f1: 0.9903 - val_loss: 0.3249 - val_custom_f1: 0.8956\n",
            "Epoch 23: lr: 9.999999747378752e-05\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0505 - custom_f1: 0.9886 - val_loss: 0.2003 - val_custom_f1: 0.9595\n",
            "Epoch 24: lr: 9.999999747378752e-05\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0786 - custom_f1: 0.9751 - val_loss: 1.1290 - val_custom_f1: 0.3155\n",
            "Epoch 25: lr: 9.999999747378752e-05\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0579 - custom_f1: 0.9823 - val_loss: 0.2865 - val_custom_f1: 0.8854\n",
            "Epoch 26: lr: 9.999999747378752e-05\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0045 - custom_f1: 1.0000\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 88ms/step - loss: 0.0045 - custom_f1: 1.0000 - val_loss: 0.1522 - val_custom_f1: 0.9615\n",
            "Epoch 27: lr: 9.999999747378752e-05\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0189 - custom_f1: 0.9912 - val_loss: 1.2842 - val_custom_f1: 0.8133\n",
            "Epoch 28: lr: 9.999999747378752e-05\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0435 - custom_f1: 0.9545 - val_loss: 0.1760 - val_custom_f1: 0.9373\n",
            "Epoch 29: lr: 9.999999747378752e-05\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0129 - custom_f1: 0.9746 - val_loss: 0.2925 - val_custom_f1: 0.9026\n",
            "Epoch 30: lr: 9.999999747378752e-05\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0292 - custom_f1: 0.9805 - val_loss: 0.1670 - val_custom_f1: 0.9079\n",
            "Epoch 31: lr: 9.999999747378752e-05\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0518 - custom_f1: 0.9794 - val_loss: 0.3370 - val_custom_f1: 0.9140\n",
            "Epoch 32: lr: 9.999999747378752e-05\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0115 - custom_f1: 0.9735 - val_loss: 0.2109 - val_custom_f1: 0.9132\n",
            "Epoch 33: lr: 9.999999747378752e-05\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0037 - custom_f1: 0.9912\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 89ms/step - loss: 0.0037 - custom_f1: 0.9912 - val_loss: 0.1304 - val_custom_f1: 0.9672\n",
            "Epoch 34: lr: 9.999999747378752e-05\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0024 - custom_f1: 0.9912 - val_loss: 0.2097 - val_custom_f1: 0.9237\n",
            "Epoch 35: lr: 9.999999747378752e-05\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0010 - custom_f1: 1.0000 - val_loss: 0.1831 - val_custom_f1: 0.9365\n",
            "Epoch 36: lr: 9.999999747378752e-05\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0053 - custom_f1: 0.9823 - val_loss: 0.2738 - val_custom_f1: 0.8803\n",
            "Epoch 37: lr: 9.999999747378752e-05\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0023 - custom_f1: 0.9912 - val_loss: 0.2546 - val_custom_f1: 0.9002\n",
            "Epoch 38: lr: 9.999999747378752e-05\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.8974e-04 - custom_f1: 0.9912 - val_loss: 0.2344 - val_custom_f1: 0.9002\n",
            "Epoch 39: lr: 9.999999747378752e-05\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.4412e-04 - custom_f1: 0.9912 - val_loss: 0.2388 - val_custom_f1: 0.8893\n",
            "Epoch 40: lr: 9.999999747378752e-05\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.8761e-04 - custom_f1: 0.9912 - val_loss: 0.2185 - val_custom_f1: 0.9002\n",
            "Epoch 41: lr: 9.999999747378752e-05\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.2597e-04 - custom_f1: 0.9912 - val_loss: 0.1941 - val_custom_f1: 0.9002\n",
            "Epoch 42: lr: 9.999999747378752e-05\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.4187e-04 - custom_f1: 0.9735 - val_loss: 0.1818 - val_custom_f1: 0.9409\n",
            "Epoch 43: lr: 9.999999747378752e-05\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.9010e-04 - custom_f1: 1.0000 - val_loss: 0.1906 - val_custom_f1: 0.9174\n",
            "Epoch 44: lr: 9.999999747378752e-05\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.0172e-04 - custom_f1: 1.0000 - val_loss: 0.1972 - val_custom_f1: 0.9078\n",
            "Epoch 45: lr: 9.999999747378752e-05\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0014 - custom_f1: 0.9823 - val_loss: 0.1901 - val_custom_f1: 0.9360\n",
            "Epoch 46: lr: 9.999999747378752e-05\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.0738e-04 - custom_f1: 1.0000 - val_loss: 0.2177 - val_custom_f1: 0.9301\n",
            "Epoch 47: lr: 9.999999747378752e-05\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.0247e-04 - custom_f1: 0.9912 - val_loss: 0.3424 - val_custom_f1: 0.9078\n",
            "Epoch 48: lr: 9.999999747378752e-05\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.3822e-04 - custom_f1: 0.9823 - val_loss: 0.2482 - val_custom_f1: 0.9187\n",
            "Epoch 49: lr: 9.999999747378752e-05\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 3.6336e-04 - custom_f1: 0.9823 - val_loss: 0.2284 - val_custom_f1: 0.9187\n",
            "Epoch 50: lr: 9.999999747378752e-05\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.4830e-04 - custom_f1: 0.9912 - val_loss: 0.2046 - val_custom_f1: 0.9301\n",
            "Epoch 51: lr: 9.999999747378752e-05\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 1.7810e-04 - custom_f1: 0.9912\n",
            "lr is fixed to 9.999999747378752e-06\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.7810e-04 - custom_f1: 0.9912 - val_loss: 0.1982 - val_custom_f1: 0.9187\n",
            "Epoch 52: lr: 9.999999747378752e-06\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.3597e-04 - custom_f1: 0.9912 - val_loss: 0.2023 - val_custom_f1: 0.9187\n",
            "Epoch 53: lr: 9.999999747378752e-06\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.1544e-04 - custom_f1: 1.0000 - val_loss: 0.1990 - val_custom_f1: 0.9187\n",
            "Epoch 54: lr: 9.999999747378752e-06\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.6033e-04 - custom_f1: 0.9912 - val_loss: 0.1981 - val_custom_f1: 0.9187\n",
            "Epoch 55: lr: 9.999999747378752e-06\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.7107e-04 - custom_f1: 0.9912 - val_loss: 0.2000 - val_custom_f1: 0.9187\n",
            "Epoch 56: lr: 9.999999747378752e-06\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.8498e-04 - custom_f1: 0.9912 - val_loss: 0.2000 - val_custom_f1: 0.9187\n",
            "Epoch 57: lr: 9.999999747378752e-06\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.6306e-05 - custom_f1: 1.0000 - val_loss: 0.2030 - val_custom_f1: 0.9187\n",
            "Epoch 58: lr: 9.999999747378752e-06\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.2800e-04 - custom_f1: 0.9823 - val_loss: 0.2072 - val_custom_f1: 0.9187\n",
            "Epoch 59: lr: 9.999999747378752e-06\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.2817e-04 - custom_f1: 0.9823 - val_loss: 0.2002 - val_custom_f1: 0.9187\n",
            "Epoch 60: lr: 9.999999747378752e-06\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.4653e-04 - custom_f1: 0.9735 - val_loss: 0.2127 - val_custom_f1: 0.9187\n",
            "Epoch 61: lr: 9.999999747378752e-06\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.0410e-04 - custom_f1: 1.0000 - val_loss: 0.2142 - val_custom_f1: 0.9187\n",
            "Epoch 62: lr: 9.999999747378752e-06\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.9142e-04 - custom_f1: 0.9558 - val_loss: 0.1763 - val_custom_f1: 0.9474\n",
            "Epoch 63: lr: 9.999999747378752e-06\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.4536e-04 - custom_f1: 0.9823 - val_loss: 0.1794 - val_custom_f1: 0.9474\n",
            "Epoch 64: lr: 9.999999747378752e-06\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.5345e-04 - custom_f1: 0.9823 - val_loss: 0.1820 - val_custom_f1: 0.9474\n",
            "Epoch 65: lr: 9.999999747378752e-06\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.8402e-05 - custom_f1: 1.0000 - val_loss: 0.1935 - val_custom_f1: 0.9359\n",
            "Epoch 66: lr: 9.999999747378752e-06\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.2510e-04 - custom_f1: 0.9912 - val_loss: 0.2063 - val_custom_f1: 0.9187\n",
            "Epoch 67: lr: 9.999999747378752e-06\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.0892e-04 - custom_f1: 0.9912 - val_loss: 0.2067 - val_custom_f1: 0.9187\n",
            "Epoch 68: lr: 9.999999747378752e-06\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.2311e-04 - custom_f1: 0.9823 - val_loss: 0.2055 - val_custom_f1: 0.9187\n",
            "Epoch 69: lr: 9.999999747378752e-06\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.1079e-04 - custom_f1: 0.9912 - val_loss: 0.2113 - val_custom_f1: 0.9187\n",
            "Epoch 70: lr: 9.999999747378752e-06\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 2.5023e-04 - custom_f1: 0.9646 - val_loss: 0.2055 - val_custom_f1: 0.9187\n",
            "Epoch 71: lr: 9.999999747378752e-06\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.2560e-04 - custom_f1: 0.9735 - val_loss: 0.2033 - val_custom_f1: 0.9187\n",
            "Epoch 72: lr: 9.999999747378752e-06\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.2653e-05 - custom_f1: 0.9912 - val_loss: 0.2095 - val_custom_f1: 0.9187\n",
            "Epoch 73: lr: 9.999999747378752e-06\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.3960e-04 - custom_f1: 0.9823 - val_loss: 0.2070 - val_custom_f1: 0.9187\n",
            "Epoch 74: lr: 9.999999747378752e-06\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.2946e-04 - custom_f1: 0.9735 - val_loss: 0.2162 - val_custom_f1: 0.9187\n",
            "Epoch 75: lr: 9.999999747378752e-06\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.7565e-04 - custom_f1: 0.9735 - val_loss: 0.2202 - val_custom_f1: 0.9187\n",
            "Epoch 76: lr: 9.999999747378752e-06\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 8.9639e-05 - custom_f1: 0.9823 - val_loss: 0.2182 - val_custom_f1: 0.9187\n",
            "Epoch 77: lr: 9.999999747378752e-06\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.6159e-05 - custom_f1: 0.9823 - val_loss: 0.2318 - val_custom_f1: 0.9187\n",
            "Epoch 78: lr: 9.999999747378752e-06\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.0668e-04 - custom_f1: 0.9912 - val_loss: 0.2194 - val_custom_f1: 0.9187\n",
            "Epoch 79: lr: 9.999999747378752e-06\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.8079e-05 - custom_f1: 0.9823 - val_loss: 0.2137 - val_custom_f1: 0.9187\n",
            "Epoch 80: lr: 9.999999747378752e-06\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.2727e-04 - custom_f1: 0.9735 - val_loss: 0.2000 - val_custom_f1: 0.9187\n",
            "Epoch 81: lr: 9.999999747378752e-06\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.7033e-05 - custom_f1: 0.9823 - val_loss: 0.1934 - val_custom_f1: 0.9187\n",
            "Epoch 82: lr: 9.999999747378752e-06\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.4183e-05 - custom_f1: 1.0000 - val_loss: 0.2045 - val_custom_f1: 0.9187\n",
            "Epoch 83: lr: 9.999999747378752e-06\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.2439e-05 - custom_f1: 1.0000 - val_loss: 0.2311 - val_custom_f1: 0.9187\n",
            "Epoch 84: lr: 9.999999747378752e-06\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 6.9913e-05 - custom_f1: 0.9912 - val_loss: 0.2100 - val_custom_f1: 0.9187\n",
            "Epoch 85: lr: 9.999999747378752e-06\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.9301e-04 - custom_f1: 0.9912 - val_loss: 0.1737 - val_custom_f1: 0.9359\n",
            "Epoch 86: lr: 9.999999747378752e-06\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.7134e-05 - custom_f1: 0.9823 - val_loss: 0.2018 - val_custom_f1: 0.9187\n",
            "Epoch 87: lr: 9.999999747378752e-06\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.0974e-05 - custom_f1: 0.9735 - val_loss: 0.2130 - val_custom_f1: 0.9078\n",
            "Epoch 88: lr: 9.999999747378752e-06\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 8.1460e-05 - custom_f1: 0.9823 - val_loss: 0.2118 - val_custom_f1: 0.9078\n",
            "Epoch 89: lr: 9.999999747378752e-06\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.1427e-05 - custom_f1: 1.0000 - val_loss: 0.2263 - val_custom_f1: 0.9078\n",
            "Epoch 90: lr: 9.999999747378752e-06\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 8.5005e-05 - custom_f1: 0.9823 - val_loss: 0.2257 - val_custom_f1: 0.9078\n",
            "Epoch 91: lr: 9.999999747378752e-06\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.7105e-05 - custom_f1: 0.9823 - val_loss: 0.2125 - val_custom_f1: 0.9250\n",
            "Epoch 92: lr: 9.999999747378752e-06\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.6292e-05 - custom_f1: 1.0000 - val_loss: 0.2385 - val_custom_f1: 0.9078\n",
            "Epoch 93: lr: 9.999999747378752e-06\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.4919e-05 - custom_f1: 0.9823 - val_loss: 0.2438 - val_custom_f1: 0.9078\n",
            "Epoch 94: lr: 9.999999747378752e-06\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 9.5434e-05 - custom_f1: 0.9823 - val_loss: 0.2126 - val_custom_f1: 0.9250\n",
            "Epoch 95: lr: 9.999999747378752e-06\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.0413e-05 - custom_f1: 1.0000 - val_loss: 0.2259 - val_custom_f1: 0.9250\n",
            "Epoch 96: lr: 9.999999747378752e-06\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.9656e-05 - custom_f1: 0.9912 - val_loss: 0.2324 - val_custom_f1: 0.9250\n",
            "Epoch 97: lr: 9.999999747378752e-06\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 3.9993e-05 - custom_f1: 1.0000 - val_loss: 0.2428 - val_custom_f1: 0.9078\n",
            "Epoch 98: lr: 9.999999747378752e-06\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.9787e-05 - custom_f1: 0.9823 - val_loss: 0.2168 - val_custom_f1: 0.9250\n",
            "Epoch 99: lr: 9.999999747378752e-06\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.2080e-05 - custom_f1: 0.9823 - val_loss: 0.2066 - val_custom_f1: 0.9359\n",
            "Epoch 100: lr: 9.999999747378752e-06\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.6287e-05 - custom_f1: 0.9823 - val_loss: 0.2212 - val_custom_f1: 0.9250\n",
            "weights are setted to best weights (epochs 33)\n",
            "fold 10 [450,500]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.5799 - custom_f1: 0.7897\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 9s 84ms/step - loss: 0.5799 - custom_f1: 0.7897 - val_loss: 7.2420 - val_custom_f1: 0.8479\n",
            "Epoch 2: lr: 9.999999747378752e-05\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.3549 - custom_f1: 0.8822\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 89ms/step - loss: 0.3549 - custom_f1: 0.8822 - val_loss: 2.5908 - val_custom_f1: 0.8479\n",
            "Epoch 3: lr: 9.999999747378752e-05\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.3178 - custom_f1: 0.8854 - val_loss: 15.4293 - val_custom_f1: 0.8479\n",
            "Epoch 4: lr: 9.999999747378752e-05\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.2341 - custom_f1: 0.9206 - val_loss: 13.6981 - val_custom_f1: 0.8479\n",
            "Epoch 5: lr: 9.999999747378752e-05\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.2568 - custom_f1: 0.9129 - val_loss: 6.7420 - val_custom_f1: 0.8479\n",
            "Epoch 6: lr: 9.999999747378752e-05\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1691 - custom_f1: 0.9480\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 88ms/step - loss: 0.1691 - custom_f1: 0.9480 - val_loss: 1.3382 - val_custom_f1: 0.8697\n",
            "Epoch 7: lr: 9.999999747378752e-05\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1529 - custom_f1: 0.9481\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 9s 82ms/step - loss: 0.1529 - custom_f1: 0.9481 - val_loss: 0.5306 - val_custom_f1: 0.9325\n",
            "Epoch 8: lr: 9.999999747378752e-05\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1130 - custom_f1: 0.9668 - val_loss: 1.1463 - val_custom_f1: 0.5833\n",
            "Epoch 9: lr: 9.999999747378752e-05\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0717 - custom_f1: 0.9843 - val_loss: 0.6711 - val_custom_f1: 0.9325\n",
            "Epoch 10: lr: 9.999999747378752e-05\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0578 - custom_f1: 0.9817\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 88ms/step - loss: 0.0578 - custom_f1: 0.9817 - val_loss: 0.4347 - val_custom_f1: 0.9400\n",
            "Epoch 11: lr: 9.999999747378752e-05\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0867 - custom_f1: 0.9699 - val_loss: 0.5107 - val_custom_f1: 0.8982\n",
            "Epoch 12: lr: 9.999999747378752e-05\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0672 - custom_f1: 0.9797 - val_loss: 0.6748 - val_custom_f1: 0.7500\n",
            "Epoch 13: lr: 9.999999747378752e-05\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0392 - custom_f1: 0.9915 - val_loss: 0.5640 - val_custom_f1: 0.9215\n",
            "Epoch 14: lr: 9.999999747378752e-05\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0992 - custom_f1: 0.9654 - val_loss: 1.5312 - val_custom_f1: 0.9087\n",
            "Epoch 15: lr: 9.999999747378752e-05\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1387 - custom_f1: 0.9370 - val_loss: 1.3752 - val_custom_f1: 0.4653\n",
            "Epoch 16: lr: 9.999999747378752e-05\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0602 - custom_f1: 0.9809 - val_loss: 0.5348 - val_custom_f1: 0.8696\n",
            "Epoch 17: lr: 9.999999747378752e-05\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0869 - custom_f1: 0.9670 - val_loss: 0.7486 - val_custom_f1: 0.8157\n",
            "Epoch 18: lr: 9.999999747378752e-05\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0524 - custom_f1: 0.9850 - val_loss: 0.5480 - val_custom_f1: 0.9167\n",
            "Epoch 19: lr: 9.999999747378752e-05\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0482 - custom_f1: 0.9810 - val_loss: 0.5565 - val_custom_f1: 0.9528\n",
            "Epoch 20: lr: 9.999999747378752e-05\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1044 - custom_f1: 0.9624 - val_loss: 0.5115 - val_custom_f1: 0.8478\n",
            "Epoch 21: lr: 9.999999747378752e-05\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0452 - custom_f1: 0.9827 - val_loss: 0.5076 - val_custom_f1: 0.8838\n",
            "Epoch 22: lr: 9.999999747378752e-05\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0460 - custom_f1: 0.9780 - val_loss: 0.4743 - val_custom_f1: 0.8696\n",
            "Epoch 23: lr: 9.999999747378752e-05\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0204 - custom_f1: 0.9823 - val_loss: 0.6164 - val_custom_f1: 0.9087\n",
            "Epoch 24: lr: 9.999999747378752e-05\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0477 - custom_f1: 0.9751 - val_loss: 0.4372 - val_custom_f1: 0.9430\n",
            "Epoch 25: lr: 9.999999747378752e-05\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0296 - custom_f1: 0.9810 - val_loss: 0.4767 - val_custom_f1: 0.8439\n",
            "Epoch 26: lr: 9.999999747378752e-05\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0238 - custom_f1: 0.9882 - val_loss: 0.6816 - val_custom_f1: 0.8135\n",
            "Epoch 27: lr: 9.999999747378752e-05\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0095 - custom_f1: 0.9912 - val_loss: 1.4052 - val_custom_f1: 0.5511\n",
            "Epoch 28: lr: 9.999999747378752e-05\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0114 - custom_f1: 0.9735 - val_loss: 0.8524 - val_custom_f1: 0.5936\n",
            "Epoch 29: lr: 9.999999747378752e-05\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0179 - custom_f1: 0.9882 - val_loss: 0.6525 - val_custom_f1: 0.9153\n",
            "Epoch 30: lr: 9.999999747378752e-05\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0102 - custom_f1: 0.9646 - val_loss: 2.6725 - val_custom_f1: 0.1718\n",
            "Epoch 31: lr: 9.999999747378752e-05\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0059 - custom_f1: 1.0000 - val_loss: 0.5004 - val_custom_f1: 0.8723\n",
            "Epoch 32: lr: 9.999999747378752e-05\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0079 - custom_f1: 0.9823 - val_loss: 0.7518 - val_custom_f1: 0.7000\n",
            "Epoch 33: lr: 9.999999747378752e-05\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0068 - custom_f1: 0.9882\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 90ms/step - loss: 0.0068 - custom_f1: 0.9882 - val_loss: 0.4031 - val_custom_f1: 0.9167\n",
            "Epoch 34: lr: 9.999999747378752e-05\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0049 - custom_f1: 0.9912 - val_loss: 0.4569 - val_custom_f1: 0.9167\n",
            "Epoch 35: lr: 9.999999747378752e-05\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0023 - custom_f1: 0.9912 - val_loss: 0.4753 - val_custom_f1: 0.9051\n",
            "Epoch 36: lr: 9.999999747378752e-05\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0010 - custom_f1: 0.9912 - val_loss: 0.4095 - val_custom_f1: 0.9290\n",
            "Epoch 37: lr: 9.999999747378752e-05\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 8.1201e-04 - custom_f1: 0.9912 - val_loss: 0.4066 - val_custom_f1: 0.9105\n",
            "Epoch 38: lr: 9.999999747378752e-05\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0099 - custom_f1: 0.9735 - val_loss: 0.5558 - val_custom_f1: 0.9583\n",
            "Epoch 39: lr: 9.999999747378752e-05\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0365 - custom_f1: 0.9933 - val_loss: 1.7328 - val_custom_f1: 0.8697\n",
            "Epoch 40: lr: 9.999999747378752e-05\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0143 - custom_f1: 0.9899 - val_loss: 0.5166 - val_custom_f1: 0.8313\n",
            "Epoch 41: lr: 9.999999747378752e-05\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0349 - custom_f1: 0.9717\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 89ms/step - loss: 0.0349 - custom_f1: 0.9717 - val_loss: 0.3110 - val_custom_f1: 0.9415\n",
            "Epoch 42: lr: 9.999999747378752e-05\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0172 - custom_f1: 0.9952 - val_loss: 0.6871 - val_custom_f1: 0.9258\n",
            "Epoch 43: lr: 9.999999747378752e-05\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0117 - custom_f1: 0.9617\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 10s 88ms/step - loss: 0.0117 - custom_f1: 0.9617 - val_loss: 0.3013 - val_custom_f1: 0.9600\n",
            "Epoch 44: lr: 9.999999747378752e-05\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0828 - custom_f1: 0.9767 - val_loss: 0.7174 - val_custom_f1: 0.7749\n",
            "Epoch 45: lr: 9.999999747378752e-05\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.1476 - custom_f1: 0.9358 - val_loss: 0.4178 - val_custom_f1: 0.9343\n",
            "Epoch 46: lr: 9.999999747378752e-05\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0304 - custom_f1: 0.9593 - val_loss: 0.7739 - val_custom_f1: 0.7310\n",
            "Epoch 47: lr: 9.999999747378752e-05\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0038 - custom_f1: 0.9823 - val_loss: 0.5673 - val_custom_f1: 0.8696\n",
            "Epoch 48: lr: 9.999999747378752e-05\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0253 - custom_f1: 0.9805 - val_loss: 0.3651 - val_custom_f1: 0.9400\n",
            "Epoch 49: lr: 9.999999747378752e-05\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0064 - custom_f1: 0.9735 - val_loss: 0.3445 - val_custom_f1: 0.9167\n",
            "Epoch 50: lr: 9.999999747378752e-05\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0091 - custom_f1: 0.9912 - val_loss: 0.4325 - val_custom_f1: 0.8948\n",
            "Epoch 51: lr: 9.999999747378752e-05\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0221 - custom_f1: 0.9909\n",
            "lr is fixed to 9.999999747378752e-06\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0221 - custom_f1: 0.9909 - val_loss: 0.8052 - val_custom_f1: 0.8846\n",
            "Epoch 52: lr: 9.999999747378752e-06\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0433 - custom_f1: 0.9798 - val_loss: 0.4490 - val_custom_f1: 0.9321\n",
            "Epoch 53: lr: 9.999999747378752e-06\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0277 - custom_f1: 0.9781 - val_loss: 0.4229 - val_custom_f1: 0.9506\n",
            "Epoch 54: lr: 9.999999747378752e-06\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0145 - custom_f1: 0.9823 - val_loss: 0.4129 - val_custom_f1: 0.9289\n",
            "Epoch 55: lr: 9.999999747378752e-06\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0105 - custom_f1: 0.9823 - val_loss: 0.4185 - val_custom_f1: 0.9506\n",
            "Epoch 56: lr: 9.999999747378752e-06\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0078 - custom_f1: 0.9735 - val_loss: 0.4170 - val_custom_f1: 0.9289\n",
            "Epoch 57: lr: 9.999999747378752e-06\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0046 - custom_f1: 0.9735 - val_loss: 0.4151 - val_custom_f1: 0.9289\n",
            "Epoch 58: lr: 9.999999747378752e-06\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.0022 - custom_f1: 1.0000 - val_loss: 0.4202 - val_custom_f1: 0.9506\n",
            "Epoch 59: lr: 9.999999747378752e-06\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0051 - custom_f1: 0.9912 - val_loss: 0.4099 - val_custom_f1: 0.9506\n",
            "Epoch 60: lr: 9.999999747378752e-06\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0015 - custom_f1: 1.0000 - val_loss: 0.4128 - val_custom_f1: 0.9506\n",
            "Epoch 61: lr: 9.999999747378752e-06\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0014 - custom_f1: 1.0000 - val_loss: 0.4202 - val_custom_f1: 0.9506\n",
            "Epoch 62: lr: 9.999999747378752e-06\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0013 - custom_f1: 1.0000 - val_loss: 0.4200 - val_custom_f1: 0.9506\n",
            "Epoch 63: lr: 9.999999747378752e-06\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0044 - custom_f1: 0.9735 - val_loss: 0.4048 - val_custom_f1: 0.9383\n",
            "Epoch 64: lr: 9.999999747378752e-06\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0017 - custom_f1: 0.9912 - val_loss: 0.4049 - val_custom_f1: 0.9506\n",
            "Epoch 65: lr: 9.999999747378752e-06\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0015 - custom_f1: 0.9912 - val_loss: 0.4057 - val_custom_f1: 0.9506\n",
            "Epoch 66: lr: 9.999999747378752e-06\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0013 - custom_f1: 0.9912 - val_loss: 0.4061 - val_custom_f1: 0.9506\n",
            "Epoch 67: lr: 9.999999747378752e-06\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0014 - custom_f1: 0.9823 - val_loss: 0.4015 - val_custom_f1: 0.9506\n",
            "Epoch 68: lr: 9.999999747378752e-06\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0015 - custom_f1: 0.9735 - val_loss: 0.4006 - val_custom_f1: 0.9506\n",
            "Epoch 69: lr: 9.999999747378752e-06\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0012 - custom_f1: 0.9912 - val_loss: 0.4001 - val_custom_f1: 0.9506\n",
            "Epoch 70: lr: 9.999999747378752e-06\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.3387e-04 - custom_f1: 0.9912 - val_loss: 0.3976 - val_custom_f1: 0.9506\n",
            "Epoch 71: lr: 9.999999747378752e-06\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 0.0016 - custom_f1: 0.9558 - val_loss: 0.3903 - val_custom_f1: 0.9506\n",
            "Epoch 72: lr: 9.999999747378752e-06\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 9.2990e-04 - custom_f1: 0.9735 - val_loss: 0.3903 - val_custom_f1: 0.9506\n",
            "Epoch 73: lr: 9.999999747378752e-06\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.2911e-04 - custom_f1: 0.9912 - val_loss: 0.3934 - val_custom_f1: 0.9506\n",
            "Epoch 74: lr: 9.999999747378752e-06\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.0786e-04 - custom_f1: 0.9912 - val_loss: 0.3913 - val_custom_f1: 0.9506\n",
            "Epoch 75: lr: 9.999999747378752e-06\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.2762e-04 - custom_f1: 0.9912 - val_loss: 0.3919 - val_custom_f1: 0.9506\n",
            "Epoch 76: lr: 9.999999747378752e-06\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 8.7632e-04 - custom_f1: 0.9735 - val_loss: 0.3861 - val_custom_f1: 0.9506\n",
            "Epoch 77: lr: 9.999999747378752e-06\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 5.2332e-04 - custom_f1: 0.9912 - val_loss: 0.3871 - val_custom_f1: 0.9506\n",
            "Epoch 78: lr: 9.999999747378752e-06\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.4067e-04 - custom_f1: 1.0000 - val_loss: 0.3863 - val_custom_f1: 0.9506\n",
            "Epoch 79: lr: 9.999999747378752e-06\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 6.0070e-04 - custom_f1: 0.9912 - val_loss: 0.3838 - val_custom_f1: 0.9506\n",
            "Epoch 80: lr: 9.999999747378752e-06\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 4.8010e-04 - custom_f1: 0.9735 - val_loss: 0.3814 - val_custom_f1: 0.9506\n",
            "Epoch 81: lr: 9.999999747378752e-06\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 8.4847e-04 - custom_f1: 0.9646 - val_loss: 0.3805 - val_custom_f1: 0.9506\n",
            "Epoch 82: lr: 9.999999747378752e-06\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 3.8148e-04 - custom_f1: 0.9912 - val_loss: 0.3835 - val_custom_f1: 0.9506\n",
            "Epoch 83: lr: 9.999999747378752e-06\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.1653e-04 - custom_f1: 0.9912 - val_loss: 0.3847 - val_custom_f1: 0.9506\n",
            "Epoch 84: lr: 9.999999747378752e-06\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.5122e-04 - custom_f1: 0.9912 - val_loss: 0.3815 - val_custom_f1: 0.9506\n",
            "Epoch 85: lr: 9.999999747378752e-06\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 5.3902e-04 - custom_f1: 0.9823 - val_loss: 0.3796 - val_custom_f1: 0.9506\n",
            "Epoch 86: lr: 9.999999747378752e-06\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 3.8455e-04 - custom_f1: 0.9912 - val_loss: 0.3817 - val_custom_f1: 0.9506\n",
            "Epoch 87: lr: 9.999999747378752e-06\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 7.7388e-04 - custom_f1: 0.9469 - val_loss: 0.3746 - val_custom_f1: 0.9506\n",
            "Epoch 88: lr: 9.999999747378752e-06\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 3.7909e-04 - custom_f1: 0.9823 - val_loss: 0.3794 - val_custom_f1: 0.9506\n",
            "Epoch 89: lr: 9.999999747378752e-06\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 3.2221e-04 - custom_f1: 0.9912 - val_loss: 0.3871 - val_custom_f1: 0.9506\n",
            "Epoch 90: lr: 9.999999747378752e-06\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.7257e-04 - custom_f1: 0.9912 - val_loss: 0.3871 - val_custom_f1: 0.9506\n",
            "Epoch 91: lr: 9.999999747378752e-06\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.2304e-04 - custom_f1: 1.0000 - val_loss: 0.3901 - val_custom_f1: 0.9506\n",
            "Epoch 92: lr: 9.999999747378752e-06\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 3.2758e-04 - custom_f1: 0.9823 - val_loss: 0.3866 - val_custom_f1: 0.9506\n",
            "Epoch 93: lr: 9.999999747378752e-06\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.4764e-04 - custom_f1: 0.9912 - val_loss: 0.3891 - val_custom_f1: 0.9506\n",
            "Epoch 94: lr: 9.999999747378752e-06\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.7642e-04 - custom_f1: 1.0000 - val_loss: 0.3984 - val_custom_f1: 0.9506\n",
            "Epoch 95: lr: 9.999999747378752e-06\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.1946e-04 - custom_f1: 0.9912 - val_loss: 0.3927 - val_custom_f1: 0.9506\n",
            "Epoch 96: lr: 9.999999747378752e-06\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 4.5122e-04 - custom_f1: 0.9646 - val_loss: 0.3844 - val_custom_f1: 0.9506\n",
            "Epoch 97: lr: 9.999999747378752e-06\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.8485e-04 - custom_f1: 1.0000 - val_loss: 0.3883 - val_custom_f1: 0.9506\n",
            "Epoch 98: lr: 9.999999747378752e-06\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.0029e-04 - custom_f1: 1.0000 - val_loss: 0.3875 - val_custom_f1: 0.9506\n",
            "Epoch 99: lr: 9.999999747378752e-06\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 1.9720e-04 - custom_f1: 0.9912 - val_loss: 0.3919 - val_custom_f1: 0.9506\n",
            "Epoch 100: lr: 9.999999747378752e-06\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 9s 77ms/step - loss: 2.3998e-04 - custom_f1: 0.9823 - val_loss: 0.3904 - val_custom_f1: 0.9506\n",
            "weights are setted to best weights (epochs 43)\n",
            "######################\n",
            "##                  ##\n",
            "##    Test STEP     ##\n",
            "##                  ##\n",
            "######################\n",
            "Fold 1/10\n",
            "4/4 [==============================] - 2s 374ms/step\n",
            "Fold 2/10\n",
            "4/4 [==============================] - 0s 135ms/step\n",
            "Fold 3/10\n",
            "4/4 [==============================] - 0s 135ms/step\n",
            "Fold 4/10\n",
            "4/4 [==============================] - 0s 134ms/step\n",
            "Fold 5/10\n",
            "4/4 [==============================] - 0s 134ms/step\n",
            "Fold 6/10\n",
            "4/4 [==============================] - 0s 134ms/step\n",
            "Fold 7/10\n",
            "4/4 [==============================] - 0s 135ms/step\n",
            "Fold 8/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e1e2d3f82001>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'##                  ##'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'######################'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mtesting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-48f3037a311c>\u001b[0m in \u001b[0;36mtesting\u001b[0;34m(data, model, fold, thr, save)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_5/model_4/pool1_pad/Pad' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n      handler_func(fileobj, events)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-8-e1e2d3f82001>\", line 45, in <module>\n      testing(data, model, thr = 0.5, save=save)\n    File \"<ipython-input-4-48f3037a311c>\", line 94, in testing\n      pred = model.predict(data.test_X,verbose=1)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1982, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1801, in predict_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1790, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step\n      outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\n      return self(x, training=False)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 452, in call\n      inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 452, in call\n      inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py\", line 3236, in call\n      inputs, padding=self.padding, data_format=self.data_format)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 3761, in spatial_2d_padding\n      return tf.compat.v1.pad(x, pattern)\nNode: 'model_5/model_4/pool1_pad/Pad'\nOOM when allocating tensor with shape[2048,258,258] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_5/model_4/pool1_pad/Pad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_1384900]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trainning step\n",
        "print('######################')\n",
        "print('##                  ##')\n",
        "print('##    Test STEP     ##')\n",
        "print('##                  ##')\n",
        "print('######################')\n",
        "testing(data, model, thr = 0.5, save=save)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-axZN4xKEuOC",
        "outputId": "ad81e7c4-acd3-4185-efb9-a9f6135b3c2b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######################\n",
            "##                  ##\n",
            "##    Test STEP     ##\n",
            "##                  ##\n",
            "######################\n",
            "Fold 1/10\n",
            "4/4 [==============================] - 0s 136ms/step\n",
            "Fold 2/10\n",
            "4/4 [==============================] - 0s 135ms/step\n",
            "Fold 3/10\n",
            "4/4 [==============================] - 0s 134ms/step\n",
            "Fold 4/10\n",
            "4/4 [==============================] - 0s 134ms/step\n",
            "Fold 5/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-229b3c052900>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'##                  ##'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'######################'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtesting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-48f3037a311c>\u001b[0m in \u001b[0;36mtesting\u001b[0;34m(data, model, fold, thr, save)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_5/model_4/pool1_pad/Pad' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n      handler_func(fileobj, events)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-8-e1e2d3f82001>\", line 45, in <module>\n      testing(data, model, thr = 0.5, save=save)\n    File \"<ipython-input-4-48f3037a311c>\", line 94, in testing\n      pred = model.predict(data.test_X,verbose=1)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1982, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1801, in predict_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1790, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step\n      outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\n      return self(x, training=False)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 452, in call\n      inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 452, in call\n      inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py\", line 3236, in call\n      inputs, padding=self.padding, data_format=self.data_format)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 3761, in spatial_2d_padding\n      return tf.compat.v1.pad(x, pattern)\nNode: 'model_5/model_4/pool1_pad/Pad'\nOOM when allocating tensor with shape[2048,258,258] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_5/model_4/pool1_pad/Pad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_1384900]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow\n",
        "import tensorflow.keras.applications\n",
        "\n",
        "###CONFIG#####\n",
        "train = False\n",
        "im_size = (512,512)\n",
        "save = '/content/drive/MyDrive/SyntekaBio/weights'\n",
        "path = '/content/drive/MyDrive/SyntekaBio/train/PNG'\n",
        "epochs = 100\n",
        "batch_size = 4\n",
        "fold = 10\n",
        "lr = 1e-4\n",
        "###############\n",
        "\n",
        "data = data_load(path,input_shape = im_size) \n",
        "model = keras_xception(im_size) \n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "#trainning step\n",
        "print('######################')\n",
        "print('##                  ##')\n",
        "print('##   Train Models   ##')\n",
        "print('##                  ##')\n",
        "print('######################')\n",
        "    \n",
        "training(data, model, \n",
        "        epochs = epochs,\n",
        "        batch_size = batch_size,\n",
        "        fold = fold, \n",
        "        save=save,\n",
        "        r=50, \n",
        "        decay=0.1,\n",
        "        lr = lr)\n",
        "\n",
        "\n",
        "#trainning step\n",
        "print('######################')\n",
        "print('##                  ##')\n",
        "print('##    Test STEP     ##')\n",
        "print('##                  ##')\n",
        "print('######################')\n",
        "testing(data, model, thr = 0.5, save=save)"
      ],
      "metadata": {
        "id": "J7AbjuU3cldO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf042800-b58e-46cc-f17b-40bbe1d0b468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train img load...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 501/501 [00:20<00:00, 24.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test img load...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 126/126 [00:08<00:00, 15.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 512, 512, 3)]     0         \n",
            "                                                                 \n",
            " model_6 (Functional)        (None, 2048)              20861480  \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 2049      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,863,529\n",
            "Trainable params: 20,809,001\n",
            "Non-trainable params: 54,528\n",
            "_________________________________________________________________\n",
            "######################\n",
            "##                  ##\n",
            "##   Train Models   ##\n",
            "##                  ##\n",
            "######################\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 1 [0,50]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "  6/113 [>.............................] - ETA: 22s - loss: 0.6266 - custom_f1: 0.8254WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0450s vs `on_train_batch_end` time: 0.1393s). Check your callbacks.\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.5382 - custom_f1: 0.8025\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 34s 240ms/step - loss: 0.5382 - custom_f1: 0.8025 - val_loss: 0.6663 - val_custom_f1: 0.8676\n",
            "Epoch 2: lr: 9.999999747378752e-05\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.2345 - custom_f1: 0.9068\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 25s 225ms/step - loss: 0.2345 - custom_f1: 0.9068 - val_loss: 0.5772 - val_custom_f1: 0.8676\n",
            "Epoch 3: lr: 9.999999747378752e-05\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.3445 - custom_f1: 0.8839\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 25s 225ms/step - loss: 0.3445 - custom_f1: 0.8839 - val_loss: 0.5368 - val_custom_f1: 0.8676\n",
            "Epoch 4: lr: 9.999999747378752e-05\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 0.1749 - custom_f1: 0.9483 - val_loss: 1.1892 - val_custom_f1: 0.8676\n",
            "Epoch 5: lr: 9.999999747378752e-05\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 0.1412 - custom_f1: 0.9566 - val_loss: 3.2571 - val_custom_f1: 0.8676\n",
            "Epoch 6: lr: 9.999999747378752e-05\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 0.1816 - custom_f1: 0.9381 - val_loss: 3.8919 - val_custom_f1: 0.8676\n",
            "Epoch 7: lr: 9.999999747378752e-05\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 0.1513 - custom_f1: 0.9587 - val_loss: 2.1723 - val_custom_f1: 0.8676\n",
            "Epoch 8: lr: 9.999999747378752e-05\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1359 - custom_f1: 0.9429\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 25s 226ms/step - loss: 0.1359 - custom_f1: 0.9429 - val_loss: 0.1712 - val_custom_f1: 0.9521\n",
            "Epoch 9: lr: 9.999999747378752e-05\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 0.1574 - custom_f1: 0.9416 - val_loss: 2.2753 - val_custom_f1: 0.3750\n",
            "Epoch 10: lr: 9.999999747378752e-05\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1127 - custom_f1: 0.9606\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 227ms/step - loss: 0.1127 - custom_f1: 0.9606 - val_loss: 0.1666 - val_custom_f1: 0.9600\n",
            "Epoch 11: lr: 9.999999747378752e-05\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 0.1219 - custom_f1: 0.9435 - val_loss: 0.4914 - val_custom_f1: 0.8393\n",
            "Epoch 12: lr: 9.999999747378752e-05\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 0.0497 - custom_f1: 0.9822 - val_loss: 0.2428 - val_custom_f1: 0.9126\n",
            "Epoch 13: lr: 9.999999747378752e-05\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0493 - custom_f1: 0.9692\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 25s 225ms/step - loss: 0.0493 - custom_f1: 0.9692 - val_loss: 0.1535 - val_custom_f1: 0.9509\n",
            "Epoch 14: lr: 9.999999747378752e-05\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 0.0248 - custom_f1: 0.9810 - val_loss: 0.2318 - val_custom_f1: 0.9630\n",
            "Epoch 15: lr: 9.999999747378752e-05\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 0.0075 - custom_f1: 0.9823 - val_loss: 0.2110 - val_custom_f1: 0.9542\n",
            "Epoch 16: lr: 9.999999747378752e-05\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 0.0027 - custom_f1: 0.9912 - val_loss: 0.2724 - val_custom_f1: 0.9458\n",
            "Epoch 17: lr: 9.999999747378752e-05\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0205 - custom_f1: 0.9646\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 25s 225ms/step - loss: 0.0205 - custom_f1: 0.9646 - val_loss: 0.1499 - val_custom_f1: 0.9549\n",
            "Epoch 18: lr: 9.999999747378752e-05\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 0.0043 - custom_f1: 0.9823 - val_loss: 0.3075 - val_custom_f1: 0.8931\n",
            "Epoch 19: lr: 9.999999747378752e-05\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0024 - custom_f1: 0.9912\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 25s 225ms/step - loss: 0.0024 - custom_f1: 0.9912 - val_loss: 0.1201 - val_custom_f1: 0.9717\n",
            "Epoch 20: lr: 9.999999747378752e-05\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 0.0014 - custom_f1: 0.9912 - val_loss: 0.1492 - val_custom_f1: 0.9444\n",
            "Epoch 21: lr: 9.999999747378752e-05\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 9.2427e-04 - custom_f1: 0.9912 - val_loss: 0.1467 - val_custom_f1: 0.9444\n",
            "Epoch 22: lr: 9.999999747378752e-05\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 8.3743e-04 - custom_f1: 0.9823 - val_loss: 0.1424 - val_custom_f1: 0.9444\n",
            "Epoch 23: lr: 9.999999747378752e-05\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 8.3774e-04 - custom_f1: 0.9823\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 25s 225ms/step - loss: 8.3774e-04 - custom_f1: 0.9823 - val_loss: 0.1122 - val_custom_f1: 0.9717\n",
            "Epoch 24: lr: 9.999999747378752e-05\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 3.7838e-04 - custom_f1: 1.0000 - val_loss: 0.1515 - val_custom_f1: 0.9630\n",
            "Epoch 25: lr: 9.999999747378752e-05\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 0.0012 - custom_f1: 0.9735 - val_loss: 0.5411 - val_custom_f1: 0.8806\n",
            "Epoch 26: lr: 9.999999747378752e-05\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 6.1886e-04 - custom_f1: 0.9912 - val_loss: 0.1864 - val_custom_f1: 0.9360\n",
            "Epoch 27: lr: 9.999999747378752e-05\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 4.2442e-04 - custom_f1: 0.9912 - val_loss: 0.2410 - val_custom_f1: 0.9376\n",
            "Epoch 28: lr: 9.999999747378752e-05\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 4.3086e-04 - custom_f1: 0.9735 - val_loss: 0.1980 - val_custom_f1: 0.9360\n",
            "Epoch 29: lr: 9.999999747378752e-05\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 4.7075e-04 - custom_f1: 0.9646 - val_loss: 0.1860 - val_custom_f1: 0.9444\n",
            "Epoch 30: lr: 9.999999747378752e-05\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 2.7755e-04 - custom_f1: 0.9912 - val_loss: 0.2215 - val_custom_f1: 0.9360\n",
            "Epoch 31: lr: 9.999999747378752e-05\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 2.0431e-04 - custom_f1: 0.9912 - val_loss: 0.2154 - val_custom_f1: 0.9360\n",
            "Epoch 32: lr: 9.999999747378752e-05\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 1.4297e-04 - custom_f1: 1.0000 - val_loss: 0.2519 - val_custom_f1: 0.9204\n",
            "Epoch 33: lr: 9.999999747378752e-05\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 1.4993e-04 - custom_f1: 1.0000 - val_loss: 0.2780 - val_custom_f1: 0.9204\n",
            "Epoch 34: lr: 9.999999747378752e-05\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 4.3109e-04 - custom_f1: 0.9735 - val_loss: 0.1732 - val_custom_f1: 0.9623\n",
            "Epoch 35: lr: 9.999999747378752e-05\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 1.5019e-04 - custom_f1: 0.9912 - val_loss: 0.2024 - val_custom_f1: 0.9532\n",
            "Epoch 36: lr: 9.999999747378752e-05\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 1.1632e-04 - custom_f1: 0.9912 - val_loss: 0.2091 - val_custom_f1: 0.9444\n",
            "Epoch 37: lr: 9.999999747378752e-05\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 1.2944e-04 - custom_f1: 0.9823 - val_loss: 0.2117 - val_custom_f1: 0.9444\n",
            "Epoch 38: lr: 9.999999747378752e-05\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 1.2642e-04 - custom_f1: 1.0000 - val_loss: 0.2134 - val_custom_f1: 0.9444\n",
            "Epoch 39: lr: 9.999999747378752e-05\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 2.0700e-04 - custom_f1: 0.9735 - val_loss: 0.1626 - val_custom_f1: 0.9623\n",
            "Epoch 40: lr: 9.999999747378752e-05\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 1.4976e-04 - custom_f1: 0.9823 - val_loss: 0.1880 - val_custom_f1: 0.9623\n",
            "Epoch 41: lr: 9.999999747378752e-05\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 2.0297e-04 - custom_f1: 0.9469 - val_loss: 0.1720 - val_custom_f1: 0.9623\n",
            "Epoch 42: lr: 9.999999747378752e-05\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 1.1542e-04 - custom_f1: 0.9823 - val_loss: 0.1960 - val_custom_f1: 0.9623\n",
            "Epoch 43: lr: 9.999999747378752e-05\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 9.2846e-05 - custom_f1: 0.9646 - val_loss: 0.2169 - val_custom_f1: 0.9532\n",
            "Epoch 44: lr: 9.999999747378752e-05\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 1.0264e-04 - custom_f1: 0.9735 - val_loss: 0.2303 - val_custom_f1: 0.9444\n",
            "Epoch 45: lr: 9.999999747378752e-05\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 8.6052e-05 - custom_f1: 0.9823 - val_loss: 0.2362 - val_custom_f1: 0.9542\n",
            "Epoch 46: lr: 9.999999747378752e-05\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 9.9500e-05 - custom_f1: 0.9912 - val_loss: 0.2189 - val_custom_f1: 0.9630\n",
            "Epoch 47: lr: 9.999999747378752e-05\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 7.0902e-05 - custom_f1: 0.9912 - val_loss: 0.2427 - val_custom_f1: 0.9458\n",
            "Epoch 48: lr: 9.999999747378752e-05\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 5.9740e-05 - custom_f1: 0.9912 - val_loss: 0.2379 - val_custom_f1: 0.9542\n",
            "Epoch 49: lr: 9.999999747378752e-05\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 5.8390e-05 - custom_f1: 0.9823 - val_loss: 0.2381 - val_custom_f1: 0.9542\n",
            "Epoch 50: lr: 9.999999747378752e-05\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 3.4524e-05 - custom_f1: 1.0000 - val_loss: 0.2607 - val_custom_f1: 0.9376\n",
            "Epoch 51: lr: 9.999999747378752e-05\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 5.3349e-05 - custom_f1: 0.9823\n",
            "lr is fixed to 9.999999747378752e-06\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 5.3349e-05 - custom_f1: 0.9823 - val_loss: 0.2590 - val_custom_f1: 0.9542\n",
            "Epoch 52: lr: 9.999999747378752e-06\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 7.2694e-05 - custom_f1: 0.9823 - val_loss: 0.2506 - val_custom_f1: 0.9542\n",
            "Epoch 53: lr: 9.999999747378752e-06\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 8.7285e-05 - custom_f1: 0.9735 - val_loss: 0.2426 - val_custom_f1: 0.9542\n",
            "Epoch 54: lr: 9.999999747378752e-06\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 8.4017e-05 - custom_f1: 0.9823 - val_loss: 0.2424 - val_custom_f1: 0.9542\n",
            "Epoch 55: lr: 9.999999747378752e-06\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 5.8780e-05 - custom_f1: 0.9823 - val_loss: 0.2342 - val_custom_f1: 0.9444\n",
            "Epoch 56: lr: 9.999999747378752e-06\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 4.7401e-05 - custom_f1: 0.9823 - val_loss: 0.2287 - val_custom_f1: 0.9444\n",
            "Epoch 57: lr: 9.999999747378752e-06\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 4.5582e-05 - custom_f1: 0.9823 - val_loss: 0.2346 - val_custom_f1: 0.9444\n",
            "Epoch 58: lr: 9.999999747378752e-06\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 5.7061e-05 - custom_f1: 0.9735 - val_loss: 0.2422 - val_custom_f1: 0.9444\n",
            "Epoch 59: lr: 9.999999747378752e-06\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 3.9339e-05 - custom_f1: 0.9912 - val_loss: 0.2445 - val_custom_f1: 0.9444\n",
            "Epoch 60: lr: 9.999999747378752e-06\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 4.9865e-05 - custom_f1: 0.9823 - val_loss: 0.2335 - val_custom_f1: 0.9444\n",
            "Epoch 61: lr: 9.999999747378752e-06\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - 24s 214ms/step - loss: 5.8414e-05 - custom_f1: 0.9735 - val_loss: 0.2260 - val_custom_f1: 0.9532\n",
            "Epoch 62: lr: 9.999999747378752e-06\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 6.0620e-05 - custom_f1: 0.9646 - val_loss: 0.2283 - val_custom_f1: 0.9444\n",
            "Epoch 63: lr: 9.999999747378752e-06\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 3.8896e-05 - custom_f1: 0.9912 - val_loss: 0.2315 - val_custom_f1: 0.9444\n",
            "Epoch 64: lr: 9.999999747378752e-06\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 4.2539e-05 - custom_f1: 0.9823 - val_loss: 0.2421 - val_custom_f1: 0.9444\n",
            "Epoch 65: lr: 9.999999747378752e-06\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 2.5926e-05 - custom_f1: 1.0000 - val_loss: 0.2397 - val_custom_f1: 0.9444\n",
            "Epoch 66: lr: 9.999999747378752e-06\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 3.5402e-05 - custom_f1: 0.9912 - val_loss: 0.2439 - val_custom_f1: 0.9542\n",
            "Epoch 67: lr: 9.999999747378752e-06\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 5.0626e-05 - custom_f1: 0.9735 - val_loss: 0.2394 - val_custom_f1: 0.9444\n",
            "Epoch 68: lr: 9.999999747378752e-06\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 3.7065e-05 - custom_f1: 0.9823 - val_loss: 0.2480 - val_custom_f1: 0.9542\n",
            "Epoch 69: lr: 9.999999747378752e-06\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 5.3777e-05 - custom_f1: 0.9646 - val_loss: 0.2435 - val_custom_f1: 0.9542\n",
            "Epoch 70: lr: 9.999999747378752e-06\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 3.2646e-05 - custom_f1: 0.9823 - val_loss: 0.2486 - val_custom_f1: 0.9542\n",
            "Epoch 71: lr: 9.999999747378752e-06\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 4.2847e-05 - custom_f1: 0.9823 - val_loss: 0.2437 - val_custom_f1: 0.9444\n",
            "Epoch 72: lr: 9.999999747378752e-06\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 24s 214ms/step - loss: 3.7904e-05 - custom_f1: 0.9912 - val_loss: 0.2556 - val_custom_f1: 0.9542\n",
            "Epoch 73: lr: 9.999999747378752e-06\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 6.9181e-05 - custom_f1: 0.9558 - val_loss: 0.2375 - val_custom_f1: 0.9444\n",
            "Epoch 74: lr: 9.999999747378752e-06\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 24s 214ms/step - loss: 3.6307e-05 - custom_f1: 0.9912 - val_loss: 0.2385 - val_custom_f1: 0.9444\n",
            "Epoch 75: lr: 9.999999747378752e-06\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 4.2032e-05 - custom_f1: 0.9912 - val_loss: 0.2413 - val_custom_f1: 0.9444\n",
            "Epoch 76: lr: 9.999999747378752e-06\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 4.5444e-05 - custom_f1: 0.9735 - val_loss: 0.2481 - val_custom_f1: 0.9444\n",
            "Epoch 77: lr: 9.999999747378752e-06\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 3.4539e-05 - custom_f1: 0.9823 - val_loss: 0.2447 - val_custom_f1: 0.9444\n",
            "Epoch 78: lr: 9.999999747378752e-06\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 3.4784e-05 - custom_f1: 0.9823 - val_loss: 0.2498 - val_custom_f1: 0.9444\n",
            "Epoch 79: lr: 9.999999747378752e-06\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 2.9444e-05 - custom_f1: 0.9912 - val_loss: 0.2511 - val_custom_f1: 0.9444\n",
            "Epoch 80: lr: 9.999999747378752e-06\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 3.2188e-05 - custom_f1: 0.9912 - val_loss: 0.2641 - val_custom_f1: 0.9542\n",
            "Epoch 81: lr: 9.999999747378752e-06\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 1.7664e-05 - custom_f1: 1.0000 - val_loss: 0.2696 - val_custom_f1: 0.9542\n",
            "Epoch 82: lr: 9.999999747378752e-06\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 2.3850e-05 - custom_f1: 1.0000 - val_loss: 0.2824 - val_custom_f1: 0.9542\n",
            "Epoch 83: lr: 9.999999747378752e-06\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 2.4756e-05 - custom_f1: 0.9912 - val_loss: 0.2853 - val_custom_f1: 0.9542\n",
            "Epoch 84: lr: 9.999999747378752e-06\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 3.8160e-05 - custom_f1: 0.9912 - val_loss: 0.2813 - val_custom_f1: 0.9542\n",
            "Epoch 85: lr: 9.999999747378752e-06\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 2.7587e-05 - custom_f1: 0.9912 - val_loss: 0.2926 - val_custom_f1: 0.9376\n",
            "Epoch 86: lr: 9.999999747378752e-06\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 2.1835e-05 - custom_f1: 0.9912 - val_loss: 0.2924 - val_custom_f1: 0.9376\n",
            "Epoch 87: lr: 9.999999747378752e-06\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 3.3155e-05 - custom_f1: 0.9823 - val_loss: 0.2799 - val_custom_f1: 0.9542\n",
            "Epoch 88: lr: 9.999999747378752e-06\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 3.4167e-05 - custom_f1: 0.9823 - val_loss: 0.2728 - val_custom_f1: 0.9542\n",
            "Epoch 89: lr: 9.999999747378752e-06\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 1.4178e-05 - custom_f1: 1.0000 - val_loss: 0.2785 - val_custom_f1: 0.9542\n",
            "Epoch 90: lr: 9.999999747378752e-06\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 5.9486e-05 - custom_f1: 0.9646 - val_loss: 0.2289 - val_custom_f1: 0.9444\n",
            "Epoch 91: lr: 9.999999747378752e-06\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 4.1481e-05 - custom_f1: 0.9823 - val_loss: 0.2160 - val_custom_f1: 0.9623\n",
            "Epoch 92: lr: 9.999999747378752e-06\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 2.3276e-05 - custom_f1: 0.9912 - val_loss: 0.2325 - val_custom_f1: 0.9532\n",
            "Epoch 93: lr: 9.999999747378752e-06\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 2.6036e-05 - custom_f1: 0.9823 - val_loss: 0.2544 - val_custom_f1: 0.9444\n",
            "Epoch 94: lr: 9.999999747378752e-06\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 3.4017e-05 - custom_f1: 0.9912 - val_loss: 0.2255 - val_custom_f1: 0.9623\n",
            "Epoch 95: lr: 9.999999747378752e-06\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 2.3666e-05 - custom_f1: 0.9823 - val_loss: 0.2426 - val_custom_f1: 0.9532\n",
            "Epoch 96: lr: 9.999999747378752e-06\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 2.8539e-05 - custom_f1: 0.9823 - val_loss: 0.2409 - val_custom_f1: 0.9532\n",
            "Epoch 97: lr: 9.999999747378752e-06\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 2.9439e-05 - custom_f1: 0.9646 - val_loss: 0.2314 - val_custom_f1: 0.9623\n",
            "Epoch 98: lr: 9.999999747378752e-06\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 2.7466e-05 - custom_f1: 0.9823 - val_loss: 0.2386 - val_custom_f1: 0.9532\n",
            "Epoch 99: lr: 9.999999747378752e-06\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 2.0045e-05 - custom_f1: 0.9912 - val_loss: 0.2474 - val_custom_f1: 0.9444\n",
            "Epoch 100: lr: 9.999999747378752e-06\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 1.8372e-05 - custom_f1: 0.9912 - val_loss: 0.2659 - val_custom_f1: 0.9542\n",
            "weights are setted to best weights (epochs 23)\n",
            "fold 2 [50,100]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "  6/113 [>.............................] - ETA: 23s - loss: 0.6001 - custom_f1: 0.8048WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0461s vs `on_train_batch_end` time: 0.1710s). Check your callbacks.\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.6183 - custom_f1: 0.7812\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 25s 222ms/step - loss: 0.6183 - custom_f1: 0.7812 - val_loss: 0.6930 - val_custom_f1: 0.7151\n",
            "Epoch 2: lr: 9.999999747378752e-05\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.4001 - custom_f1: 0.8498 - val_loss: 0.6978 - val_custom_f1: 0.0000e+00\n",
            "Epoch 3: lr: 9.999999747378752e-05\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 0.2399 - custom_f1: 0.9188 - val_loss: 0.7238 - val_custom_f1: 0.0000e+00\n",
            "Epoch 4: lr: 9.999999747378752e-05\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 0.1952 - custom_f1: 0.9313 - val_loss: 0.8405 - val_custom_f1: 0.0000e+00\n",
            "Epoch 5: lr: 9.999999747378752e-05\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 0.0839 - custom_f1: 0.9773 - val_loss: 0.9505 - val_custom_f1: 0.0000e+00\n",
            "Epoch 6: lr: 9.999999747378752e-05\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 0.0389 - custom_f1: 0.9915 - val_loss: 1.4409 - val_custom_f1: 0.0000e+00\n",
            "Epoch 7: lr: 9.999999747378752e-05\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.1480 - custom_f1: 0.9518 - val_loss: 1.4865 - val_custom_f1: 0.1546\n",
            "Epoch 8: lr: 9.999999747378752e-05\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1131 - custom_f1: 0.9635\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 229ms/step - loss: 0.1131 - custom_f1: 0.9635 - val_loss: 0.4849 - val_custom_f1: 0.6554\n",
            "Epoch 9: lr: 9.999999747378752e-05\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0631 - custom_f1: 0.9751\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 27s 236ms/step - loss: 0.0631 - custom_f1: 0.9751 - val_loss: 0.2700 - val_custom_f1: 0.9042\n",
            "Epoch 10: lr: 9.999999747378752e-05\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0303 - custom_f1: 0.9798 - val_loss: 0.4676 - val_custom_f1: 0.8667\n",
            "Epoch 11: lr: 9.999999747378752e-05\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0299 - custom_f1: 0.9794 - val_loss: 0.3474 - val_custom_f1: 0.8500\n",
            "Epoch 12: lr: 9.999999747378752e-05\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0156 - custom_f1: 0.9794 - val_loss: 0.2829 - val_custom_f1: 0.8920\n",
            "Epoch 13: lr: 9.999999747378752e-05\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0044 - custom_f1: 0.9912 - val_loss: 0.3655 - val_custom_f1: 0.8655\n",
            "Epoch 14: lr: 9.999999747378752e-05\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 0.0019 - custom_f1: 0.9912 - val_loss: 0.4698 - val_custom_f1: 0.8565\n",
            "Epoch 15: lr: 9.999999747378752e-05\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 0.0026 - custom_f1: 0.9912 - val_loss: 0.4032 - val_custom_f1: 0.8762\n",
            "Epoch 16: lr: 9.999999747378752e-05\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0027 - custom_f1: 1.0000 - val_loss: 0.4281 - val_custom_f1: 0.8348\n",
            "Epoch 17: lr: 9.999999747378752e-05\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 0.0046 - custom_f1: 0.9823 - val_loss: 0.3409 - val_custom_f1: 0.8784\n",
            "Epoch 18: lr: 9.999999747378752e-05\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 0.0013 - custom_f1: 0.9912 - val_loss: 0.4230 - val_custom_f1: 0.8565\n",
            "Epoch 19: lr: 9.999999747378752e-05\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 8.9160e-04 - custom_f1: 0.9912 - val_loss: 0.4236 - val_custom_f1: 0.8565\n",
            "Epoch 20: lr: 9.999999747378752e-05\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 6.1192e-04 - custom_f1: 0.9912 - val_loss: 0.5012 - val_custom_f1: 0.8565\n",
            "Epoch 21: lr: 9.999999747378752e-05\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 7.4013e-04 - custom_f1: 0.9912 - val_loss: 0.4321 - val_custom_f1: 0.8565\n",
            "Epoch 22: lr: 9.999999747378752e-05\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.5688e-04 - custom_f1: 1.0000 - val_loss: 0.4852 - val_custom_f1: 0.8565\n",
            "Epoch 23: lr: 9.999999747378752e-05\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 8.9157e-04 - custom_f1: 0.9646 - val_loss: 0.3701 - val_custom_f1: 0.8756\n",
            "Epoch 24: lr: 9.999999747378752e-05\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 6.5574e-04 - custom_f1: 0.9823 - val_loss: 0.3715 - val_custom_f1: 0.8756\n",
            "Epoch 25: lr: 9.999999747378752e-05\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 8.1016e-04 - custom_f1: 0.9646 - val_loss: 0.5028 - val_custom_f1: 0.7711\n",
            "Epoch 26: lr: 9.999999747378752e-05\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 4.3489e-04 - custom_f1: 0.9735 - val_loss: 0.4241 - val_custom_f1: 0.8545\n",
            "Epoch 27: lr: 9.999999747378752e-05\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.7041e-04 - custom_f1: 0.9823 - val_loss: 0.5055 - val_custom_f1: 0.8565\n",
            "Epoch 28: lr: 9.999999747378752e-05\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 2.5830e-04 - custom_f1: 0.9912 - val_loss: 0.5183 - val_custom_f1: 0.8565\n",
            "Epoch 29: lr: 9.999999747378752e-05\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 1.5330e-04 - custom_f1: 1.0000 - val_loss: 0.5377 - val_custom_f1: 0.8565\n",
            "Epoch 30: lr: 9.999999747378752e-05\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 1.5897e-04 - custom_f1: 1.0000 - val_loss: 0.5506 - val_custom_f1: 0.8565\n",
            "Epoch 31: lr: 9.999999747378752e-05\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 3.5957e-04 - custom_f1: 0.9823 - val_loss: 0.4033 - val_custom_f1: 0.8756\n",
            "Epoch 32: lr: 9.999999747378752e-05\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 3.8751e-04 - custom_f1: 0.9912 - val_loss: 0.4178 - val_custom_f1: 0.8434\n",
            "Epoch 33: lr: 9.999999747378752e-05\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.6031e-04 - custom_f1: 0.9912 - val_loss: 0.4917 - val_custom_f1: 0.8667\n",
            "Epoch 34: lr: 9.999999747378752e-05\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 1.2737e-04 - custom_f1: 1.0000 - val_loss: 0.5354 - val_custom_f1: 0.8565\n",
            "Epoch 35: lr: 9.999999747378752e-05\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.0837e-04 - custom_f1: 1.0000 - val_loss: 0.5510 - val_custom_f1: 0.8565\n",
            "Epoch 36: lr: 9.999999747378752e-05\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 8.0075e-05 - custom_f1: 1.0000 - val_loss: 0.5653 - val_custom_f1: 0.8565\n",
            "Epoch 37: lr: 9.999999747378752e-05\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.1543e-04 - custom_f1: 0.9823 - val_loss: 0.5298 - val_custom_f1: 0.8667\n",
            "Epoch 38: lr: 9.999999747378752e-05\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 7.6463e-05 - custom_f1: 1.0000 - val_loss: 0.5516 - val_custom_f1: 0.8565\n",
            "Epoch 39: lr: 9.999999747378752e-05\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.4822e-04 - custom_f1: 0.9735 - val_loss: 0.5096 - val_custom_f1: 0.8667\n",
            "Epoch 40: lr: 9.999999747378752e-05\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 2.3861e-04 - custom_f1: 0.9558 - val_loss: 0.4443 - val_custom_f1: 0.8434\n",
            "Epoch 41: lr: 9.999999747378752e-05\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 1.1572e-04 - custom_f1: 0.9646 - val_loss: 0.5127 - val_custom_f1: 0.8545\n",
            "Epoch 42: lr: 9.999999747378752e-05\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.0328e-04 - custom_f1: 0.9735 - val_loss: 0.5282 - val_custom_f1: 0.8545\n",
            "Epoch 43: lr: 9.999999747378752e-05\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 4.8540e-05 - custom_f1: 1.0000 - val_loss: 0.5424 - val_custom_f1: 0.8545\n",
            "Epoch 44: lr: 9.999999747378752e-05\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 7.4970e-05 - custom_f1: 0.9912 - val_loss: 0.5517 - val_custom_f1: 0.8565\n",
            "Epoch 45: lr: 9.999999747378752e-05\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 7.7326e-05 - custom_f1: 0.9735 - val_loss: 0.5068 - val_custom_f1: 0.8545\n",
            "Epoch 46: lr: 9.999999747378752e-05\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 6.2164e-05 - custom_f1: 0.9912 - val_loss: 0.5527 - val_custom_f1: 0.8667\n",
            "Epoch 47: lr: 9.999999747378752e-05\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 4.6712e-05 - custom_f1: 1.0000 - val_loss: 0.5822 - val_custom_f1: 0.8565\n",
            "Epoch 48: lr: 9.999999747378752e-05\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 1.1432e-04 - custom_f1: 0.9823 - val_loss: 0.4914 - val_custom_f1: 0.8230\n",
            "Epoch 49: lr: 9.999999747378752e-05\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 4.7508e-05 - custom_f1: 1.0000 - val_loss: 0.5417 - val_custom_f1: 0.8545\n",
            "Epoch 50: lr: 9.999999747378752e-05\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 4.6591e-05 - custom_f1: 0.9912 - val_loss: 0.5431 - val_custom_f1: 0.8545\n",
            "Epoch 51: lr: 9.999999747378752e-05\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 3.2667e-05 - custom_f1: 1.0000\n",
            "lr is fixed to 9.999999747378752e-06\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 3.2667e-05 - custom_f1: 1.0000 - val_loss: 0.5735 - val_custom_f1: 0.8667\n",
            "Epoch 52: lr: 9.999999747378752e-06\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 6.6019e-05 - custom_f1: 0.9823 - val_loss: 0.5463 - val_custom_f1: 0.8667\n",
            "Epoch 53: lr: 9.999999747378752e-06\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 2.9913e-05 - custom_f1: 1.0000 - val_loss: 0.5498 - val_custom_f1: 0.8667\n",
            "Epoch 54: lr: 9.999999747378752e-06\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 7.6018e-05 - custom_f1: 0.9823 - val_loss: 0.5346 - val_custom_f1: 0.8545\n",
            "Epoch 55: lr: 9.999999747378752e-06\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 6.4652e-05 - custom_f1: 0.9735 - val_loss: 0.5353 - val_custom_f1: 0.8545\n",
            "Epoch 56: lr: 9.999999747378752e-06\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 5.6096e-05 - custom_f1: 0.9823 - val_loss: 0.5398 - val_custom_f1: 0.8545\n",
            "Epoch 57: lr: 9.999999747378752e-06\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 3.0283e-05 - custom_f1: 1.0000 - val_loss: 0.5415 - val_custom_f1: 0.8545\n",
            "Epoch 58: lr: 9.999999747378752e-06\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 4.1543e-05 - custom_f1: 0.9912 - val_loss: 0.5454 - val_custom_f1: 0.8545\n",
            "Epoch 59: lr: 9.999999747378752e-06\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 3.9630e-05 - custom_f1: 0.9912 - val_loss: 0.5426 - val_custom_f1: 0.8545\n",
            "Epoch 60: lr: 9.999999747378752e-06\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.7216e-05 - custom_f1: 0.9912 - val_loss: 0.5473 - val_custom_f1: 0.8667\n",
            "Epoch 61: lr: 9.999999747378752e-06\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 4.3199e-05 - custom_f1: 0.9823 - val_loss: 0.5462 - val_custom_f1: 0.8545\n",
            "Epoch 62: lr: 9.999999747378752e-06\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 6.7749e-05 - custom_f1: 0.9823 - val_loss: 0.5408 - val_custom_f1: 0.8545\n",
            "Epoch 63: lr: 9.999999747378752e-06\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 6.2533e-05 - custom_f1: 0.9646 - val_loss: 0.5318 - val_custom_f1: 0.8545\n",
            "Epoch 64: lr: 9.999999747378752e-06\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 3.8958e-05 - custom_f1: 0.9912 - val_loss: 0.5343 - val_custom_f1: 0.8545\n",
            "Epoch 65: lr: 9.999999747378752e-06\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 3.3970e-05 - custom_f1: 0.9912 - val_loss: 0.5390 - val_custom_f1: 0.8545\n",
            "Epoch 66: lr: 9.999999747378752e-06\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 3.0215e-05 - custom_f1: 1.0000 - val_loss: 0.5479 - val_custom_f1: 0.8545\n",
            "Epoch 67: lr: 9.999999747378752e-06\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 6.8809e-05 - custom_f1: 0.9735 - val_loss: 0.5170 - val_custom_f1: 0.8545\n",
            "Epoch 68: lr: 9.999999747378752e-06\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 6.1987e-05 - custom_f1: 0.9823 - val_loss: 0.5030 - val_custom_f1: 0.8545\n",
            "Epoch 69: lr: 9.999999747378752e-06\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 4.2516e-05 - custom_f1: 0.9912 - val_loss: 0.5051 - val_custom_f1: 0.8545\n",
            "Epoch 70: lr: 9.999999747378752e-06\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 4.6458e-05 - custom_f1: 0.9912 - val_loss: 0.5050 - val_custom_f1: 0.8545\n",
            "Epoch 71: lr: 9.999999747378752e-06\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 4.3256e-05 - custom_f1: 0.9823 - val_loss: 0.5113 - val_custom_f1: 0.8545\n",
            "Epoch 72: lr: 9.999999747378752e-06\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 5.8062e-05 - custom_f1: 0.9558 - val_loss: 0.5129 - val_custom_f1: 0.8545\n",
            "Epoch 73: lr: 9.999999747378752e-06\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 3.8623e-05 - custom_f1: 0.9735 - val_loss: 0.5194 - val_custom_f1: 0.8545\n",
            "Epoch 74: lr: 9.999999747378752e-06\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 2.3270e-05 - custom_f1: 1.0000 - val_loss: 0.5257 - val_custom_f1: 0.8545\n",
            "Epoch 75: lr: 9.999999747378752e-06\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 5.2342e-05 - custom_f1: 0.9646 - val_loss: 0.5165 - val_custom_f1: 0.8545\n",
            "Epoch 76: lr: 9.999999747378752e-06\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 2.8152e-05 - custom_f1: 1.0000 - val_loss: 0.5289 - val_custom_f1: 0.8545\n",
            "Epoch 77: lr: 9.999999747378752e-06\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.0657e-05 - custom_f1: 0.9912 - val_loss: 0.5335 - val_custom_f1: 0.8545\n",
            "Epoch 78: lr: 9.999999747378752e-06\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 3.9283e-05 - custom_f1: 0.9823 - val_loss: 0.5311 - val_custom_f1: 0.8545\n",
            "Epoch 79: lr: 9.999999747378752e-06\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 2.8584e-05 - custom_f1: 1.0000 - val_loss: 0.5453 - val_custom_f1: 0.8545\n",
            "Epoch 80: lr: 9.999999747378752e-06\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.9638e-05 - custom_f1: 0.9823 - val_loss: 0.5467 - val_custom_f1: 0.8545\n",
            "Epoch 81: lr: 9.999999747378752e-06\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 2.6656e-05 - custom_f1: 1.0000 - val_loss: 0.5611 - val_custom_f1: 0.8545\n",
            "Epoch 82: lr: 9.999999747378752e-06\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 2.0629e-05 - custom_f1: 1.0000 - val_loss: 0.5773 - val_custom_f1: 0.8667\n",
            "Epoch 83: lr: 9.999999747378752e-06\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.5125e-05 - custom_f1: 0.9735 - val_loss: 0.5756 - val_custom_f1: 0.8545\n",
            "Epoch 84: lr: 9.999999747378752e-06\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.7647e-05 - custom_f1: 0.9823 - val_loss: 0.5527 - val_custom_f1: 0.8545\n",
            "Epoch 85: lr: 9.999999747378752e-06\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.4115e-05 - custom_f1: 0.9823 - val_loss: 0.5632 - val_custom_f1: 0.8545\n",
            "Epoch 86: lr: 9.999999747378752e-06\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 2.3124e-05 - custom_f1: 1.0000 - val_loss: 0.5706 - val_custom_f1: 0.8545\n",
            "Epoch 87: lr: 9.999999747378752e-06\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 2.4658e-05 - custom_f1: 0.9912 - val_loss: 0.5853 - val_custom_f1: 0.8545\n",
            "Epoch 88: lr: 9.999999747378752e-06\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 3.1947e-05 - custom_f1: 0.9823 - val_loss: 0.5664 - val_custom_f1: 0.8545\n",
            "Epoch 89: lr: 9.999999747378752e-06\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 2.1173e-05 - custom_f1: 1.0000 - val_loss: 0.5820 - val_custom_f1: 0.8545\n",
            "Epoch 90: lr: 9.999999747378752e-06\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.5514e-05 - custom_f1: 0.9735 - val_loss: 0.5643 - val_custom_f1: 0.8545\n",
            "Epoch 91: lr: 9.999999747378752e-06\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 2.3162e-05 - custom_f1: 0.9912 - val_loss: 0.5570 - val_custom_f1: 0.8545\n",
            "Epoch 92: lr: 9.999999747378752e-06\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 2.4769e-05 - custom_f1: 0.9823 - val_loss: 0.5683 - val_custom_f1: 0.8545\n",
            "Epoch 93: lr: 9.999999747378752e-06\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.2951e-05 - custom_f1: 0.9735 - val_loss: 0.5455 - val_custom_f1: 0.8545\n",
            "Epoch 94: lr: 9.999999747378752e-06\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 2.2459e-05 - custom_f1: 0.9912 - val_loss: 0.5187 - val_custom_f1: 0.8545\n",
            "Epoch 95: lr: 9.999999747378752e-06\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 2.7920e-05 - custom_f1: 0.9912 - val_loss: 0.5215 - val_custom_f1: 0.8545\n",
            "Epoch 96: lr: 9.999999747378752e-06\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 1.7748e-05 - custom_f1: 0.9912 - val_loss: 0.5435 - val_custom_f1: 0.8545\n",
            "Epoch 97: lr: 9.999999747378752e-06\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.7578e-05 - custom_f1: 0.9912 - val_loss: 0.5577 - val_custom_f1: 0.8545\n",
            "Epoch 98: lr: 9.999999747378752e-06\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 2.1122e-05 - custom_f1: 0.9823 - val_loss: 0.5657 - val_custom_f1: 0.8545\n",
            "Epoch 99: lr: 9.999999747378752e-06\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 1.7231e-05 - custom_f1: 0.9912 - val_loss: 0.5862 - val_custom_f1: 0.8545\n",
            "Epoch 100: lr: 9.999999747378752e-06\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 2.9213e-05 - custom_f1: 0.9735 - val_loss: 0.5875 - val_custom_f1: 0.8545\n",
            "weights are setted to best weights (epochs 9)\n",
            "fold 3 [100,150]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "  6/113 [>.............................] - ETA: 22s - loss: 0.6489 - custom_f1: 0.7722WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0459s vs `on_train_batch_end` time: 0.1652s). Check your callbacks.\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.6341 - custom_f1: 0.7660\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 25s 223ms/step - loss: 0.6341 - custom_f1: 0.7660 - val_loss: 0.6892 - val_custom_f1: 0.8182\n",
            "Epoch 2: lr: 9.999999747378752e-05\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.4605 - custom_f1: 0.8231\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 229ms/step - loss: 0.4605 - custom_f1: 0.8231 - val_loss: 0.6808 - val_custom_f1: 0.8182\n",
            "Epoch 3: lr: 9.999999747378752e-05\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.2339 - custom_f1: 0.9126\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 229ms/step - loss: 0.2339 - custom_f1: 0.9126 - val_loss: 0.6656 - val_custom_f1: 0.8182\n",
            "Epoch 4: lr: 9.999999747378752e-05\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 0.2027 - custom_f1: 0.9431 - val_loss: 0.6843 - val_custom_f1: 0.8182\n",
            "Epoch 5: lr: 9.999999747378752e-05\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1361 - custom_f1: 0.9585\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 229ms/step - loss: 0.1361 - custom_f1: 0.9585 - val_loss: 0.5887 - val_custom_f1: 0.8182\n",
            "Epoch 6: lr: 9.999999747378752e-05\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1108 - custom_f1: 0.9583\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 229ms/step - loss: 0.1108 - custom_f1: 0.9583 - val_loss: 0.4462 - val_custom_f1: 0.9028\n",
            "Epoch 7: lr: 9.999999747378752e-05\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0679 - custom_f1: 0.9762\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 229ms/step - loss: 0.0679 - custom_f1: 0.9762 - val_loss: 0.2906 - val_custom_f1: 0.9105\n",
            "Epoch 8: lr: 9.999999747378752e-05\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 0.0607 - custom_f1: 0.9721 - val_loss: 0.6302 - val_custom_f1: 0.7044\n",
            "Epoch 9: lr: 9.999999747378752e-05\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0353 - custom_f1: 0.9881\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 228ms/step - loss: 0.0353 - custom_f1: 0.9881 - val_loss: 0.2061 - val_custom_f1: 0.9028\n",
            "Epoch 10: lr: 9.999999747378752e-05\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0171 - custom_f1: 0.9912\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 227ms/step - loss: 0.0171 - custom_f1: 0.9912 - val_loss: 0.1889 - val_custom_f1: 0.9583\n",
            "Epoch 11: lr: 9.999999747378752e-05\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 0.0068 - custom_f1: 0.9912 - val_loss: 0.2400 - val_custom_f1: 0.8999\n",
            "Epoch 12: lr: 9.999999747378752e-05\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0018 - custom_f1: 1.0000\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 228ms/step - loss: 0.0018 - custom_f1: 1.0000 - val_loss: 0.1715 - val_custom_f1: 0.9481\n",
            "Epoch 13: lr: 9.999999747378752e-05\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0021 - custom_f1: 0.9823\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 229ms/step - loss: 0.0021 - custom_f1: 0.9823 - val_loss: 0.1692 - val_custom_f1: 0.9481\n",
            "Epoch 14: lr: 9.999999747378752e-05\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0167 - custom_f1: 0.9793 - val_loss: 1.1963 - val_custom_f1: 0.8510\n",
            "Epoch 15: lr: 9.999999747378752e-05\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 0.0778 - custom_f1: 0.9729 - val_loss: 1.6248 - val_custom_f1: 0.5429\n",
            "Epoch 16: lr: 9.999999747378752e-05\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 0.0310 - custom_f1: 0.9810 - val_loss: 0.9415 - val_custom_f1: 0.8423\n",
            "Epoch 17: lr: 9.999999747378752e-05\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 0.0037 - custom_f1: 1.0000 - val_loss: 0.3556 - val_custom_f1: 0.9105\n",
            "Epoch 18: lr: 9.999999747378752e-05\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0012 - custom_f1: 1.0000 - val_loss: 0.2496 - val_custom_f1: 0.9296\n",
            "Epoch 19: lr: 9.999999747378752e-05\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 0.0012 - custom_f1: 1.0000 - val_loss: 0.2010 - val_custom_f1: 0.9398\n",
            "Epoch 20: lr: 9.999999747378752e-05\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 0.0027 - custom_f1: 0.9823 - val_loss: 0.2258 - val_custom_f1: 0.9366\n",
            "Epoch 21: lr: 9.999999747378752e-05\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 6.9707e-04 - custom_f1: 1.0000 - val_loss: 0.2089 - val_custom_f1: 0.9183\n",
            "Epoch 22: lr: 9.999999747378752e-05\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 0.0011 - custom_f1: 0.9823 - val_loss: 0.2361 - val_custom_f1: 0.9366\n",
            "Epoch 23: lr: 9.999999747378752e-05\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 0.0017 - custom_f1: 0.9558 - val_loss: 0.3246 - val_custom_f1: 0.9058\n",
            "Epoch 24: lr: 9.999999747378752e-05\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 7.7220e-04 - custom_f1: 0.9735 - val_loss: 0.2313 - val_custom_f1: 0.9565\n",
            "Epoch 25: lr: 9.999999747378752e-05\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 4.3119e-04 - custom_f1: 0.9823 - val_loss: 0.2030 - val_custom_f1: 0.9366\n",
            "Epoch 26: lr: 9.999999747378752e-05\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 3.3417e-04 - custom_f1: 0.9912 - val_loss: 0.1975 - val_custom_f1: 0.9366\n",
            "Epoch 27: lr: 9.999999747378752e-05\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 6.0958e-04 - custom_f1: 0.9646 - val_loss: 0.2031 - val_custom_f1: 0.9366\n",
            "Epoch 28: lr: 9.999999747378752e-05\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 3.7229e-04 - custom_f1: 0.9823 - val_loss: 0.2063 - val_custom_f1: 0.9366\n",
            "Epoch 29: lr: 9.999999747378752e-05\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 2.3123e-04 - custom_f1: 0.9912 - val_loss: 0.1966 - val_custom_f1: 0.9366\n",
            "Epoch 30: lr: 9.999999747378752e-05\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 1.5762e-04 - custom_f1: 1.0000 - val_loss: 0.1998 - val_custom_f1: 0.9183\n",
            "Epoch 31: lr: 9.999999747378752e-05\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 5.6211e-04 - custom_f1: 0.9646 - val_loss: 0.2764 - val_custom_f1: 0.9555\n",
            "Epoch 32: lr: 9.999999747378752e-05\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 2.4641e-04 - custom_f1: 1.0000\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 227ms/step - loss: 2.4641e-04 - custom_f1: 1.0000 - val_loss: 0.1593 - val_custom_f1: 0.9366\n",
            "Epoch 33: lr: 9.999999747378752e-05\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 1.7217e-04 - custom_f1: 0.9912 - val_loss: 0.1632 - val_custom_f1: 0.9366\n",
            "Epoch 34: lr: 9.999999747378752e-05\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 1.6328e-04 - custom_f1: 0.9912 - val_loss: 0.1738 - val_custom_f1: 0.9183\n",
            "Epoch 35: lr: 9.999999747378752e-05\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 1.0944e-04 - custom_f1: 1.0000 - val_loss: 0.1795 - val_custom_f1: 0.9398\n",
            "Epoch 36: lr: 9.999999747378752e-05\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 9.1422e-05 - custom_f1: 1.0000 - val_loss: 0.1873 - val_custom_f1: 0.9398\n",
            "Epoch 37: lr: 9.999999747378752e-05\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 1.9796e-04 - custom_f1: 0.9735 - val_loss: 0.1807 - val_custom_f1: 0.9366\n",
            "Epoch 38: lr: 9.999999747378752e-05\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 1.4516e-04 - custom_f1: 0.9912 - val_loss: 0.1783 - val_custom_f1: 0.9366\n",
            "Epoch 39: lr: 9.999999747378752e-05\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 2.0678e-04 - custom_f1: 0.9735 - val_loss: 0.2027 - val_custom_f1: 0.9366\n",
            "Epoch 40: lr: 9.999999747378752e-05\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.6478e-04 - custom_f1: 0.9823 - val_loss: 0.1960 - val_custom_f1: 0.9366\n",
            "Epoch 41: lr: 9.999999747378752e-05\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 1.3484e-04 - custom_f1: 0.9823 - val_loss: 0.2019 - val_custom_f1: 0.9366\n",
            "Epoch 42: lr: 9.999999747378752e-05\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 1.0055e-04 - custom_f1: 0.9912 - val_loss: 0.2003 - val_custom_f1: 0.9183\n",
            "Epoch 43: lr: 9.999999747378752e-05\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.0202e-04 - custom_f1: 0.9912 - val_loss: 0.1912 - val_custom_f1: 0.9366\n",
            "Epoch 44: lr: 9.999999747378752e-05\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 1.2753e-04 - custom_f1: 0.9735 - val_loss: 0.1853 - val_custom_f1: 0.9366\n",
            "Epoch 45: lr: 9.999999747378752e-05\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 1.2144e-04 - custom_f1: 0.9646 - val_loss: 0.1977 - val_custom_f1: 0.9366\n",
            "Epoch 46: lr: 9.999999747378752e-05\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 8.5989e-05 - custom_f1: 0.9823 - val_loss: 0.1962 - val_custom_f1: 0.9183\n",
            "Epoch 47: lr: 9.999999747378752e-05\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 8.5474e-05 - custom_f1: 0.9823 - val_loss: 0.1916 - val_custom_f1: 0.9366\n",
            "Epoch 48: lr: 9.999999747378752e-05\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 8.3749e-05 - custom_f1: 0.9823 - val_loss: 0.1930 - val_custom_f1: 0.9366\n",
            "Epoch 49: lr: 9.999999747378752e-05\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 8.2102e-05 - custom_f1: 0.9646 - val_loss: 0.2031 - val_custom_f1: 0.9183\n",
            "Epoch 50: lr: 9.999999747378752e-05\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 8.3137e-05 - custom_f1: 0.9735 - val_loss: 0.2046 - val_custom_f1: 0.9183\n",
            "Epoch 51: lr: 9.999999747378752e-05\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 3.9917e-05 - custom_f1: 1.0000\n",
            "lr is fixed to 9.999999747378752e-06\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.9917e-05 - custom_f1: 1.0000 - val_loss: 0.1994 - val_custom_f1: 0.9183\n",
            "Epoch 52: lr: 9.999999747378752e-06\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 4.0725e-05 - custom_f1: 1.0000 - val_loss: 0.2004 - val_custom_f1: 0.9183\n",
            "Epoch 53: lr: 9.999999747378752e-06\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 8.8914e-05 - custom_f1: 0.9735 - val_loss: 0.2016 - val_custom_f1: 0.9183\n",
            "Epoch 54: lr: 9.999999747378752e-06\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 8.3516e-05 - custom_f1: 0.9646 - val_loss: 0.2019 - val_custom_f1: 0.9183\n",
            "Epoch 55: lr: 9.999999747378752e-06\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 5.1079e-05 - custom_f1: 0.9823 - val_loss: 0.2016 - val_custom_f1: 0.9183\n",
            "Epoch 56: lr: 9.999999747378752e-06\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 6.9159e-05 - custom_f1: 0.9735 - val_loss: 0.1991 - val_custom_f1: 0.9183\n",
            "Epoch 57: lr: 9.999999747378752e-06\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 5.3583e-05 - custom_f1: 0.9912 - val_loss: 0.1993 - val_custom_f1: 0.9183\n",
            "Epoch 58: lr: 9.999999747378752e-06\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 6.5553e-05 - custom_f1: 0.9823 - val_loss: 0.2009 - val_custom_f1: 0.9183\n",
            "Epoch 59: lr: 9.999999747378752e-06\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 6.9751e-05 - custom_f1: 0.9735 - val_loss: 0.2017 - val_custom_f1: 0.9183\n",
            "Epoch 60: lr: 9.999999747378752e-06\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 4.6759e-05 - custom_f1: 1.0000 - val_loss: 0.2009 - val_custom_f1: 0.9183\n",
            "Epoch 61: lr: 9.999999747378752e-06\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 3.6329e-05 - custom_f1: 1.0000 - val_loss: 0.2008 - val_custom_f1: 0.9183\n",
            "Epoch 62: lr: 9.999999747378752e-06\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 4.5840e-05 - custom_f1: 0.9912 - val_loss: 0.2018 - val_custom_f1: 0.9183\n",
            "Epoch 63: lr: 9.999999747378752e-06\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 6.0487e-05 - custom_f1: 0.9912 - val_loss: 0.2038 - val_custom_f1: 0.9183\n",
            "Epoch 64: lr: 9.999999747378752e-06\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 4.9618e-05 - custom_f1: 0.9912 - val_loss: 0.2037 - val_custom_f1: 0.9183\n",
            "Epoch 65: lr: 9.999999747378752e-06\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 4.8991e-05 - custom_f1: 0.9912 - val_loss: 0.2044 - val_custom_f1: 0.9183\n",
            "Epoch 66: lr: 9.999999747378752e-06\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 4.5369e-05 - custom_f1: 0.9912 - val_loss: 0.2028 - val_custom_f1: 0.9183\n",
            "Epoch 67: lr: 9.999999747378752e-06\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 4.8329e-05 - custom_f1: 0.9823 - val_loss: 0.2046 - val_custom_f1: 0.9183\n",
            "Epoch 68: lr: 9.999999747378752e-06\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 6.6229e-05 - custom_f1: 0.9735 - val_loss: 0.2046 - val_custom_f1: 0.9183\n",
            "Epoch 69: lr: 9.999999747378752e-06\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 5.8626e-05 - custom_f1: 0.9735 - val_loss: 0.2028 - val_custom_f1: 0.9183\n",
            "Epoch 70: lr: 9.999999747378752e-06\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 3.5887e-05 - custom_f1: 1.0000 - val_loss: 0.2032 - val_custom_f1: 0.9183\n",
            "Epoch 71: lr: 9.999999747378752e-06\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 5.6418e-05 - custom_f1: 0.9735 - val_loss: 0.2058 - val_custom_f1: 0.9183\n",
            "Epoch 72: lr: 9.999999747378752e-06\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 5.1909e-05 - custom_f1: 0.9823 - val_loss: 0.2065 - val_custom_f1: 0.9183\n",
            "Epoch 73: lr: 9.999999747378752e-06\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 6.3290e-05 - custom_f1: 0.9646 - val_loss: 0.2070 - val_custom_f1: 0.9183\n",
            "Epoch 74: lr: 9.999999747378752e-06\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 3.9841e-05 - custom_f1: 0.9912 - val_loss: 0.2055 - val_custom_f1: 0.9183\n",
            "Epoch 75: lr: 9.999999747378752e-06\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 5.8583e-05 - custom_f1: 0.9735 - val_loss: 0.2079 - val_custom_f1: 0.9183\n",
            "Epoch 76: lr: 9.999999747378752e-06\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 4.9275e-05 - custom_f1: 0.9735 - val_loss: 0.2072 - val_custom_f1: 0.9183\n",
            "Epoch 77: lr: 9.999999747378752e-06\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - 25s 221ms/step - loss: 3.0010e-05 - custom_f1: 1.0000 - val_loss: 0.2055 - val_custom_f1: 0.9183\n",
            "Epoch 78: lr: 9.999999747378752e-06\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 3.2638e-05 - custom_f1: 1.0000 - val_loss: 0.2067 - val_custom_f1: 0.9183\n",
            "Epoch 79: lr: 9.999999747378752e-06\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 5.7535e-05 - custom_f1: 0.9735 - val_loss: 0.2093 - val_custom_f1: 0.9183\n",
            "Epoch 80: lr: 9.999999747378752e-06\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 3.7318e-05 - custom_f1: 0.9823 - val_loss: 0.2096 - val_custom_f1: 0.9183\n",
            "Epoch 81: lr: 9.999999747378752e-06\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 3.1173e-05 - custom_f1: 0.9912 - val_loss: 0.2085 - val_custom_f1: 0.9183\n",
            "Epoch 82: lr: 9.999999747378752e-06\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 2.7777e-05 - custom_f1: 1.0000 - val_loss: 0.2082 - val_custom_f1: 0.9183\n",
            "Epoch 83: lr: 9.999999747378752e-06\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 5.0925e-05 - custom_f1: 0.9912 - val_loss: 0.2101 - val_custom_f1: 0.9183\n",
            "Epoch 84: lr: 9.999999747378752e-06\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 3.1155e-05 - custom_f1: 0.9912 - val_loss: 0.2108 - val_custom_f1: 0.9183\n",
            "Epoch 85: lr: 9.999999747378752e-06\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 3.6337e-05 - custom_f1: 0.9823 - val_loss: 0.2131 - val_custom_f1: 0.9183\n",
            "Epoch 86: lr: 9.999999747378752e-06\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 3.7571e-05 - custom_f1: 0.9823 - val_loss: 0.2152 - val_custom_f1: 0.9183\n",
            "Epoch 87: lr: 9.999999747378752e-06\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 3.9183e-05 - custom_f1: 0.9823 - val_loss: 0.2152 - val_custom_f1: 0.9183\n",
            "Epoch 88: lr: 9.999999747378752e-06\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 4.5211e-05 - custom_f1: 0.9735 - val_loss: 0.2115 - val_custom_f1: 0.9183\n",
            "Epoch 89: lr: 9.999999747378752e-06\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 4.0142e-05 - custom_f1: 0.9735 - val_loss: 0.2137 - val_custom_f1: 0.9183\n",
            "Epoch 90: lr: 9.999999747378752e-06\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 4.4938e-05 - custom_f1: 0.9735 - val_loss: 0.2110 - val_custom_f1: 0.9183\n",
            "Epoch 91: lr: 9.999999747378752e-06\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 2.8611e-05 - custom_f1: 0.9912 - val_loss: 0.2111 - val_custom_f1: 0.9183\n",
            "Epoch 92: lr: 9.999999747378752e-06\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 3.3265e-05 - custom_f1: 0.9823 - val_loss: 0.2138 - val_custom_f1: 0.9183\n",
            "Epoch 93: lr: 9.999999747378752e-06\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 1.9354e-05 - custom_f1: 1.0000 - val_loss: 0.2145 - val_custom_f1: 0.9183\n",
            "Epoch 94: lr: 9.999999747378752e-06\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 2.3534e-05 - custom_f1: 1.0000 - val_loss: 0.2151 - val_custom_f1: 0.9081\n",
            "Epoch 95: lr: 9.999999747378752e-06\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 3.5370e-05 - custom_f1: 0.9735 - val_loss: 0.2184 - val_custom_f1: 0.9183\n",
            "Epoch 96: lr: 9.999999747378752e-06\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 2.9848e-05 - custom_f1: 0.9823 - val_loss: 0.2176 - val_custom_f1: 0.9183\n",
            "Epoch 97: lr: 9.999999747378752e-06\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 2.8987e-05 - custom_f1: 0.9823 - val_loss: 0.2222 - val_custom_f1: 0.9183\n",
            "Epoch 98: lr: 9.999999747378752e-06\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 2.4085e-05 - custom_f1: 0.9823 - val_loss: 0.2188 - val_custom_f1: 0.9183\n",
            "Epoch 99: lr: 9.999999747378752e-06\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 3.2913e-05 - custom_f1: 0.9735 - val_loss: 0.2213 - val_custom_f1: 0.9183\n",
            "Epoch 100: lr: 9.999999747378752e-06\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 2.0268e-05 - custom_f1: 0.9912 - val_loss: 0.2216 - val_custom_f1: 0.9183\n",
            "weights are setted to best weights (epochs 32)\n",
            "fold 4 [150,200]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "  6/113 [>.............................] - ETA: 22s - loss: 0.6937 - custom_f1: 0.5056WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0450s vs `on_train_batch_end` time: 0.1675s). Check your callbacks.\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.5564 - custom_f1: 0.7713\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 25s 222ms/step - loss: 0.5564 - custom_f1: 0.7713 - val_loss: 0.7050 - val_custom_f1: 0.0000e+00\n",
            "Epoch 2: lr: 9.999999747378752e-05\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.4142 - custom_f1: 0.8521\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 226ms/step - loss: 0.4142 - custom_f1: 0.8521 - val_loss: 0.6648 - val_custom_f1: 0.8179\n",
            "Epoch 3: lr: 9.999999747378752e-05\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.2824 - custom_f1: 0.8921\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 228ms/step - loss: 0.2824 - custom_f1: 0.8921 - val_loss: 0.6015 - val_custom_f1: 0.8179\n",
            "Epoch 4: lr: 9.999999747378752e-05\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 0.2484 - custom_f1: 0.9140 - val_loss: 0.7323 - val_custom_f1: 0.0000e+00\n",
            "Epoch 5: lr: 9.999999747378752e-05\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1309 - custom_f1: 0.9590\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 230ms/step - loss: 0.1309 - custom_f1: 0.9590 - val_loss: 0.5301 - val_custom_f1: 0.8179\n",
            "Epoch 6: lr: 9.999999747378752e-05\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 0.0809 - custom_f1: 0.9737 - val_loss: 0.5464 - val_custom_f1: 0.8339\n",
            "Epoch 7: lr: 9.999999747378752e-05\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1140 - custom_f1: 0.9713\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 227ms/step - loss: 0.1140 - custom_f1: 0.9713 - val_loss: 0.2651 - val_custom_f1: 0.9038\n",
            "Epoch 8: lr: 9.999999747378752e-05\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 0.0986 - custom_f1: 0.9654 - val_loss: 0.2705 - val_custom_f1: 0.9327\n",
            "Epoch 9: lr: 9.999999747378752e-05\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 0.0365 - custom_f1: 0.9899 - val_loss: 0.4864 - val_custom_f1: 0.8808\n",
            "Epoch 10: lr: 9.999999747378752e-05\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 0.0326 - custom_f1: 0.9899 - val_loss: 0.5135 - val_custom_f1: 0.9208\n",
            "Epoch 11: lr: 9.999999747378752e-05\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 0.0209 - custom_f1: 0.9912 - val_loss: 0.3248 - val_custom_f1: 0.9391\n",
            "Epoch 12: lr: 9.999999747378752e-05\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 0.0513 - custom_f1: 0.9680 - val_loss: 0.4627 - val_custom_f1: 0.9038\n",
            "Epoch 13: lr: 9.999999747378752e-05\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 0.0077 - custom_f1: 1.0000 - val_loss: 0.3211 - val_custom_f1: 0.9208\n",
            "Epoch 14: lr: 9.999999747378752e-05\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0086 - custom_f1: 0.9912\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 226ms/step - loss: 0.0086 - custom_f1: 0.9912 - val_loss: 0.1958 - val_custom_f1: 0.9181\n",
            "Epoch 15: lr: 9.999999747378752e-05\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 0.0258 - custom_f1: 0.9835 - val_loss: 0.7612 - val_custom_f1: 0.7119\n",
            "Epoch 16: lr: 9.999999747378752e-05\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 0.0509 - custom_f1: 0.9734 - val_loss: 0.2535 - val_custom_f1: 0.8869\n",
            "Epoch 17: lr: 9.999999747378752e-05\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0200 - custom_f1: 0.9899\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 229ms/step - loss: 0.0200 - custom_f1: 0.9899 - val_loss: 0.1265 - val_custom_f1: 0.9800\n",
            "Epoch 18: lr: 9.999999747378752e-05\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 0.0358 - custom_f1: 0.9705 - val_loss: 0.6052 - val_custom_f1: 0.8558\n",
            "Epoch 19: lr: 9.999999747378752e-05\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 0.0298 - custom_f1: 0.9658 - val_loss: 0.2796 - val_custom_f1: 0.9391\n",
            "Epoch 20: lr: 9.999999747378752e-05\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 0.0125 - custom_f1: 0.9882 - val_loss: 0.4957 - val_custom_f1: 0.9117\n",
            "Epoch 21: lr: 9.999999747378752e-05\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 0.0027 - custom_f1: 0.9912 - val_loss: 0.2835 - val_custom_f1: 0.9208\n",
            "Epoch 22: lr: 9.999999747378752e-05\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 0.0013 - custom_f1: 1.0000 - val_loss: 0.1730 - val_custom_f1: 0.9685\n",
            "Epoch 23: lr: 9.999999747378752e-05\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 0.0017 - custom_f1: 0.9823 - val_loss: 0.1418 - val_custom_f1: 0.9685\n",
            "Epoch 24: lr: 9.999999747378752e-05\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 0.0015 - custom_f1: 0.9823 - val_loss: 0.1341 - val_custom_f1: 0.9574\n",
            "Epoch 25: lr: 9.999999747378752e-05\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 9.3075e-04 - custom_f1: 1.0000 - val_loss: 0.1380 - val_custom_f1: 0.9583\n",
            "Epoch 26: lr: 9.999999747378752e-05\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 0.0012 - custom_f1: 0.9823 - val_loss: 0.1457 - val_custom_f1: 0.9685\n",
            "Epoch 27: lr: 9.999999747378752e-05\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 5.7117e-04 - custom_f1: 0.9912 - val_loss: 0.1360 - val_custom_f1: 0.9685\n",
            "Epoch 28: lr: 9.999999747378752e-05\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 4.6320e-04 - custom_f1: 0.9912 - val_loss: 0.1269 - val_custom_f1: 0.9476\n",
            "Epoch 29: lr: 9.999999747378752e-05\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 8.2945e-04 - custom_f1: 0.9646 - val_loss: 0.2325 - val_custom_f1: 0.9443\n",
            "Epoch 30: lr: 9.999999747378752e-05\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 7.7258e-04 - custom_f1: 0.9912 - val_loss: 0.1428 - val_custom_f1: 0.9476\n",
            "Epoch 31: lr: 9.999999747378752e-05\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 7.1955e-04 - custom_f1: 0.9735\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 226ms/step - loss: 7.1955e-04 - custom_f1: 0.9735 - val_loss: 0.1248 - val_custom_f1: 0.9574\n",
            "Epoch 32: lr: 9.999999747378752e-05\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 4.2677e-04 - custom_f1: 0.9558 - val_loss: 0.1262 - val_custom_f1: 0.9476\n",
            "Epoch 33: lr: 9.999999747378752e-05\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 2.1943e-04 - custom_f1: 1.0000 - val_loss: 0.1296 - val_custom_f1: 0.9476\n",
            "Epoch 34: lr: 9.999999747378752e-05\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 1.7174e-04 - custom_f1: 1.0000 - val_loss: 0.1308 - val_custom_f1: 0.9476\n",
            "Epoch 35: lr: 9.999999747378752e-05\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 2.3856e-04 - custom_f1: 0.9912 - val_loss: 0.1293 - val_custom_f1: 0.9583\n",
            "Epoch 36: lr: 9.999999747378752e-05\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 1.7618e-04 - custom_f1: 0.9912 - val_loss: 0.1281 - val_custom_f1: 0.9476\n",
            "Epoch 37: lr: 9.999999747378752e-05\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 2.6894e-04 - custom_f1: 0.9912 - val_loss: 0.1338 - val_custom_f1: 0.9476\n",
            "Epoch 38: lr: 9.999999747378752e-05\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 2.0891e-04 - custom_f1: 0.9735 - val_loss: 0.1379 - val_custom_f1: 0.9476\n",
            "Epoch 39: lr: 9.999999747378752e-05\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 1.3341e-04 - custom_f1: 0.9912 - val_loss: 0.1402 - val_custom_f1: 0.9476\n",
            "Epoch 40: lr: 9.999999747378752e-05\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 1.1342e-04 - custom_f1: 1.0000 - val_loss: 0.1398 - val_custom_f1: 0.9476\n",
            "Epoch 41: lr: 9.999999747378752e-05\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 1.2296e-04 - custom_f1: 0.9912 - val_loss: 0.1395 - val_custom_f1: 0.9476\n",
            "Epoch 42: lr: 9.999999747378752e-05\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 1.2411e-04 - custom_f1: 0.9823 - val_loss: 0.1395 - val_custom_f1: 0.9476\n",
            "Epoch 43: lr: 9.999999747378752e-05\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 1.2200e-04 - custom_f1: 0.9912 - val_loss: 0.1313 - val_custom_f1: 0.9574\n",
            "Epoch 44: lr: 9.999999747378752e-05\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 1.1654e-04 - custom_f1: 0.9912 - val_loss: 0.1322 - val_custom_f1: 0.9574\n",
            "Epoch 45: lr: 9.999999747378752e-05\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 7.9486e-05 - custom_f1: 1.0000 - val_loss: 0.1338 - val_custom_f1: 0.9574\n",
            "Epoch 46: lr: 9.999999747378752e-05\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 7.2930e-05 - custom_f1: 1.0000 - val_loss: 0.1377 - val_custom_f1: 0.9476\n",
            "Epoch 47: lr: 9.999999747378752e-05\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 9.8487e-05 - custom_f1: 0.9823 - val_loss: 0.1381 - val_custom_f1: 0.9574\n",
            "Epoch 48: lr: 9.999999747378752e-05\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 1.4933e-04 - custom_f1: 0.9735 - val_loss: 0.1392 - val_custom_f1: 0.9574\n",
            "Epoch 49: lr: 9.999999747378752e-05\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 7.3139e-05 - custom_f1: 0.9912 - val_loss: 0.1442 - val_custom_f1: 0.9574\n",
            "Epoch 50: lr: 9.999999747378752e-05\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 8.1255e-05 - custom_f1: 0.9912 - val_loss: 0.1446 - val_custom_f1: 0.9574\n",
            "Epoch 51: lr: 9.999999747378752e-05\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 6.7107e-05 - custom_f1: 0.9912\n",
            "lr is fixed to 9.999999747378752e-06\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 6.7107e-05 - custom_f1: 0.9912 - val_loss: 0.1457 - val_custom_f1: 0.9574\n",
            "Epoch 52: lr: 9.999999747378752e-06\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 6.8947e-05 - custom_f1: 0.9912 - val_loss: 0.1452 - val_custom_f1: 0.9574\n",
            "Epoch 53: lr: 9.999999747378752e-06\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 4.6715e-05 - custom_f1: 1.0000 - val_loss: 0.1451 - val_custom_f1: 0.9574\n",
            "Epoch 54: lr: 9.999999747378752e-06\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 8.6622e-05 - custom_f1: 0.9823 - val_loss: 0.1438 - val_custom_f1: 0.9574\n",
            "Epoch 55: lr: 9.999999747378752e-06\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 7.3531e-05 - custom_f1: 0.9823 - val_loss: 0.1440 - val_custom_f1: 0.9574\n",
            "Epoch 56: lr: 9.999999747378752e-06\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 7.5615e-05 - custom_f1: 0.9823 - val_loss: 0.1441 - val_custom_f1: 0.9574\n",
            "Epoch 57: lr: 9.999999747378752e-06\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 8.9723e-05 - custom_f1: 0.9735 - val_loss: 0.1441 - val_custom_f1: 0.9574\n",
            "Epoch 58: lr: 9.999999747378752e-06\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 8.1940e-05 - custom_f1: 0.9735 - val_loss: 0.1435 - val_custom_f1: 0.9574\n",
            "Epoch 59: lr: 9.999999747378752e-06\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 5.9490e-05 - custom_f1: 0.9912 - val_loss: 0.1435 - val_custom_f1: 0.9574\n",
            "Epoch 60: lr: 9.999999747378752e-06\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 4.1605e-05 - custom_f1: 1.0000 - val_loss: 0.1434 - val_custom_f1: 0.9574\n",
            "Epoch 61: lr: 9.999999747378752e-06\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 6.0531e-05 - custom_f1: 0.9912 - val_loss: 0.1435 - val_custom_f1: 0.9574\n",
            "Epoch 62: lr: 9.999999747378752e-06\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 1.1750e-04 - custom_f1: 0.9735 - val_loss: 0.1439 - val_custom_f1: 0.9574\n",
            "Epoch 63: lr: 9.999999747378752e-06\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 5.5150e-05 - custom_f1: 0.9912 - val_loss: 0.1455 - val_custom_f1: 0.9574\n",
            "Epoch 64: lr: 9.999999747378752e-06\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 5.7244e-05 - custom_f1: 0.9912 - val_loss: 0.1463 - val_custom_f1: 0.9574\n",
            "Epoch 65: lr: 9.999999747378752e-06\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 4.6831e-05 - custom_f1: 0.9912 - val_loss: 0.1464 - val_custom_f1: 0.9574\n",
            "Epoch 66: lr: 9.999999747378752e-06\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 4.7460e-05 - custom_f1: 0.9912 - val_loss: 0.1466 - val_custom_f1: 0.9574\n",
            "Epoch 67: lr: 9.999999747378752e-06\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 7.1466e-05 - custom_f1: 0.9735 - val_loss: 0.1474 - val_custom_f1: 0.9574\n",
            "Epoch 68: lr: 9.999999747378752e-06\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 3.9347e-05 - custom_f1: 1.0000 - val_loss: 0.1463 - val_custom_f1: 0.9574\n",
            "Epoch 69: lr: 9.999999747378752e-06\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 4.9326e-05 - custom_f1: 0.9912 - val_loss: 0.1467 - val_custom_f1: 0.9574\n",
            "Epoch 70: lr: 9.999999747378752e-06\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 6.2072e-05 - custom_f1: 0.9823 - val_loss: 0.1468 - val_custom_f1: 0.9476\n",
            "Epoch 71: lr: 9.999999747378752e-06\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 5.2483e-05 - custom_f1: 0.9912 - val_loss: 0.1469 - val_custom_f1: 0.9574\n",
            "Epoch 72: lr: 9.999999747378752e-06\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 9.2885e-05 - custom_f1: 0.9735 - val_loss: 0.1501 - val_custom_f1: 0.9574\n",
            "Epoch 73: lr: 9.999999747378752e-06\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 8.9556e-05 - custom_f1: 0.9646 - val_loss: 0.1560 - val_custom_f1: 0.9574\n",
            "Epoch 74: lr: 9.999999747378752e-06\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 6.4901e-05 - custom_f1: 0.9823 - val_loss: 0.1579 - val_custom_f1: 0.9574\n",
            "Epoch 75: lr: 9.999999747378752e-06\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 2.9767e-05 - custom_f1: 1.0000 - val_loss: 0.1577 - val_custom_f1: 0.9574\n",
            "Epoch 76: lr: 9.999999747378752e-06\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 4.4153e-05 - custom_f1: 1.0000 - val_loss: 0.1566 - val_custom_f1: 0.9574\n",
            "Epoch 77: lr: 9.999999747378752e-06\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 3.2403e-05 - custom_f1: 1.0000 - val_loss: 0.1549 - val_custom_f1: 0.9574\n",
            "Epoch 78: lr: 9.999999747378752e-06\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 3.8522e-05 - custom_f1: 1.0000 - val_loss: 0.1541 - val_custom_f1: 0.9574\n",
            "Epoch 79: lr: 9.999999747378752e-06\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 4.8887e-05 - custom_f1: 0.9912 - val_loss: 0.1546 - val_custom_f1: 0.9574\n",
            "Epoch 80: lr: 9.999999747378752e-06\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 5.9208e-05 - custom_f1: 0.9912 - val_loss: 0.1544 - val_custom_f1: 0.9574\n",
            "Epoch 81: lr: 9.999999747378752e-06\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 4.1212e-05 - custom_f1: 0.9912 - val_loss: 0.1585 - val_custom_f1: 0.9574\n",
            "Epoch 82: lr: 9.999999747378752e-06\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 3.3075e-05 - custom_f1: 1.0000 - val_loss: 0.1582 - val_custom_f1: 0.9574\n",
            "Epoch 83: lr: 9.999999747378752e-06\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 5.6583e-05 - custom_f1: 0.9735 - val_loss: 0.1596 - val_custom_f1: 0.9574\n",
            "Epoch 84: lr: 9.999999747378752e-06\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 3.4064e-05 - custom_f1: 1.0000 - val_loss: 0.1582 - val_custom_f1: 0.9574\n",
            "Epoch 85: lr: 9.999999747378752e-06\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 6.5182e-05 - custom_f1: 0.9646 - val_loss: 0.1591 - val_custom_f1: 0.9574\n",
            "Epoch 86: lr: 9.999999747378752e-06\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 3.6263e-05 - custom_f1: 0.9912 - val_loss: 0.1587 - val_custom_f1: 0.9574\n",
            "Epoch 87: lr: 9.999999747378752e-06\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 4.0562e-05 - custom_f1: 0.9823 - val_loss: 0.1581 - val_custom_f1: 0.9574\n",
            "Epoch 88: lr: 9.999999747378752e-06\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 4.5259e-05 - custom_f1: 0.9823 - val_loss: 0.1576 - val_custom_f1: 0.9574\n",
            "Epoch 89: lr: 9.999999747378752e-06\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 2.5863e-05 - custom_f1: 1.0000 - val_loss: 0.1574 - val_custom_f1: 0.9574\n",
            "Epoch 90: lr: 9.999999747378752e-06\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 5.6993e-05 - custom_f1: 0.9646 - val_loss: 0.1576 - val_custom_f1: 0.9574\n",
            "Epoch 91: lr: 9.999999747378752e-06\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 3.3701e-05 - custom_f1: 0.9912 - val_loss: 0.1575 - val_custom_f1: 0.9574\n",
            "Epoch 92: lr: 9.999999747378752e-06\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 3.1185e-05 - custom_f1: 0.9912 - val_loss: 0.1580 - val_custom_f1: 0.9574\n",
            "Epoch 93: lr: 9.999999747378752e-06\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 5.3277e-05 - custom_f1: 0.9646 - val_loss: 0.1588 - val_custom_f1: 0.9574\n",
            "Epoch 94: lr: 9.999999747378752e-06\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 3.3039e-05 - custom_f1: 0.9823 - val_loss: 0.1589 - val_custom_f1: 0.9574\n",
            "Epoch 95: lr: 9.999999747378752e-06\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 3.3623e-05 - custom_f1: 0.9823 - val_loss: 0.1593 - val_custom_f1: 0.9574\n",
            "Epoch 96: lr: 9.999999747378752e-06\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 2.0173e-05 - custom_f1: 1.0000 - val_loss: 0.1590 - val_custom_f1: 0.9574\n",
            "Epoch 97: lr: 9.999999747378752e-06\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 2.9683e-05 - custom_f1: 0.9823 - val_loss: 0.1598 - val_custom_f1: 0.9574\n",
            "Epoch 98: lr: 9.999999747378752e-06\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 4.1805e-05 - custom_f1: 0.9646 - val_loss: 0.1634 - val_custom_f1: 0.9574\n",
            "Epoch 99: lr: 9.999999747378752e-06\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 3.4574e-05 - custom_f1: 0.9735 - val_loss: 0.1617 - val_custom_f1: 0.9574\n",
            "Epoch 100: lr: 9.999999747378752e-06\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 1.8479e-05 - custom_f1: 1.0000 - val_loss: 0.1597 - val_custom_f1: 0.9574\n",
            "weights are setted to best weights (epochs 31)\n",
            "fold 5 [200,250]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "  6/113 [>.............................] - ETA: 23s - loss: 0.6522 - custom_f1: 0.7222WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0454s vs `on_train_batch_end` time: 0.1702s). Check your callbacks.\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.5804 - custom_f1: 0.7929\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 25s 225ms/step - loss: 0.5804 - custom_f1: 0.7929 - val_loss: 0.6785 - val_custom_f1: 0.7639\n",
            "Epoch 2: lr: 9.999999747378752e-05\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.4035 - custom_f1: 0.8399\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 229ms/step - loss: 0.4035 - custom_f1: 0.8399 - val_loss: 0.6652 - val_custom_f1: 0.7639\n",
            "Epoch 3: lr: 9.999999747378752e-05\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 0.2519 - custom_f1: 0.9109 - val_loss: 0.6662 - val_custom_f1: 0.7639\n",
            "Epoch 4: lr: 9.999999747378752e-05\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1733 - custom_f1: 0.9366\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 229ms/step - loss: 0.1733 - custom_f1: 0.9366 - val_loss: 0.6651 - val_custom_f1: 0.7639\n",
            "Epoch 5: lr: 9.999999747378752e-05\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - 25s 221ms/step - loss: 0.1264 - custom_f1: 0.9598 - val_loss: 0.6968 - val_custom_f1: 0.7639\n",
            "Epoch 6: lr: 9.999999747378752e-05\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 0.0833 - custom_f1: 0.9767 - val_loss: 0.6925 - val_custom_f1: 0.7793\n",
            "Epoch 7: lr: 9.999999747378752e-05\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 0.0266 - custom_f1: 0.9894 - val_loss: 0.7314 - val_custom_f1: 0.8474\n",
            "Epoch 8: lr: 9.999999747378752e-05\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0131 - custom_f1: 0.9971\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 230ms/step - loss: 0.0131 - custom_f1: 0.9971 - val_loss: 0.4019 - val_custom_f1: 0.8900\n",
            "Epoch 9: lr: 9.999999747378752e-05\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 0.0262 - custom_f1: 0.9863 - val_loss: 0.7896 - val_custom_f1: 0.8373\n",
            "Epoch 10: lr: 9.999999747378752e-05\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 0.0118 - custom_f1: 0.9912 - val_loss: 0.4275 - val_custom_f1: 0.8924\n",
            "Epoch 11: lr: 9.999999747378752e-05\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 0.0187 - custom_f1: 0.9705 - val_loss: 0.4875 - val_custom_f1: 0.9002\n",
            "Epoch 12: lr: 9.999999747378752e-05\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 0.0056 - custom_f1: 0.9823 - val_loss: 0.7323 - val_custom_f1: 0.8806\n",
            "Epoch 13: lr: 9.999999747378752e-05\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 0.0035 - custom_f1: 0.9823 - val_loss: 0.4967 - val_custom_f1: 0.8432\n",
            "Epoch 14: lr: 9.999999747378752e-05\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 0.0013 - custom_f1: 0.9912 - val_loss: 0.5508 - val_custom_f1: 0.8869\n",
            "Epoch 15: lr: 9.999999747378752e-05\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 9.8647e-04 - custom_f1: 0.9735 - val_loss: 0.5479 - val_custom_f1: 0.8634\n",
            "Epoch 16: lr: 9.999999747378752e-05\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 9.8448e-04 - custom_f1: 0.9823 - val_loss: 0.5280 - val_custom_f1: 0.8432\n",
            "Epoch 17: lr: 9.999999747378752e-05\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 4.6745e-04 - custom_f1: 0.9912 - val_loss: 0.6039 - val_custom_f1: 0.8869\n",
            "Epoch 18: lr: 9.999999747378752e-05\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 4.4343e-04 - custom_f1: 0.9823 - val_loss: 0.6022 - val_custom_f1: 0.8869\n",
            "Epoch 19: lr: 9.999999747378752e-05\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - 25s 221ms/step - loss: 2.3091e-04 - custom_f1: 0.9912 - val_loss: 0.6042 - val_custom_f1: 0.8869\n",
            "Epoch 20: lr: 9.999999747378752e-05\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 2.5755e-04 - custom_f1: 0.9912 - val_loss: 0.6228 - val_custom_f1: 0.8869\n",
            "Epoch 21: lr: 9.999999747378752e-05\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 2.3141e-04 - custom_f1: 0.9912 - val_loss: 0.6439 - val_custom_f1: 0.8769\n",
            "Epoch 22: lr: 9.999999747378752e-05\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - 25s 221ms/step - loss: 1.8067e-04 - custom_f1: 0.9912 - val_loss: 0.6342 - val_custom_f1: 0.8869\n",
            "Epoch 23: lr: 9.999999747378752e-05\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 0.0268 - custom_f1: 0.9781 - val_loss: 10.4701 - val_custom_f1: 0.7639\n",
            "Epoch 24: lr: 9.999999747378752e-05\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 0.0804 - custom_f1: 0.9833 - val_loss: 1.1054 - val_custom_f1: 0.4396\n",
            "Epoch 25: lr: 9.999999747378752e-05\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 0.0649 - custom_f1: 0.9733 - val_loss: 0.5014 - val_custom_f1: 0.7947\n",
            "Epoch 26: lr: 9.999999747378752e-05\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 0.0821 - custom_f1: 0.9624 - val_loss: 0.4496 - val_custom_f1: 0.7698\n",
            "Epoch 27: lr: 9.999999747378752e-05\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 0.0512 - custom_f1: 0.9578 - val_loss: 0.9530 - val_custom_f1: 0.7035\n",
            "Epoch 28: lr: 9.999999747378752e-05\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0080 - custom_f1: 0.9823 - val_loss: 0.4631 - val_custom_f1: 0.8637\n",
            "Epoch 29: lr: 9.999999747378752e-05\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0015 - custom_f1: 0.9823 - val_loss: 0.4664 - val_custom_f1: 0.8637\n",
            "Epoch 30: lr: 9.999999747378752e-05\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 7.0125e-04 - custom_f1: 1.0000 - val_loss: 0.4666 - val_custom_f1: 0.8611\n",
            "Epoch 31: lr: 9.999999747378752e-05\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - 25s 221ms/step - loss: 6.1289e-04 - custom_f1: 0.9823 - val_loss: 0.4768 - val_custom_f1: 0.8759\n",
            "Epoch 32: lr: 9.999999747378752e-05\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 5.3541e-04 - custom_f1: 0.9735 - val_loss: 0.4841 - val_custom_f1: 0.8759\n",
            "Epoch 33: lr: 9.999999747378752e-05\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 2.7868e-04 - custom_f1: 0.9912 - val_loss: 0.4906 - val_custom_f1: 0.8611\n",
            "Epoch 34: lr: 9.999999747378752e-05\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 3.5646e-04 - custom_f1: 0.9735 - val_loss: 0.4929 - val_custom_f1: 0.8759\n",
            "Epoch 35: lr: 9.999999747378752e-05\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 2.4974e-04 - custom_f1: 0.9912 - val_loss: 0.4994 - val_custom_f1: 0.8900\n",
            "Epoch 36: lr: 9.999999747378752e-05\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 1.7454e-04 - custom_f1: 0.9912 - val_loss: 0.5041 - val_custom_f1: 0.8900\n",
            "Epoch 37: lr: 9.999999747378752e-05\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 2.6420e-04 - custom_f1: 0.9823 - val_loss: 0.5049 - val_custom_f1: 0.8900\n",
            "Epoch 38: lr: 9.999999747378752e-05\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 1.5760e-04 - custom_f1: 1.0000 - val_loss: 0.5110 - val_custom_f1: 0.8900\n",
            "Epoch 39: lr: 9.999999747378752e-05\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 1.9858e-04 - custom_f1: 0.9735 - val_loss: 0.5129 - val_custom_f1: 0.8900\n",
            "Epoch 40: lr: 9.999999747378752e-05\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 1.4129e-04 - custom_f1: 0.9823 - val_loss: 0.5133 - val_custom_f1: 0.8900\n",
            "Epoch 41: lr: 9.999999747378752e-05\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 2.7513e-04 - custom_f1: 0.9735 - val_loss: 0.5198 - val_custom_f1: 0.8611\n",
            "Epoch 42: lr: 9.999999747378752e-05\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 1.4129e-04 - custom_f1: 0.9735 - val_loss: 0.5225 - val_custom_f1: 0.8611\n",
            "Epoch 43: lr: 9.999999747378752e-05\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 1.1181e-04 - custom_f1: 0.9912 - val_loss: 0.5280 - val_custom_f1: 0.8759\n",
            "Epoch 44: lr: 9.999999747378752e-05\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 1.1636e-04 - custom_f1: 0.9912 - val_loss: 0.5304 - val_custom_f1: 0.8759\n",
            "Epoch 45: lr: 9.999999747378752e-05\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 1.0401e-04 - custom_f1: 0.9912 - val_loss: 0.5355 - val_custom_f1: 0.8759\n",
            "Epoch 46: lr: 9.999999747378752e-05\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 9.5544e-05 - custom_f1: 0.9912 - val_loss: 0.5391 - val_custom_f1: 0.8759\n",
            "Epoch 47: lr: 9.999999747378752e-05\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 8.6368e-05 - custom_f1: 0.9823 - val_loss: 0.5456 - val_custom_f1: 0.8759\n",
            "Epoch 48: lr: 9.999999747378752e-05\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 6.8803e-05 - custom_f1: 1.0000 - val_loss: 0.5509 - val_custom_f1: 0.8900\n",
            "Epoch 49: lr: 9.999999747378752e-05\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 25s 221ms/step - loss: 7.7140e-05 - custom_f1: 0.9823 - val_loss: 0.5554 - val_custom_f1: 0.8900\n",
            "Epoch 50: lr: 9.999999747378752e-05\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 8.5151e-05 - custom_f1: 0.9735 - val_loss: 0.5548 - val_custom_f1: 0.8900\n",
            "Epoch 51: lr: 9.999999747378752e-05\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 5.6001e-05 - custom_f1: 1.0000\n",
            "lr is fixed to 9.999999747378752e-06\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 5.6001e-05 - custom_f1: 1.0000 - val_loss: 0.5573 - val_custom_f1: 0.8900\n",
            "Epoch 52: lr: 9.999999747378752e-06\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 9.8903e-05 - custom_f1: 0.9646 - val_loss: 0.5631 - val_custom_f1: 0.8900\n",
            "Epoch 53: lr: 9.999999747378752e-06\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 4.8802e-05 - custom_f1: 0.9912 - val_loss: 0.5606 - val_custom_f1: 0.8900\n",
            "Epoch 54: lr: 9.999999747378752e-06\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 3.6321e-05 - custom_f1: 1.0000 - val_loss: 0.5606 - val_custom_f1: 0.8900\n",
            "Epoch 55: lr: 9.999999747378752e-06\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 5.7731e-05 - custom_f1: 0.9912 - val_loss: 0.5635 - val_custom_f1: 0.8900\n",
            "Epoch 56: lr: 9.999999747378752e-06\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 8.5036e-05 - custom_f1: 0.9735 - val_loss: 0.5641 - val_custom_f1: 0.8900\n",
            "Epoch 57: lr: 9.999999747378752e-06\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 4.9381e-05 - custom_f1: 1.0000 - val_loss: 0.5608 - val_custom_f1: 0.8900\n",
            "Epoch 58: lr: 9.999999747378752e-06\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - 25s 221ms/step - loss: 4.9410e-05 - custom_f1: 0.9912 - val_loss: 0.5641 - val_custom_f1: 0.8900\n",
            "Epoch 59: lr: 9.999999747378752e-06\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 9.1908e-05 - custom_f1: 0.9823 - val_loss: 0.5612 - val_custom_f1: 0.8900\n",
            "Epoch 60: lr: 9.999999747378752e-06\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 8.7059e-05 - custom_f1: 0.9823 - val_loss: 0.5628 - val_custom_f1: 0.8900\n",
            "Epoch 61: lr: 9.999999747378752e-06\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - 25s 221ms/step - loss: 4.8730e-05 - custom_f1: 0.9912 - val_loss: 0.5614 - val_custom_f1: 0.8900\n",
            "Epoch 62: lr: 9.999999747378752e-06\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 5.9103e-05 - custom_f1: 0.9912 - val_loss: 0.5612 - val_custom_f1: 0.8900\n",
            "Epoch 63: lr: 9.999999747378752e-06\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 6.9823e-05 - custom_f1: 0.9735 - val_loss: 0.5621 - val_custom_f1: 0.8900\n",
            "Epoch 64: lr: 9.999999747378752e-06\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 5.3974e-05 - custom_f1: 0.9912 - val_loss: 0.5654 - val_custom_f1: 0.8900\n",
            "Epoch 65: lr: 9.999999747378752e-06\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 5.2180e-05 - custom_f1: 1.0000 - val_loss: 0.5667 - val_custom_f1: 0.8900\n",
            "Epoch 66: lr: 9.999999747378752e-06\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 5.5533e-05 - custom_f1: 0.9912 - val_loss: 0.5655 - val_custom_f1: 0.8900\n",
            "Epoch 67: lr: 9.999999747378752e-06\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - 25s 221ms/step - loss: 4.8539e-05 - custom_f1: 0.9912 - val_loss: 0.5663 - val_custom_f1: 0.8900\n",
            "Epoch 68: lr: 9.999999747378752e-06\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 5.5368e-05 - custom_f1: 0.9823 - val_loss: 0.5657 - val_custom_f1: 0.8900\n",
            "Epoch 69: lr: 9.999999747378752e-06\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 5.0447e-05 - custom_f1: 0.9912 - val_loss: 0.5667 - val_custom_f1: 0.8900\n",
            "Epoch 70: lr: 9.999999747378752e-06\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 3.3012e-05 - custom_f1: 1.0000 - val_loss: 0.5696 - val_custom_f1: 0.8900\n",
            "Epoch 71: lr: 9.999999747378752e-06\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 5.5054e-05 - custom_f1: 0.9735 - val_loss: 0.5691 - val_custom_f1: 0.8900\n",
            "Epoch 72: lr: 9.999999747378752e-06\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 4.0847e-05 - custom_f1: 1.0000 - val_loss: 0.5677 - val_custom_f1: 0.8900\n",
            "Epoch 73: lr: 9.999999747378752e-06\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 5.0879e-05 - custom_f1: 0.9912 - val_loss: 0.5719 - val_custom_f1: 0.8900\n",
            "Epoch 74: lr: 9.999999747378752e-06\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 5.4933e-05 - custom_f1: 0.9823 - val_loss: 0.5729 - val_custom_f1: 0.8900\n",
            "Epoch 75: lr: 9.999999747378752e-06\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 4.8217e-05 - custom_f1: 0.9912 - val_loss: 0.5717 - val_custom_f1: 0.8900\n",
            "Epoch 76: lr: 9.999999747378752e-06\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 5.7204e-05 - custom_f1: 0.9912 - val_loss: 0.5730 - val_custom_f1: 0.8900\n",
            "Epoch 77: lr: 9.999999747378752e-06\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - 25s 222ms/step - loss: 6.3808e-05 - custom_f1: 0.9823 - val_loss: 0.5554 - val_custom_f1: 0.8900\n",
            "Epoch 78: lr: 9.999999747378752e-06\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 5.2062e-05 - custom_f1: 0.9823 - val_loss: 0.5601 - val_custom_f1: 0.8900\n",
            "Epoch 79: lr: 9.999999747378752e-06\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 3.2257e-05 - custom_f1: 1.0000 - val_loss: 0.5682 - val_custom_f1: 0.8900\n",
            "Epoch 80: lr: 9.999999747378752e-06\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 3.7936e-05 - custom_f1: 0.9912 - val_loss: 0.5680 - val_custom_f1: 0.8900\n",
            "Epoch 81: lr: 9.999999747378752e-06\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 3.7710e-05 - custom_f1: 0.9912 - val_loss: 0.5711 - val_custom_f1: 0.8900\n",
            "Epoch 82: lr: 9.999999747378752e-06\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 3.7399e-05 - custom_f1: 0.9912 - val_loss: 0.5735 - val_custom_f1: 0.8900\n",
            "Epoch 83: lr: 9.999999747378752e-06\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 4.8088e-05 - custom_f1: 0.9912 - val_loss: 0.5779 - val_custom_f1: 0.8900\n",
            "Epoch 84: lr: 9.999999747378752e-06\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - 25s 221ms/step - loss: 6.3037e-05 - custom_f1: 0.9735 - val_loss: 0.5665 - val_custom_f1: 0.8900\n",
            "Epoch 85: lr: 9.999999747378752e-06\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 3.7897e-05 - custom_f1: 0.9912 - val_loss: 0.5710 - val_custom_f1: 0.8900\n",
            "Epoch 86: lr: 9.999999747378752e-06\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 3.7522e-05 - custom_f1: 0.9912 - val_loss: 0.5733 - val_custom_f1: 0.8900\n",
            "Epoch 87: lr: 9.999999747378752e-06\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 25s 221ms/step - loss: 2.4027e-05 - custom_f1: 1.0000 - val_loss: 0.5765 - val_custom_f1: 0.8900\n",
            "Epoch 88: lr: 9.999999747378752e-06\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 4.2994e-05 - custom_f1: 0.9912 - val_loss: 0.5771 - val_custom_f1: 0.8900\n",
            "Epoch 89: lr: 9.999999747378752e-06\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 2.5188e-05 - custom_f1: 1.0000 - val_loss: 0.5802 - val_custom_f1: 0.8900\n",
            "Epoch 90: lr: 9.999999747378752e-06\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 3.2303e-05 - custom_f1: 0.9912 - val_loss: 0.5850 - val_custom_f1: 0.8900\n",
            "Epoch 91: lr: 9.999999747378752e-06\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 3.6959e-05 - custom_f1: 0.9912 - val_loss: 0.5875 - val_custom_f1: 0.8900\n",
            "Epoch 92: lr: 9.999999747378752e-06\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - 25s 221ms/step - loss: 2.8282e-05 - custom_f1: 0.9912 - val_loss: 0.5880 - val_custom_f1: 0.8900\n",
            "Epoch 93: lr: 9.999999747378752e-06\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 3.8500e-05 - custom_f1: 0.9823 - val_loss: 0.5835 - val_custom_f1: 0.8900\n",
            "Epoch 94: lr: 9.999999747378752e-06\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 2.0099e-05 - custom_f1: 1.0000 - val_loss: 0.5882 - val_custom_f1: 0.8900\n",
            "Epoch 95: lr: 9.999999747378752e-06\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 3.2375e-05 - custom_f1: 0.9912 - val_loss: 0.5913 - val_custom_f1: 0.8900\n",
            "Epoch 96: lr: 9.999999747378752e-06\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 4.1321e-05 - custom_f1: 0.9735 - val_loss: 0.5916 - val_custom_f1: 0.8900\n",
            "Epoch 97: lr: 9.999999747378752e-06\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 25s 219ms/step - loss: 2.9431e-05 - custom_f1: 0.9823 - val_loss: 0.5935 - val_custom_f1: 0.8900\n",
            "Epoch 98: lr: 9.999999747378752e-06\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 25s 220ms/step - loss: 1.8817e-05 - custom_f1: 1.0000 - val_loss: 0.5943 - val_custom_f1: 0.8900\n",
            "Epoch 99: lr: 9.999999747378752e-06\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 25s 221ms/step - loss: 2.9037e-05 - custom_f1: 0.9823 - val_loss: 0.5932 - val_custom_f1: 0.8900\n",
            "Epoch 100: lr: 9.999999747378752e-06\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 25s 221ms/step - loss: 2.6457e-05 - custom_f1: 0.9823 - val_loss: 0.6016 - val_custom_f1: 0.8900\n",
            "weights are setted to best weights (epochs 8)\n",
            "fold 6 [250,300]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "  6/113 [>.............................] - ETA: 22s - loss: 0.6799 - custom_f1: 0.8730WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0464s vs `on_train_batch_end` time: 0.1650s). Check your callbacks.\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.5829 - custom_f1: 0.7920\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 25s 223ms/step - loss: 0.5829 - custom_f1: 0.7920 - val_loss: 0.7252 - val_custom_f1: 0.0000e+00\n",
            "Epoch 2: lr: 9.999999747378752e-05\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 0.3664 - custom_f1: 0.8673 - val_loss: 0.8189 - val_custom_f1: 0.0000e+00\n",
            "Epoch 3: lr: 9.999999747378752e-05\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.2333 - custom_f1: 0.9248 - val_loss: 0.9307 - val_custom_f1: 0.0000e+00\n",
            "Epoch 4: lr: 9.999999747378752e-05\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.2050 - custom_f1: 0.9240 - val_loss: 0.7278 - val_custom_f1: 0.0000e+00\n",
            "Epoch 5: lr: 9.999999747378752e-05\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 0.1221 - custom_f1: 0.9562 - val_loss: 1.7784 - val_custom_f1: 0.8074\n",
            "Epoch 6: lr: 9.999999747378752e-05\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1024 - custom_f1: 0.9674\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 232ms/step - loss: 0.1024 - custom_f1: 0.9674 - val_loss: 0.5107 - val_custom_f1: 0.8289\n",
            "Epoch 7: lr: 9.999999747378752e-05\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 0.1277 - custom_f1: 0.9464 - val_loss: 0.5931 - val_custom_f1: 0.8452\n",
            "Epoch 8: lr: 9.999999747378752e-05\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0756 - custom_f1: 0.9734 - val_loss: 0.6918 - val_custom_f1: 0.8686\n",
            "Epoch 9: lr: 9.999999747378752e-05\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0337 - custom_f1: 0.9823\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 229ms/step - loss: 0.0337 - custom_f1: 0.9823 - val_loss: 0.4931 - val_custom_f1: 0.8628\n",
            "Epoch 10: lr: 9.999999747378752e-05\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0188 - custom_f1: 0.9823\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 230ms/step - loss: 0.0188 - custom_f1: 0.9823 - val_loss: 0.2587 - val_custom_f1: 0.9250\n",
            "Epoch 11: lr: 9.999999747378752e-05\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0053 - custom_f1: 1.0000 - val_loss: 0.2723 - val_custom_f1: 0.9149\n",
            "Epoch 12: lr: 9.999999747378752e-05\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 0.0024 - custom_f1: 1.0000 - val_loss: 0.2700 - val_custom_f1: 0.9149\n",
            "Epoch 13: lr: 9.999999747378752e-05\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0103 - custom_f1: 0.9899\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 228ms/step - loss: 0.0103 - custom_f1: 0.9899 - val_loss: 0.2203 - val_custom_f1: 0.9434\n",
            "Epoch 14: lr: 9.999999747378752e-05\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0064 - custom_f1: 0.9735 - val_loss: 0.2265 - val_custom_f1: 0.9121\n",
            "Epoch 15: lr: 9.999999747378752e-05\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0015 - custom_f1: 1.0000 - val_loss: 0.2347 - val_custom_f1: 0.9366\n",
            "Epoch 16: lr: 9.999999747378752e-05\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0011 - custom_f1: 0.9912\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 232ms/step - loss: 0.0011 - custom_f1: 0.9912 - val_loss: 0.2119 - val_custom_f1: 0.9366\n",
            "Epoch 17: lr: 9.999999747378752e-05\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0014 - custom_f1: 0.9912 - val_loss: 0.2328 - val_custom_f1: 0.9366\n",
            "Epoch 18: lr: 9.999999747378752e-05\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 0.0014 - custom_f1: 0.9735 - val_loss: 0.2771 - val_custom_f1: 0.9058\n",
            "Epoch 19: lr: 9.999999747378752e-05\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 7.0661e-04 - custom_f1: 0.9912 - val_loss: 0.2511 - val_custom_f1: 0.9366\n",
            "Epoch 20: lr: 9.999999747378752e-05\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 3.8767e-04 - custom_f1: 1.0000 - val_loss: 0.2695 - val_custom_f1: 0.9366\n",
            "Epoch 21: lr: 9.999999747378752e-05\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 6.4216e-04 - custom_f1: 0.9823 - val_loss: 0.2566 - val_custom_f1: 0.9366\n",
            "Epoch 22: lr: 9.999999747378752e-05\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 4.0553e-04 - custom_f1: 0.9912 - val_loss: 0.2697 - val_custom_f1: 0.9366\n",
            "Epoch 23: lr: 9.999999747378752e-05\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.7147e-04 - custom_f1: 0.9912 - val_loss: 0.2456 - val_custom_f1: 0.9250\n",
            "Epoch 24: lr: 9.999999747378752e-05\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.1423e-04 - custom_f1: 0.9912 - val_loss: 0.2440 - val_custom_f1: 0.9250\n",
            "Epoch 25: lr: 9.999999747378752e-05\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 6.6399e-04 - custom_f1: 0.9823 - val_loss: 0.2406 - val_custom_f1: 0.9356\n",
            "Epoch 26: lr: 9.999999747378752e-05\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 2.8273e-04 - custom_f1: 1.0000 - val_loss: 0.2482 - val_custom_f1: 0.9250\n",
            "Epoch 27: lr: 9.999999747378752e-05\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 0.0104 - custom_f1: 0.9810 - val_loss: 0.5091 - val_custom_f1: 0.7692\n",
            "Epoch 28: lr: 9.999999747378752e-05\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.1553 - custom_f1: 0.9443 - val_loss: 0.4188 - val_custom_f1: 0.8286\n",
            "Epoch 29: lr: 9.999999747378752e-05\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 0.1120 - custom_f1: 0.9534 - val_loss: 0.2860 - val_custom_f1: 0.8704\n",
            "Epoch 30: lr: 9.999999747378752e-05\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0265 - custom_f1: 0.9805 - val_loss: 0.6283 - val_custom_f1: 0.8721\n",
            "Epoch 31: lr: 9.999999747378752e-05\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 0.0099 - custom_f1: 0.9735 - val_loss: 0.2306 - val_custom_f1: 0.9356\n",
            "Epoch 32: lr: 9.999999747378752e-05\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0037 - custom_f1: 0.9823 - val_loss: 0.2484 - val_custom_f1: 0.8937\n",
            "Epoch 33: lr: 9.999999747378752e-05\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0025 - custom_f1: 0.9735\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 234ms/step - loss: 0.0025 - custom_f1: 0.9735 - val_loss: 0.2082 - val_custom_f1: 0.9173\n",
            "Epoch 34: lr: 9.999999747378752e-05\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0011 - custom_f1: 0.9823\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 229ms/step - loss: 0.0011 - custom_f1: 0.9823 - val_loss: 0.1941 - val_custom_f1: 0.9356\n",
            "Epoch 35: lr: 9.999999747378752e-05\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 0.0010 - custom_f1: 0.9823 - val_loss: 0.1952 - val_custom_f1: 0.9555\n",
            "Epoch 36: lr: 9.999999747378752e-05\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 4.8204e-04 - custom_f1: 1.0000\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 230ms/step - loss: 4.8204e-04 - custom_f1: 1.0000 - val_loss: 0.1881 - val_custom_f1: 0.9356\n",
            "Epoch 37: lr: 9.999999747378752e-05\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 5.2985e-04 - custom_f1: 0.9912\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 228ms/step - loss: 5.2985e-04 - custom_f1: 0.9912 - val_loss: 0.1858 - val_custom_f1: 0.9173\n",
            "Epoch 38: lr: 9.999999747378752e-05\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 6.2762e-04 - custom_f1: 0.9823 - val_loss: 0.2013 - val_custom_f1: 0.9434\n",
            "Epoch 39: lr: 9.999999747378752e-05\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 5.8003e-04 - custom_f1: 0.9823 - val_loss: 0.1993 - val_custom_f1: 0.9555\n",
            "Epoch 40: lr: 9.999999747378752e-05\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 3.7834e-04 - custom_f1: 0.9823\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 229ms/step - loss: 3.7834e-04 - custom_f1: 0.9823 - val_loss: 0.1851 - val_custom_f1: 0.9555\n",
            "Epoch 41: lr: 9.999999747378752e-05\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 4.3876e-04 - custom_f1: 0.9646\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 230ms/step - loss: 4.3876e-04 - custom_f1: 0.9646 - val_loss: 0.1794 - val_custom_f1: 0.9555\n",
            "Epoch 42: lr: 9.999999747378752e-05\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 2.0958e-04 - custom_f1: 1.0000\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 232ms/step - loss: 2.0958e-04 - custom_f1: 1.0000 - val_loss: 0.1777 - val_custom_f1: 0.9356\n",
            "Epoch 43: lr: 9.999999747378752e-05\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 2.4396e-04 - custom_f1: 0.9735 - val_loss: 0.1787 - val_custom_f1: 0.9356\n",
            "Epoch 44: lr: 9.999999747378752e-05\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.8433e-04 - custom_f1: 0.9912 - val_loss: 0.1805 - val_custom_f1: 0.9173\n",
            "Epoch 45: lr: 9.999999747378752e-05\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 2.1215e-04 - custom_f1: 0.9912 - val_loss: 0.1828 - val_custom_f1: 0.9555\n",
            "Epoch 46: lr: 9.999999747378752e-05\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 2.1233e-04 - custom_f1: 0.9823 - val_loss: 0.1912 - val_custom_f1: 0.9555\n",
            "Epoch 47: lr: 9.999999747378752e-05\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 1.5107e-04 - custom_f1: 1.0000 - val_loss: 0.1895 - val_custom_f1: 0.9173\n",
            "Epoch 48: lr: 9.999999747378752e-05\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 1.9998e-04 - custom_f1: 0.9823 - val_loss: 0.1843 - val_custom_f1: 0.9356\n",
            "Epoch 49: lr: 9.999999747378752e-05\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 1.3621e-04 - custom_f1: 0.9823 - val_loss: 0.1833 - val_custom_f1: 0.9356\n",
            "Epoch 50: lr: 9.999999747378752e-05\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 1.5631e-04 - custom_f1: 0.9823 - val_loss: 0.1826 - val_custom_f1: 0.9173\n",
            "Epoch 51: lr: 9.999999747378752e-05\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 1.5143e-04 - custom_f1: 0.9735\n",
            "lr is fixed to 9.999999747378752e-06\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.5143e-04 - custom_f1: 0.9735 - val_loss: 0.1824 - val_custom_f1: 0.9173\n",
            "Epoch 52: lr: 9.999999747378752e-06\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 1.0829e-04 - custom_f1: 0.9912 - val_loss: 0.1834 - val_custom_f1: 0.9173\n",
            "Epoch 53: lr: 9.999999747378752e-06\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.1571e-04 - custom_f1: 0.9823 - val_loss: 0.1842 - val_custom_f1: 0.9173\n",
            "Epoch 54: lr: 9.999999747378752e-06\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 7.3633e-05 - custom_f1: 1.0000 - val_loss: 0.1842 - val_custom_f1: 0.9173\n",
            "Epoch 55: lr: 9.999999747378752e-06\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 1.7008e-04 - custom_f1: 0.9823 - val_loss: 0.1832 - val_custom_f1: 0.9173\n",
            "Epoch 56: lr: 9.999999747378752e-06\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.2975e-04 - custom_f1: 0.9912 - val_loss: 0.1829 - val_custom_f1: 0.9356\n",
            "Epoch 57: lr: 9.999999747378752e-06\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 8.5857e-05 - custom_f1: 0.9912 - val_loss: 0.1840 - val_custom_f1: 0.9173\n",
            "Epoch 58: lr: 9.999999747378752e-06\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 9.9825e-05 - custom_f1: 1.0000 - val_loss: 0.1833 - val_custom_f1: 0.9173\n",
            "Epoch 59: lr: 9.999999747378752e-06\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 9.2276e-05 - custom_f1: 1.0000 - val_loss: 0.1835 - val_custom_f1: 0.9173\n",
            "Epoch 60: lr: 9.999999747378752e-06\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 1.1472e-04 - custom_f1: 0.9735 - val_loss: 0.1838 - val_custom_f1: 0.9173\n",
            "Epoch 61: lr: 9.999999747378752e-06\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 1.0724e-04 - custom_f1: 0.9823 - val_loss: 0.1827 - val_custom_f1: 0.9173\n",
            "Epoch 62: lr: 9.999999747378752e-06\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.2212e-04 - custom_f1: 0.9823 - val_loss: 0.1823 - val_custom_f1: 0.9356\n",
            "Epoch 63: lr: 9.999999747378752e-06\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 1.0327e-04 - custom_f1: 0.9912 - val_loss: 0.1835 - val_custom_f1: 0.9173\n",
            "Epoch 64: lr: 9.999999747378752e-06\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 8.9199e-05 - custom_f1: 0.9912 - val_loss: 0.1833 - val_custom_f1: 0.9173\n",
            "Epoch 65: lr: 9.999999747378752e-06\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 9.4003e-05 - custom_f1: 0.9912 - val_loss: 0.1838 - val_custom_f1: 0.9173\n",
            "Epoch 66: lr: 9.999999747378752e-06\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 1.1655e-04 - custom_f1: 0.9912 - val_loss: 0.1845 - val_custom_f1: 0.9173\n",
            "Epoch 67: lr: 9.999999747378752e-06\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 8.9608e-05 - custom_f1: 0.9823 - val_loss: 0.1838 - val_custom_f1: 0.9173\n",
            "Epoch 68: lr: 9.999999747378752e-06\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.3156e-04 - custom_f1: 0.9735 - val_loss: 0.1843 - val_custom_f1: 0.9173\n",
            "Epoch 69: lr: 9.999999747378752e-06\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 7.3349e-05 - custom_f1: 1.0000 - val_loss: 0.1839 - val_custom_f1: 0.9173\n",
            "Epoch 70: lr: 9.999999747378752e-06\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 7.9592e-05 - custom_f1: 0.9912 - val_loss: 0.1825 - val_custom_f1: 0.9173\n",
            "Epoch 71: lr: 9.999999747378752e-06\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 1.0546e-04 - custom_f1: 0.9735 - val_loss: 0.1844 - val_custom_f1: 0.9173\n",
            "Epoch 72: lr: 9.999999747378752e-06\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.0463e-04 - custom_f1: 0.9735 - val_loss: 0.1845 - val_custom_f1: 0.9173\n",
            "Epoch 73: lr: 9.999999747378752e-06\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 7.2925e-05 - custom_f1: 0.9912 - val_loss: 0.1860 - val_custom_f1: 0.9173\n",
            "Epoch 74: lr: 9.999999747378752e-06\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 9.7691e-05 - custom_f1: 0.9912 - val_loss: 0.1857 - val_custom_f1: 0.9173\n",
            "Epoch 75: lr: 9.999999747378752e-06\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 7.2922e-05 - custom_f1: 0.9912 - val_loss: 0.1866 - val_custom_f1: 0.9173\n",
            "Epoch 76: lr: 9.999999747378752e-06\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 5.8527e-05 - custom_f1: 1.0000 - val_loss: 0.1868 - val_custom_f1: 0.9173\n",
            "Epoch 77: lr: 9.999999747378752e-06\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 6.0545e-05 - custom_f1: 1.0000 - val_loss: 0.1868 - val_custom_f1: 0.9173\n",
            "Epoch 78: lr: 9.999999747378752e-06\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 4.9114e-05 - custom_f1: 1.0000 - val_loss: 0.1882 - val_custom_f1: 0.9173\n",
            "Epoch 79: lr: 9.999999747378752e-06\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 6.8981e-05 - custom_f1: 0.9912 - val_loss: 0.1904 - val_custom_f1: 0.9173\n",
            "Epoch 80: lr: 9.999999747378752e-06\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 9.5640e-05 - custom_f1: 0.9735 - val_loss: 0.1857 - val_custom_f1: 0.9173\n",
            "Epoch 81: lr: 9.999999747378752e-06\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 1.2977e-04 - custom_f1: 0.9558 - val_loss: 0.1842 - val_custom_f1: 0.9173\n",
            "Epoch 82: lr: 9.999999747378752e-06\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.0050e-04 - custom_f1: 0.9735 - val_loss: 0.1840 - val_custom_f1: 0.9173\n",
            "Epoch 83: lr: 9.999999747378752e-06\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 5.9657e-05 - custom_f1: 0.9912 - val_loss: 0.1834 - val_custom_f1: 0.9173\n",
            "Epoch 84: lr: 9.999999747378752e-06\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 9.1533e-05 - custom_f1: 0.9735 - val_loss: 0.1813 - val_custom_f1: 0.9173\n",
            "Epoch 85: lr: 9.999999747378752e-06\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 6.7585e-05 - custom_f1: 0.9912 - val_loss: 0.1815 - val_custom_f1: 0.9173\n",
            "Epoch 86: lr: 9.999999747378752e-06\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 4.3893e-05 - custom_f1: 1.0000 - val_loss: 0.1822 - val_custom_f1: 0.9173\n",
            "Epoch 87: lr: 9.999999747378752e-06\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 7.5611e-05 - custom_f1: 0.9735 - val_loss: 0.1849 - val_custom_f1: 0.9173\n",
            "Epoch 88: lr: 9.999999747378752e-06\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 9.6905e-05 - custom_f1: 0.9735 - val_loss: 0.1832 - val_custom_f1: 0.9356\n",
            "Epoch 89: lr: 9.999999747378752e-06\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 4.3061e-05 - custom_f1: 1.0000 - val_loss: 0.1853 - val_custom_f1: 0.9173\n",
            "Epoch 90: lr: 9.999999747378752e-06\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 5.1805e-05 - custom_f1: 0.9912 - val_loss: 0.1871 - val_custom_f1: 0.9173\n",
            "Epoch 91: lr: 9.999999747378752e-06\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 5.5301e-05 - custom_f1: 0.9912 - val_loss: 0.1878 - val_custom_f1: 0.9173\n",
            "Epoch 92: lr: 9.999999747378752e-06\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 4.9277e-05 - custom_f1: 0.9912 - val_loss: 0.1909 - val_custom_f1: 0.9173\n",
            "Epoch 93: lr: 9.999999747378752e-06\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 4.1675e-05 - custom_f1: 0.9912 - val_loss: 0.1911 - val_custom_f1: 0.9173\n",
            "Epoch 94: lr: 9.999999747378752e-06\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 5.1474e-05 - custom_f1: 0.9823 - val_loss: 0.1912 - val_custom_f1: 0.9173\n",
            "Epoch 95: lr: 9.999999747378752e-06\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 4.4080e-05 - custom_f1: 0.9912 - val_loss: 0.1923 - val_custom_f1: 0.9173\n",
            "Epoch 96: lr: 9.999999747378752e-06\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.9972e-05 - custom_f1: 1.0000 - val_loss: 0.1961 - val_custom_f1: 0.9173\n",
            "Epoch 97: lr: 9.999999747378752e-06\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 8.9664e-05 - custom_f1: 0.9469 - val_loss: 0.1864 - val_custom_f1: 0.9356\n",
            "Epoch 98: lr: 9.999999747378752e-06\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 4.5324e-05 - custom_f1: 0.9912 - val_loss: 0.1881 - val_custom_f1: 0.9173\n",
            "Epoch 99: lr: 9.999999747378752e-06\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.8125e-05 - custom_f1: 0.9912 - val_loss: 0.1903 - val_custom_f1: 0.9173\n",
            "Epoch 100: lr: 9.999999747378752e-06\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.7903e-05 - custom_f1: 0.9823 - val_loss: 0.1920 - val_custom_f1: 0.9173\n",
            "weights are setted to best weights (epochs 42)\n",
            "fold 7 [300,350]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "  6/113 [>.............................] - ETA: 22s - loss: 0.6852 - custom_f1: 0.6746WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0458s vs `on_train_batch_end` time: 0.1683s). Check your callbacks.\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.5634 - custom_f1: 0.7734\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 226ms/step - loss: 0.5634 - custom_f1: 0.7734 - val_loss: 0.6918 - val_custom_f1: 0.8156\n",
            "Epoch 2: lr: 9.999999747378752e-05\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.3759 - custom_f1: 0.8680\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 229ms/step - loss: 0.3759 - custom_f1: 0.8680 - val_loss: 0.6851 - val_custom_f1: 0.8156\n",
            "Epoch 3: lr: 9.999999747378752e-05\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.2045 - custom_f1: 0.9209\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 232ms/step - loss: 0.2045 - custom_f1: 0.9209 - val_loss: 0.6436 - val_custom_f1: 0.8156\n",
            "Epoch 4: lr: 9.999999747378752e-05\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.2020 - custom_f1: 0.9422\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 229ms/step - loss: 0.2020 - custom_f1: 0.9422 - val_loss: 0.6353 - val_custom_f1: 0.8156\n",
            "Epoch 5: lr: 9.999999747378752e-05\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.1327 - custom_f1: 0.9550 - val_loss: 1.0769 - val_custom_f1: 0.8156\n",
            "Epoch 6: lr: 9.999999747378752e-05\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 0.1112 - custom_f1: 0.9604 - val_loss: 1.6749 - val_custom_f1: 0.8156\n",
            "Epoch 7: lr: 9.999999747378752e-05\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 0.0850 - custom_f1: 0.9689 - val_loss: 2.7012 - val_custom_f1: 0.8232\n",
            "Epoch 8: lr: 9.999999747378752e-05\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 0.0537 - custom_f1: 0.9815 - val_loss: 0.8513 - val_custom_f1: 0.8571\n",
            "Epoch 9: lr: 9.999999747378752e-05\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 0.0472 - custom_f1: 0.9809 - val_loss: 1.9972 - val_custom_f1: 0.4276\n",
            "Epoch 10: lr: 9.999999747378752e-05\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0200 - custom_f1: 1.0000\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 229ms/step - loss: 0.0200 - custom_f1: 1.0000 - val_loss: 0.2575 - val_custom_f1: 0.8851\n",
            "Epoch 11: lr: 9.999999747378752e-05\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0085 - custom_f1: 0.9987\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 228ms/step - loss: 0.0085 - custom_f1: 0.9987 - val_loss: 0.1630 - val_custom_f1: 0.9678\n",
            "Epoch 12: lr: 9.999999747378752e-05\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0357 - custom_f1: 0.9781 - val_loss: 1.4564 - val_custom_f1: 0.3798\n",
            "Epoch 13: lr: 9.999999747378752e-05\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 0.0295 - custom_f1: 0.9881 - val_loss: 1.2011 - val_custom_f1: 0.6970\n",
            "Epoch 14: lr: 9.999999747378752e-05\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0172 - custom_f1: 0.9823 - val_loss: 0.2204 - val_custom_f1: 0.9328\n",
            "Epoch 15: lr: 9.999999747378752e-05\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0138 - custom_f1: 0.9912 - val_loss: 0.2209 - val_custom_f1: 0.9206\n",
            "Epoch 16: lr: 9.999999747378752e-05\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0051 - custom_f1: 0.9823 - val_loss: 0.2760 - val_custom_f1: 0.9365\n",
            "Epoch 17: lr: 9.999999747378752e-05\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 0.0078 - custom_f1: 0.9823 - val_loss: 0.1969 - val_custom_f1: 0.9377\n",
            "Epoch 18: lr: 9.999999747378752e-05\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0043 - custom_f1: 0.9912 - val_loss: 0.4330 - val_custom_f1: 0.8565\n",
            "Epoch 19: lr: 9.999999747378752e-05\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0069 - custom_f1: 0.9823 - val_loss: 0.1823 - val_custom_f1: 0.9206\n",
            "Epoch 20: lr: 9.999999747378752e-05\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 6.5263e-04 - custom_f1: 1.0000 - val_loss: 0.1911 - val_custom_f1: 0.9206\n",
            "Epoch 21: lr: 9.999999747378752e-05\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 0.0029 - custom_f1: 0.9646 - val_loss: 0.1981 - val_custom_f1: 0.9365\n",
            "Epoch 22: lr: 9.999999747378752e-05\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 5.0051e-04 - custom_f1: 1.0000 - val_loss: 0.1923 - val_custom_f1: 0.9322\n",
            "Epoch 23: lr: 9.999999747378752e-05\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 5.5461e-04 - custom_f1: 0.9912 - val_loss: 0.1979 - val_custom_f1: 0.9322\n",
            "Epoch 24: lr: 9.999999747378752e-05\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 6.6354e-04 - custom_f1: 0.9823 - val_loss: 0.2009 - val_custom_f1: 0.9322\n",
            "Epoch 25: lr: 9.999999747378752e-05\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 4.1112e-04 - custom_f1: 0.9912 - val_loss: 0.1986 - val_custom_f1: 0.9365\n",
            "Epoch 26: lr: 9.999999747378752e-05\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 3.1537e-04 - custom_f1: 0.9912 - val_loss: 0.1899 - val_custom_f1: 0.9322\n",
            "Epoch 27: lr: 9.999999747378752e-05\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 2.1271e-04 - custom_f1: 1.0000 - val_loss: 0.1947 - val_custom_f1: 0.9322\n",
            "Epoch 28: lr: 9.999999747378752e-05\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 3.9738e-04 - custom_f1: 0.9735 - val_loss: 0.2086 - val_custom_f1: 0.9365\n",
            "Epoch 29: lr: 9.999999747378752e-05\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 2.1384e-04 - custom_f1: 1.0000 - val_loss: 0.1869 - val_custom_f1: 0.9322\n",
            "Epoch 30: lr: 9.999999747378752e-05\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 1.4123e-04 - custom_f1: 1.0000 - val_loss: 0.1910 - val_custom_f1: 0.9322\n",
            "Epoch 31: lr: 9.999999747378752e-05\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 1.7945e-04 - custom_f1: 0.9912 - val_loss: 0.1917 - val_custom_f1: 0.9322\n",
            "Epoch 32: lr: 9.999999747378752e-05\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 2.2495e-04 - custom_f1: 0.9823 - val_loss: 0.1960 - val_custom_f1: 0.9365\n",
            "Epoch 33: lr: 9.999999747378752e-05\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 1.9477e-04 - custom_f1: 0.9823 - val_loss: 0.1984 - val_custom_f1: 0.9322\n",
            "Epoch 34: lr: 9.999999747378752e-05\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.5057e-04 - custom_f1: 0.9823 - val_loss: 0.1982 - val_custom_f1: 0.9322\n",
            "Epoch 35: lr: 9.999999747378752e-05\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 1.2953e-04 - custom_f1: 0.9912 - val_loss: 0.1907 - val_custom_f1: 0.9493\n",
            "Epoch 36: lr: 9.999999747378752e-05\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 2.8973e-04 - custom_f1: 0.9558 - val_loss: 0.1998 - val_custom_f1: 0.9365\n",
            "Epoch 37: lr: 9.999999747378752e-05\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 9.9544e-05 - custom_f1: 1.0000 - val_loss: 0.1899 - val_custom_f1: 0.9322\n",
            "Epoch 38: lr: 9.999999747378752e-05\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.1411e-04 - custom_f1: 0.9912 - val_loss: 0.1943 - val_custom_f1: 0.9493\n",
            "Epoch 39: lr: 9.999999747378752e-05\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 2.1563e-04 - custom_f1: 0.9735 - val_loss: 0.1971 - val_custom_f1: 0.9493\n",
            "Epoch 40: lr: 9.999999747378752e-05\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 1.8280e-04 - custom_f1: 0.9823 - val_loss: 0.1940 - val_custom_f1: 0.9493\n",
            "Epoch 41: lr: 9.999999747378752e-05\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 8.2341e-05 - custom_f1: 0.9912 - val_loss: 0.1878 - val_custom_f1: 0.9493\n",
            "Epoch 42: lr: 9.999999747378752e-05\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 6.8060e-05 - custom_f1: 1.0000 - val_loss: 0.1910 - val_custom_f1: 0.9096\n",
            "Epoch 43: lr: 9.999999747378752e-05\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 7.9858e-05 - custom_f1: 0.9912 - val_loss: 0.1924 - val_custom_f1: 0.9096\n",
            "Epoch 44: lr: 9.999999747378752e-05\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.1194e-04 - custom_f1: 0.9823 - val_loss: 0.1921 - val_custom_f1: 0.9322\n",
            "Epoch 45: lr: 9.999999747378752e-05\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.1603e-04 - custom_f1: 0.9912 - val_loss: 0.2342 - val_custom_f1: 0.9365\n",
            "Epoch 46: lr: 9.999999747378752e-05\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 7.3041e-05 - custom_f1: 0.9912 - val_loss: 0.2168 - val_custom_f1: 0.9079\n",
            "Epoch 47: lr: 9.999999747378752e-05\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 5.8345e-05 - custom_f1: 0.9912 - val_loss: 0.2120 - val_custom_f1: 0.9096\n",
            "Epoch 48: lr: 9.999999747378752e-05\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 7.5485e-05 - custom_f1: 0.9735 - val_loss: 0.2136 - val_custom_f1: 0.9096\n",
            "Epoch 49: lr: 9.999999747378752e-05\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 6.8706e-05 - custom_f1: 0.9912 - val_loss: 0.2113 - val_custom_f1: 0.9096\n",
            "Epoch 50: lr: 9.999999747378752e-05\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 5.9433e-05 - custom_f1: 0.9823 - val_loss: 0.2151 - val_custom_f1: 0.9096\n",
            "Epoch 51: lr: 9.999999747378752e-05\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 5.5591e-05 - custom_f1: 0.9912\n",
            "lr is fixed to 9.999999747378752e-06\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 5.5591e-05 - custom_f1: 0.9912 - val_loss: 0.2188 - val_custom_f1: 0.9096\n",
            "Epoch 52: lr: 9.999999747378752e-06\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 5.1916e-05 - custom_f1: 0.9912 - val_loss: 0.2174 - val_custom_f1: 0.9096\n",
            "Epoch 53: lr: 9.999999747378752e-06\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 4.1517e-05 - custom_f1: 0.9912 - val_loss: 0.2169 - val_custom_f1: 0.9096\n",
            "Epoch 54: lr: 9.999999747378752e-06\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.5874e-05 - custom_f1: 1.0000 - val_loss: 0.2167 - val_custom_f1: 0.9096\n",
            "Epoch 55: lr: 9.999999747378752e-06\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 4.7596e-05 - custom_f1: 0.9912 - val_loss: 0.2172 - val_custom_f1: 0.9096\n",
            "Epoch 56: lr: 9.999999747378752e-06\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 5.6444e-05 - custom_f1: 0.9823 - val_loss: 0.2161 - val_custom_f1: 0.9096\n",
            "Epoch 57: lr: 9.999999747378752e-06\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 4.6370e-05 - custom_f1: 0.9912 - val_loss: 0.2164 - val_custom_f1: 0.9096\n",
            "Epoch 58: lr: 9.999999747378752e-06\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 7.1355e-05 - custom_f1: 0.9823 - val_loss: 0.2144 - val_custom_f1: 0.9096\n",
            "Epoch 59: lr: 9.999999747378752e-06\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.9386e-05 - custom_f1: 0.9912 - val_loss: 0.2154 - val_custom_f1: 0.9096\n",
            "Epoch 60: lr: 9.999999747378752e-06\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 9.7560e-05 - custom_f1: 0.9735 - val_loss: 0.2094 - val_custom_f1: 0.9096\n",
            "Epoch 61: lr: 9.999999747378752e-06\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 5.3614e-05 - custom_f1: 0.9823 - val_loss: 0.2096 - val_custom_f1: 0.9096\n",
            "Epoch 62: lr: 9.999999747378752e-06\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 5.1757e-05 - custom_f1: 0.9735 - val_loss: 0.2102 - val_custom_f1: 0.9096\n",
            "Epoch 63: lr: 9.999999747378752e-06\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 7.0892e-05 - custom_f1: 0.9646 - val_loss: 0.2092 - val_custom_f1: 0.9096\n",
            "Epoch 64: lr: 9.999999747378752e-06\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 3.5627e-05 - custom_f1: 1.0000 - val_loss: 0.2098 - val_custom_f1: 0.9096\n",
            "Epoch 65: lr: 9.999999747378752e-06\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 3.9439e-05 - custom_f1: 0.9912 - val_loss: 0.2103 - val_custom_f1: 0.9096\n",
            "Epoch 66: lr: 9.999999747378752e-06\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 5.7986e-05 - custom_f1: 0.9823 - val_loss: 0.2076 - val_custom_f1: 0.9096\n",
            "Epoch 67: lr: 9.999999747378752e-06\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 6.8997e-05 - custom_f1: 0.9735 - val_loss: 0.2066 - val_custom_f1: 0.9096\n",
            "Epoch 68: lr: 9.999999747378752e-06\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.2712e-05 - custom_f1: 1.0000 - val_loss: 0.2071 - val_custom_f1: 0.9096\n",
            "Epoch 69: lr: 9.999999747378752e-06\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.4218e-05 - custom_f1: 1.0000 - val_loss: 0.2082 - val_custom_f1: 0.9096\n",
            "Epoch 70: lr: 9.999999747378752e-06\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 5.9741e-05 - custom_f1: 0.9735 - val_loss: 0.2067 - val_custom_f1: 0.9096\n",
            "Epoch 71: lr: 9.999999747378752e-06\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 3.0456e-05 - custom_f1: 1.0000 - val_loss: 0.2083 - val_custom_f1: 0.9096\n",
            "Epoch 72: lr: 9.999999747378752e-06\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 7.8520e-05 - custom_f1: 0.9823 - val_loss: 0.2065 - val_custom_f1: 0.9206\n",
            "Epoch 73: lr: 9.999999747378752e-06\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.4535e-05 - custom_f1: 0.9912 - val_loss: 0.2072 - val_custom_f1: 0.9096\n",
            "Epoch 74: lr: 9.999999747378752e-06\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 4.6649e-05 - custom_f1: 0.9823 - val_loss: 0.2075 - val_custom_f1: 0.9096\n",
            "Epoch 75: lr: 9.999999747378752e-06\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 2.9308e-05 - custom_f1: 1.0000 - val_loss: 0.2100 - val_custom_f1: 0.9096\n",
            "Epoch 76: lr: 9.999999747378752e-06\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 4.9249e-05 - custom_f1: 0.9823 - val_loss: 0.2111 - val_custom_f1: 0.9096\n",
            "Epoch 77: lr: 9.999999747378752e-06\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 6.1454e-05 - custom_f1: 0.9646 - val_loss: 0.2068 - val_custom_f1: 0.9096\n",
            "Epoch 78: lr: 9.999999747378752e-06\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 4.4825e-05 - custom_f1: 0.9823 - val_loss: 0.2058 - val_custom_f1: 0.9096\n",
            "Epoch 79: lr: 9.999999747378752e-06\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 4.8789e-05 - custom_f1: 0.9735 - val_loss: 0.2058 - val_custom_f1: 0.9096\n",
            "Epoch 80: lr: 9.999999747378752e-06\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 3.1754e-05 - custom_f1: 0.9912 - val_loss: 0.2083 - val_custom_f1: 0.9096\n",
            "Epoch 81: lr: 9.999999747378752e-06\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 4.0536e-05 - custom_f1: 0.9912 - val_loss: 0.2045 - val_custom_f1: 0.9096\n",
            "Epoch 82: lr: 9.999999747378752e-06\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 2.7062e-05 - custom_f1: 1.0000 - val_loss: 0.2080 - val_custom_f1: 0.9096\n",
            "Epoch 83: lr: 9.999999747378752e-06\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.6228e-05 - custom_f1: 0.9823 - val_loss: 0.2069 - val_custom_f1: 0.9096\n",
            "Epoch 84: lr: 9.999999747378752e-06\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 4.3174e-05 - custom_f1: 0.9823 - val_loss: 0.2066 - val_custom_f1: 0.9096\n",
            "Epoch 85: lr: 9.999999747378752e-06\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 2.0050e-05 - custom_f1: 1.0000 - val_loss: 0.2097 - val_custom_f1: 0.9096\n",
            "Epoch 86: lr: 9.999999747378752e-06\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 5.0359e-05 - custom_f1: 0.9735 - val_loss: 0.2047 - val_custom_f1: 0.9096\n",
            "Epoch 87: lr: 9.999999747378752e-06\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 2.7848e-05 - custom_f1: 0.9912 - val_loss: 0.2073 - val_custom_f1: 0.9096\n",
            "Epoch 88: lr: 9.999999747378752e-06\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 2.8019e-05 - custom_f1: 0.9912 - val_loss: 0.2080 - val_custom_f1: 0.9096\n",
            "Epoch 89: lr: 9.999999747378752e-06\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.9856e-05 - custom_f1: 1.0000 - val_loss: 0.2116 - val_custom_f1: 0.9096\n",
            "Epoch 90: lr: 9.999999747378752e-06\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.7963e-05 - custom_f1: 0.9823 - val_loss: 0.2071 - val_custom_f1: 0.9096\n",
            "Epoch 91: lr: 9.999999747378752e-06\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 2.7831e-05 - custom_f1: 0.9912 - val_loss: 0.2061 - val_custom_f1: 0.9096\n",
            "Epoch 92: lr: 9.999999747378752e-06\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 3.0247e-05 - custom_f1: 0.9912 - val_loss: 0.2080 - val_custom_f1: 0.9096\n",
            "Epoch 93: lr: 9.999999747378752e-06\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 2.0392e-05 - custom_f1: 1.0000 - val_loss: 0.2163 - val_custom_f1: 0.9096\n",
            "Epoch 94: lr: 9.999999747378752e-06\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 3.7276e-05 - custom_f1: 0.9735 - val_loss: 0.2109 - val_custom_f1: 0.9096\n",
            "Epoch 95: lr: 9.999999747378752e-06\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 4.5896e-05 - custom_f1: 0.9646 - val_loss: 0.2034 - val_custom_f1: 0.9096\n",
            "Epoch 96: lr: 9.999999747378752e-06\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 2.6619e-05 - custom_f1: 0.9823 - val_loss: 0.2048 - val_custom_f1: 0.9267\n",
            "Epoch 97: lr: 9.999999747378752e-06\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 3.3706e-05 - custom_f1: 0.9735 - val_loss: 0.2038 - val_custom_f1: 0.9139\n",
            "Epoch 98: lr: 9.999999747378752e-06\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 2.8709e-05 - custom_f1: 0.9735 - val_loss: 0.1992 - val_custom_f1: 0.9250\n",
            "Epoch 99: lr: 9.999999747378752e-06\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 2.4777e-05 - custom_f1: 0.9823 - val_loss: 0.2001 - val_custom_f1: 0.9267\n",
            "Epoch 100: lr: 9.999999747378752e-06\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 1.5490e-05 - custom_f1: 0.9912 - val_loss: 0.2046 - val_custom_f1: 0.9267\n",
            "weights are setted to best weights (epochs 11)\n",
            "fold 8 [350,400]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "  6/113 [>.............................] - ETA: 23s - loss: 0.7474 - custom_f1: 0.7333WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0476s vs `on_train_batch_end` time: 0.1669s). Check your callbacks.\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.5505 - custom_f1: 0.7992\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 25s 225ms/step - loss: 0.5505 - custom_f1: 0.7992 - val_loss: 0.6857 - val_custom_f1: 0.7619\n",
            "Epoch 2: lr: 9.999999747378752e-05\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.3946 - custom_f1: 0.8540\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 228ms/step - loss: 0.3946 - custom_f1: 0.8540 - val_loss: 0.6835 - val_custom_f1: 0.7619\n",
            "Epoch 3: lr: 9.999999747378752e-05\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.2173 - custom_f1: 0.9287 - val_loss: 0.6854 - val_custom_f1: 0.7619\n",
            "Epoch 4: lr: 9.999999747378752e-05\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.1805 - custom_f1: 0.9421\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 229ms/step - loss: 0.1805 - custom_f1: 0.9421 - val_loss: 0.6401 - val_custom_f1: 0.7619\n",
            "Epoch 5: lr: 9.999999747378752e-05\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.1005 - custom_f1: 0.9726 - val_loss: 1.9847 - val_custom_f1: 0.7619\n",
            "Epoch 6: lr: 9.999999747378752e-05\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.1298 - custom_f1: 0.9551 - val_loss: 1.1284 - val_custom_f1: 0.7619\n",
            "Epoch 7: lr: 9.999999747378752e-05\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0875 - custom_f1: 0.9623 - val_loss: 1.9624 - val_custom_f1: 0.7697\n",
            "Epoch 8: lr: 9.999999747378752e-05\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0694 - custom_f1: 0.9831 - val_loss: 1.5330 - val_custom_f1: 0.7778\n",
            "Epoch 9: lr: 9.999999747378752e-05\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 0.0542 - custom_f1: 0.9768 - val_loss: 2.1110 - val_custom_f1: 0.3611\n",
            "Epoch 10: lr: 9.999999747378752e-05\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.0329 - custom_f1: 0.9793\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 230ms/step - loss: 0.0329 - custom_f1: 0.9793 - val_loss: 0.2186 - val_custom_f1: 0.8812\n",
            "Epoch 11: lr: 9.999999747378752e-05\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0338 - custom_f1: 0.9781 - val_loss: 0.4631 - val_custom_f1: 0.8260\n",
            "Epoch 12: lr: 9.999999747378752e-05\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0066 - custom_f1: 1.0000 - val_loss: 0.7863 - val_custom_f1: 0.8128\n",
            "Epoch 13: lr: 9.999999747378752e-05\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0149 - custom_f1: 0.9810 - val_loss: 1.3315 - val_custom_f1: 0.3000\n",
            "Epoch 14: lr: 9.999999747378752e-05\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0241 - custom_f1: 0.9722 - val_loss: 0.2273 - val_custom_f1: 0.9289\n",
            "Epoch 15: lr: 9.999999747378752e-05\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0024 - custom_f1: 1.0000 - val_loss: 0.2388 - val_custom_f1: 0.9206\n",
            "Epoch 16: lr: 9.999999747378752e-05\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0015 - custom_f1: 1.0000 - val_loss: 0.3623 - val_custom_f1: 0.8814\n",
            "Epoch 17: lr: 9.999999747378752e-05\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0075 - custom_f1: 0.9912 - val_loss: 0.4372 - val_custom_f1: 0.8706\n",
            "Epoch 18: lr: 9.999999747378752e-05\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 0.0013 - custom_f1: 0.9912 - val_loss: 0.3901 - val_custom_f1: 0.8797\n",
            "Epoch 19: lr: 9.999999747378752e-05\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 0.0011 - custom_f1: 0.9912 - val_loss: 0.3434 - val_custom_f1: 0.8797\n",
            "Epoch 20: lr: 9.999999747378752e-05\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 6.2715e-04 - custom_f1: 0.9823 - val_loss: 0.3385 - val_custom_f1: 0.8515\n",
            "Epoch 21: lr: 9.999999747378752e-05\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 5.9644e-04 - custom_f1: 0.9912 - val_loss: 0.3450 - val_custom_f1: 0.8797\n",
            "Epoch 22: lr: 9.999999747378752e-05\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 4.7553e-04 - custom_f1: 0.9912 - val_loss: 0.3523 - val_custom_f1: 0.8797\n",
            "Epoch 23: lr: 9.999999747378752e-05\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 2.8958e-04 - custom_f1: 1.0000 - val_loss: 0.3842 - val_custom_f1: 0.8797\n",
            "Epoch 24: lr: 9.999999747378752e-05\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.8197e-04 - custom_f1: 0.9912 - val_loss: 0.3281 - val_custom_f1: 0.8691\n",
            "Epoch 25: lr: 9.999999747378752e-05\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 5.3289e-04 - custom_f1: 0.9823 - val_loss: 0.2602 - val_custom_f1: 0.8811\n",
            "Epoch 26: lr: 9.999999747378752e-05\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.6427e-04 - custom_f1: 0.9912 - val_loss: 0.3288 - val_custom_f1: 0.8886\n",
            "Epoch 27: lr: 9.999999747378752e-05\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 4.8738e-04 - custom_f1: 0.9823 - val_loss: 0.2361 - val_custom_f1: 0.9044\n",
            "Epoch 28: lr: 9.999999747378752e-05\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.1246e-04 - custom_f1: 0.9912 - val_loss: 0.2903 - val_custom_f1: 0.8600\n",
            "Epoch 29: lr: 9.999999747378752e-05\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.4087e-04 - custom_f1: 0.9823 - val_loss: 0.3057 - val_custom_f1: 0.8886\n",
            "Epoch 30: lr: 9.999999747378752e-05\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.9524e-04 - custom_f1: 0.9912 - val_loss: 0.3302 - val_custom_f1: 0.8886\n",
            "Epoch 31: lr: 9.999999747378752e-05\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.8045e-04 - custom_f1: 0.9912 - val_loss: 0.3443 - val_custom_f1: 0.8886\n",
            "Epoch 32: lr: 9.999999747378752e-05\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.0894e-04 - custom_f1: 0.9735 - val_loss: 0.2701 - val_custom_f1: 0.8886\n",
            "Epoch 33: lr: 9.999999747378752e-05\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.7129e-04 - custom_f1: 0.9912 - val_loss: 0.3183 - val_custom_f1: 0.8886\n",
            "Epoch 34: lr: 9.999999747378752e-05\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.6036e-04 - custom_f1: 1.0000 - val_loss: 0.3592 - val_custom_f1: 0.8691\n",
            "Epoch 35: lr: 9.999999747378752e-05\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.2303e-04 - custom_f1: 0.9912 - val_loss: 0.3359 - val_custom_f1: 0.8886\n",
            "Epoch 36: lr: 9.999999747378752e-05\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.9437e-04 - custom_f1: 0.9912 - val_loss: 0.2781 - val_custom_f1: 0.8600\n",
            "Epoch 37: lr: 9.999999747378752e-05\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 2.5062e-04 - custom_f1: 0.9735 - val_loss: 0.2246 - val_custom_f1: 0.8904\n",
            "Epoch 38: lr: 9.999999747378752e-05\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.1567e-04 - custom_f1: 0.9912 - val_loss: 0.2537 - val_custom_f1: 0.9100\n",
            "Epoch 39: lr: 9.999999747378752e-05\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 1.7147e-04 - custom_f1: 0.9735 - val_loss: 0.2521 - val_custom_f1: 0.9100\n",
            "Epoch 40: lr: 9.999999747378752e-05\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.1214e-04 - custom_f1: 0.9912 - val_loss: 0.2767 - val_custom_f1: 0.9100\n",
            "Epoch 41: lr: 9.999999747378752e-05\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 1.5336e-04 - custom_f1: 0.9735\n",
            "best model weights are saved at /content/drive/MyDrive/SyntekaBio/weights\n",
            "113/113 [==============================] - 26s 228ms/step - loss: 1.5336e-04 - custom_f1: 0.9735 - val_loss: 0.2083 - val_custom_f1: 0.8904\n",
            "Epoch 42: lr: 9.999999747378752e-05\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 8.8158e-05 - custom_f1: 1.0000 - val_loss: 0.2641 - val_custom_f1: 0.9100\n",
            "Epoch 43: lr: 9.999999747378752e-05\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 8.8897e-05 - custom_f1: 0.9912 - val_loss: 0.3077 - val_custom_f1: 0.8691\n",
            "Epoch 44: lr: 9.999999747378752e-05\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.0744e-04 - custom_f1: 0.9823 - val_loss: 0.2913 - val_custom_f1: 0.8886\n",
            "Epoch 45: lr: 9.999999747378752e-05\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.1035e-04 - custom_f1: 0.9735 - val_loss: 0.2918 - val_custom_f1: 0.8886\n",
            "Epoch 46: lr: 9.999999747378752e-05\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 5.6024e-05 - custom_f1: 0.9912 - val_loss: 0.3243 - val_custom_f1: 0.8691\n",
            "Epoch 47: lr: 9.999999747378752e-05\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.6964e-04 - custom_f1: 0.9646 - val_loss: 0.2267 - val_custom_f1: 0.8904\n",
            "Epoch 48: lr: 9.999999747378752e-05\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 7.6625e-05 - custom_f1: 0.9912 - val_loss: 0.2371 - val_custom_f1: 0.8904\n",
            "Epoch 49: lr: 9.999999747378752e-05\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 4.7358e-05 - custom_f1: 1.0000 - val_loss: 0.2732 - val_custom_f1: 0.8811\n",
            "Epoch 50: lr: 9.999999747378752e-05\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 5.6109e-05 - custom_f1: 0.9912 - val_loss: 0.2665 - val_custom_f1: 0.8811\n",
            "Epoch 51: lr: 9.999999747378752e-05\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - ETA: 0s - loss: 5.3279e-05 - custom_f1: 0.9912\n",
            "lr is fixed to 9.999999747378752e-06\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 5.3279e-05 - custom_f1: 0.9912 - val_loss: 0.2690 - val_custom_f1: 0.8811\n",
            "Epoch 52: lr: 9.999999747378752e-06\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 4.2357e-05 - custom_f1: 0.9912 - val_loss: 0.2684 - val_custom_f1: 0.8811\n",
            "Epoch 53: lr: 9.999999747378752e-06\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 5.7442e-05 - custom_f1: 0.9912 - val_loss: 0.2650 - val_custom_f1: 0.8811\n",
            "Epoch 54: lr: 9.999999747378752e-06\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 5.8351e-05 - custom_f1: 0.9823 - val_loss: 0.2696 - val_custom_f1: 0.8811\n",
            "Epoch 55: lr: 9.999999747378752e-06\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 4.8331e-05 - custom_f1: 0.9912 - val_loss: 0.2670 - val_custom_f1: 0.8811\n",
            "Epoch 56: lr: 9.999999747378752e-06\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 6.4405e-05 - custom_f1: 0.9912 - val_loss: 0.2693 - val_custom_f1: 0.8811\n",
            "Epoch 57: lr: 9.999999747378752e-06\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 5.1616e-05 - custom_f1: 0.9912 - val_loss: 0.2730 - val_custom_f1: 0.8811\n",
            "Epoch 58: lr: 9.999999747378752e-06\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 4.9198e-05 - custom_f1: 0.9912 - val_loss: 0.2768 - val_custom_f1: 0.8811\n",
            "Epoch 59: lr: 9.999999747378752e-06\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 4.7738e-05 - custom_f1: 0.9823 - val_loss: 0.2794 - val_custom_f1: 0.8811\n",
            "Epoch 60: lr: 9.999999747378752e-06\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 4.8973e-05 - custom_f1: 0.9912 - val_loss: 0.2810 - val_custom_f1: 0.8811\n",
            "Epoch 61: lr: 9.999999747378752e-06\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 5.9488e-05 - custom_f1: 0.9912 - val_loss: 0.2581 - val_custom_f1: 0.8811\n",
            "Epoch 62: lr: 9.999999747378752e-06\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 4.9824e-05 - custom_f1: 0.9823 - val_loss: 0.2589 - val_custom_f1: 0.8811\n",
            "Epoch 63: lr: 9.999999747378752e-06\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 4.6946e-05 - custom_f1: 0.9912 - val_loss: 0.2691 - val_custom_f1: 0.8811\n",
            "Epoch 64: lr: 9.999999747378752e-06\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 3.2482e-05 - custom_f1: 1.0000 - val_loss: 0.2745 - val_custom_f1: 0.9100\n",
            "Epoch 65: lr: 9.999999747378752e-06\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 4.8998e-05 - custom_f1: 0.9912 - val_loss: 0.2689 - val_custom_f1: 0.9100\n",
            "Epoch 66: lr: 9.999999747378752e-06\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 4.8956e-05 - custom_f1: 0.9823 - val_loss: 0.2702 - val_custom_f1: 0.9100\n",
            "Epoch 67: lr: 9.999999747378752e-06\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 7.4573e-05 - custom_f1: 0.9823 - val_loss: 0.2639 - val_custom_f1: 0.9100\n",
            "Epoch 68: lr: 9.999999747378752e-06\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 4.0329e-05 - custom_f1: 0.9912 - val_loss: 0.2660 - val_custom_f1: 0.9100\n",
            "Epoch 69: lr: 9.999999747378752e-06\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 2.6079e-05 - custom_f1: 1.0000 - val_loss: 0.2748 - val_custom_f1: 0.9100\n",
            "Epoch 70: lr: 9.999999747378752e-06\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.3015e-05 - custom_f1: 1.0000 - val_loss: 0.2810 - val_custom_f1: 0.9100\n",
            "Epoch 71: lr: 9.999999747378752e-06\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 3.2609e-05 - custom_f1: 1.0000 - val_loss: 0.2862 - val_custom_f1: 0.8886\n",
            "Epoch 72: lr: 9.999999747378752e-06\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 8.6478e-05 - custom_f1: 0.9735 - val_loss: 0.2636 - val_custom_f1: 0.8811\n",
            "Epoch 73: lr: 9.999999747378752e-06\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 5.6304e-05 - custom_f1: 0.9735 - val_loss: 0.2728 - val_custom_f1: 0.8811\n",
            "Epoch 74: lr: 9.999999747378752e-06\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 7.0029e-05 - custom_f1: 0.9823 - val_loss: 0.2474 - val_custom_f1: 0.8700\n",
            "Epoch 75: lr: 9.999999747378752e-06\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 5.9885e-05 - custom_f1: 0.9646 - val_loss: 0.2587 - val_custom_f1: 0.8811\n",
            "Epoch 76: lr: 9.999999747378752e-06\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.1175e-05 - custom_f1: 0.9912 - val_loss: 0.2653 - val_custom_f1: 0.8811\n",
            "Epoch 77: lr: 9.999999747378752e-06\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.5594e-05 - custom_f1: 0.9912 - val_loss: 0.2720 - val_custom_f1: 0.8811\n",
            "Epoch 78: lr: 9.999999747378752e-06\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.4778e-05 - custom_f1: 0.9912 - val_loss: 0.2821 - val_custom_f1: 0.8811\n",
            "Epoch 79: lr: 9.999999747378752e-06\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 4.9705e-05 - custom_f1: 0.9735 - val_loss: 0.2747 - val_custom_f1: 0.8811\n",
            "Epoch 80: lr: 9.999999747378752e-06\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - 24s 216ms/step - loss: 3.0164e-05 - custom_f1: 0.9912 - val_loss: 0.2842 - val_custom_f1: 0.8811\n",
            "Epoch 81: lr: 9.999999747378752e-06\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 3.6259e-05 - custom_f1: 0.9823 - val_loss: 0.2832 - val_custom_f1: 0.8811\n",
            "Epoch 82: lr: 9.999999747378752e-06\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 24s 217ms/step - loss: 4.0067e-05 - custom_f1: 0.9823 - val_loss: 0.2883 - val_custom_f1: 0.8811\n",
            "Epoch 83: lr: 9.999999747378752e-06\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.1617e-05 - custom_f1: 0.9912 - val_loss: 0.2920 - val_custom_f1: 0.8811\n",
            "Epoch 84: lr: 9.999999747378752e-06\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 2.1416e-05 - custom_f1: 1.0000 - val_loss: 0.3036 - val_custom_f1: 0.8600\n",
            "Epoch 85: lr: 9.999999747378752e-06\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 2.1365e-05 - custom_f1: 1.0000 - val_loss: 0.3151 - val_custom_f1: 0.8600\n",
            "Epoch 86: lr: 9.999999747378752e-06\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 5.3065e-05 - custom_f1: 0.9735 - val_loss: 0.2753 - val_custom_f1: 0.8811\n",
            "Epoch 87: lr: 9.999999747378752e-06\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 2.5082e-05 - custom_f1: 0.9912 - val_loss: 0.2892 - val_custom_f1: 0.8811\n",
            "Epoch 88: lr: 9.999999747378752e-06\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.4626e-05 - custom_f1: 0.9823 - val_loss: 0.2942 - val_custom_f1: 0.8811\n",
            "Epoch 89: lr: 9.999999747378752e-06\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 4.5394e-05 - custom_f1: 0.9912 - val_loss: 0.2911 - val_custom_f1: 0.8811\n",
            "Epoch 90: lr: 9.999999747378752e-06\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 1.8149e-05 - custom_f1: 1.0000 - val_loss: 0.3051 - val_custom_f1: 0.8811\n",
            "Epoch 91: lr: 9.999999747378752e-06\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.5247e-05 - custom_f1: 1.0000 - val_loss: 0.3181 - val_custom_f1: 0.8600\n",
            "Epoch 92: lr: 9.999999747378752e-06\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 4.0241e-05 - custom_f1: 0.9735 - val_loss: 0.2916 - val_custom_f1: 0.8811\n",
            "Epoch 93: lr: 9.999999747378752e-06\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 2.9553e-05 - custom_f1: 0.9823 - val_loss: 0.2923 - val_custom_f1: 0.8811\n",
            "Epoch 94: lr: 9.999999747378752e-06\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.2438e-05 - custom_f1: 0.9823 - val_loss: 0.2879 - val_custom_f1: 0.8811\n",
            "Epoch 95: lr: 9.999999747378752e-06\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 2.1480e-05 - custom_f1: 0.9912 - val_loss: 0.2996 - val_custom_f1: 0.8811\n",
            "Epoch 96: lr: 9.999999747378752e-06\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 3.0470e-05 - custom_f1: 0.9735 - val_loss: 0.3034 - val_custom_f1: 0.8811\n",
            "Epoch 97: lr: 9.999999747378752e-06\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 2.7562e-05 - custom_f1: 0.9823 - val_loss: 0.3210 - val_custom_f1: 0.8600\n",
            "Epoch 98: lr: 9.999999747378752e-06\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 1.5830e-05 - custom_f1: 0.9912 - val_loss: 0.3419 - val_custom_f1: 0.8600\n",
            "Epoch 99: lr: 9.999999747378752e-06\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 2.0032e-05 - custom_f1: 0.9912 - val_loss: 0.3504 - val_custom_f1: 0.8600\n",
            "Epoch 100: lr: 9.999999747378752e-06\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 25s 217ms/step - loss: 2.1417e-05 - custom_f1: 0.9912 - val_loss: 0.3442 - val_custom_f1: 0.8600\n",
            "weights are setted to best weights (epochs 41)\n",
            "fold 9 [400,450]\n",
            "Epoch 1: lr: 9.999999747378752e-05\n",
            "Epoch 1/100\n",
            "  6/113 [>.............................] - ETA: 23s - loss: 0.4796 - custom_f1: 0.8762WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0484s vs `on_train_batch_end` time: 0.1723s). Check your callbacks.\n",
            "113/113 [==============================] - ETA: 0s - loss: 0.5625 - custom_f1: 0.8050"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "u_RNCLmeNdvj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}